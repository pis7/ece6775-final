==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:39 ; elapsed = 00:00:43 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 371385 ; free virtual = 557439
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:39 ; elapsed = 00:00:43 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 371385 ; free virtual = 557439
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:47 ; elapsed = 00:00:51 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 371162 ; free virtual = 557248
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:107) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:411) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:652) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:49 ; elapsed = 00:00:53 . Memory (MB): peak = 1381.477 ; gain = 743.449 ; free physical = 371086 ; free virtual = 557182
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:479) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:496) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:501) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:507) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:513) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:540) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-7.1' (kernel.cpp:583) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-8.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-11.1' (kernel.cpp:627) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_1_j10' (kernel.cpp:637) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13' (kernel.cpp:647) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:648) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_4_i12' (kernel.cpp:654) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_4_j11' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:665) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-16.1' (kernel.cpp:674) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_7_s4' (kernel.cpp:687) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:696) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-20' (kernel.cpp:713) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_10_i13' (kernel.cpp:727) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:735) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:434) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:385) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:393) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:374) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:355) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:271) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:279) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:288) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:248) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:233) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:143) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:223) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:479) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:496) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:501) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:507) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:513) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:540) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-7.1' (kernel.cpp:583) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-8.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-11.1' (kernel.cpp:627) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_1_j10' (kernel.cpp:637) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13' (kernel.cpp:647) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:648) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_4_i12' (kernel.cpp:654) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_4_j11' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:665) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-16.1' (kernel.cpp:674) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_7_s4' (kernel.cpp:687) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:696) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-20' (kernel.cpp:713) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_10_i13' (kernel.cpp:727) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:735) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:434) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:385) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:393) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:374) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:355) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:271) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:279) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:288) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:248) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:233) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:145) in function 'linear_forward_no_mul' completely with a factor of 24.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:162) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:223) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:269) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:277) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v222.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:478) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales.V' (kernel.cpp:495) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:581) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:625) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:646) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:663) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:672) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:695) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales.V' (kernel.cpp:712) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:646) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v265' (kernel.cpp:451) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v267' (kernel.cpp:453) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v269' (kernel.cpp:455) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v271' (kernel.cpp:457) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-102] Partitioning array 'v79.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v791.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v792.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v793.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v794.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v795.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v796.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v797.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v798.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v799.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7910.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7911.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7912.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7913.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7914.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7915.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7916.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7917.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7918.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7919.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7920.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7921.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7922.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7923.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:107) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:411) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/bits/stl_algobase.h:215:7) to (kernel.cpp:98:32) in function 'quantize_activation'... converting 10 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:143:53) to (kernel.cpp:143:46) in function 'linear_forward_no_mul'... converting 193 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:217:34) to (kernel.cpp:139:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:518:31) to (kernel.cpp:582:20) in function 'attention'... converting 38 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:128)...96 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:55 ; elapsed = 00:01:00 . Memory (MB): peak = 1504.156 ; gain = 866.129 ; free physical = 370924 ; free virtual = 557040
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:139:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:339:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:138:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v205' (kernel.cpp:343:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v226[0]' (kernel.cpp:388:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v226[0]' (kernel.cpp:422:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v226[0]' (kernel.cpp:412:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v154[0]' (kernel.cpp:252:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v154[0]' (kernel.cpp:254:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v148[0]' (kernel.cpp:237:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:121:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v195' (kernel.cpp:323:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v195' (kernel.cpp:328:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:481:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:503:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:509:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:515:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:585:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:602:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:629:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:642:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:659:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:676:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:684:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:691:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:698:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:273:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:281:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:297:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v166[0]' (kernel.cpp:305:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v254[0]' (kernel.cpp:442:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v212[0]' (kernel.cpp:363:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:15 ; elapsed = 00:01:20 . Memory (MB): peak = 1581.188 ; gain = 943.160 ; free physical = 370791 ; free virtual = 556914
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 80.36 seconds; current allocated memory: 615.415 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 616.771 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 617.171 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 617.652 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 618.354 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 619.109 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 112.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.01 seconds; current allocated memory: 623.848 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 2.02 seconds; current allocated memory: 630.602 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 2.23 seconds; current allocated memory: 631.593 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.08 seconds; current allocated memory: 631.745 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 631.866 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 632.032 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 632.374 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 632.851 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 633.143 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 633.474 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 633.647 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 633.865 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 634.087 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 634.341 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 634.686 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.28 seconds; current allocated memory: 635.283 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 635.720 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 635.976 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 637.641 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.55 seconds; current allocated memory: 643.098 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 2.86 seconds; current allocated memory: 648.329 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1 seconds; current allocated memory: 654.835 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fpext_32ns_64_2_1' to 'attention_fpext_3sc4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32tde' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32tde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fpext_3sc4': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 657.185 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52sudo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97vdy' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52sudo': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97vdy': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.9 seconds; current allocated memory: 670.683 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 3.89 seconds; current allocated memory: 696.210 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 697.044 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_xdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 698.500 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.71 seconds; current allocated memory: 700.676 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.57 seconds; current allocated memory: 702.386 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.55 seconds; current allocated memory: 703.746 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuyd2' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuyd2': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32tde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 705.769 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.81 seconds; current allocated memory: 708.190 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v280' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_96' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_95' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_94' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_93' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_92' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_91' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_90' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_89' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_88' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_47' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_46' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_45' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_44' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_27' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_26' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_25' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_24' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_23' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_22' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_21' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_20' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_19' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_18' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_17' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantiz5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantiz7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantiz8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantiz9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantizbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizbdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_87' to 'attention_quantizbek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_86' to 'attention_quantizbfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_85' to 'attention_quantizbgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_84' to 'attention_quantizbhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_83' to 'attention_quantizbil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_82' to 'attention_quantizbjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_81' to 'attention_quantizbkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_80' to 'attention_quantizbll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_79' to 'attention_quantizbml' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_78' to 'attention_quantizbnm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_77' to 'attention_quantizbom' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_76' to 'attention_quantizbpm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_75' to 'attention_quantizbqm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_74' to 'attention_quantizbrm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_73' to 'attention_quantizbsm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_72' to 'attention_quantizbtn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_71' to 'attention_quantizbun' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_70' to 'attention_quantizbvn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_69' to 'attention_quantizbwn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_68' to 'attention_quantizbxn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_67' to 'attention_quantizbyn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_66' to 'attention_quantizbzo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_65' to 'attention_quantizbAo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_64' to 'attention_quantizbBo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_63' to 'attention_quantizbCo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_62' to 'attention_quantizbDo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_61' to 'attention_quantizbEo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_60' to 'attention_quantizbFp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_59' to 'attention_quantizbGp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_58' to 'attention_quantizbHp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_57' to 'attention_quantizbIp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_56' to 'attention_quantizbJp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_55' to 'attention_quantizbKp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_54' to 'attention_quantizbLp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_53' to 'attention_quantizbMq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_52' to 'attention_quantizbNq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_51' to 'attention_quantizbOq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_50' to 'attention_quantizbPq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_49' to 'attention_quantizbQq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_48' to 'attention_quantizbRq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_43' to 'attention_quantizbSr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_42' to 'attention_quantizbTr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_41' to 'attention_quantizbUr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_40' to 'attention_quantizbVr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_39' to 'attention_quantizbWr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_38' to 'attention_quantizbXr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_37' to 'attention_quantizbYs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_36' to 'attention_quantizbZs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_35' to 'attention_quantizb0s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_34' to 'attention_quantizb1s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_33' to 'attention_quantizb2s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_32' to 'attention_quantizb3s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_31' to 'attention_quantizb4t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_30' to 'attention_quantizb5t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_29' to 'attention_quantizb6t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_28' to 'attention_quantizb7t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_b8t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_96' to 'attention_quantizb9t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_95' to 'attention_quantizcau' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_94' to 'attention_quantizcbu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_93' to 'attention_quantizccu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_92' to 'attention_quantizcdu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_91' to 'attention_quantizceu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_90' to 'attention_quantizcfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_89' to 'attention_quantizcgu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_88' to 'attention_quantizchv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_47' to 'attention_quantizciv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_46' to 'attention_quantizcjv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_45' to 'attention_quantizckv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_44' to 'attention_quantizclv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_27' to 'attention_quantizcmv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_26' to 'attention_quantizcnw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_25' to 'attention_quantizcow' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_24' to 'attention_quantizcpw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_23' to 'attention_quantizcqw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_22' to 'attention_quantizcrw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_21' to 'attention_quantizcsw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_20' to 'attention_quantizctx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_19' to 'attention_quantizcux' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_18' to 'attention_quantizcvx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_17' to 'attention_quantizcwx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_16' to 'attention_quantizcxx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_15' to 'attention_quantizcyx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_14' to 'attention_quantizczy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_13' to 'attention_quantizcAy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_12' to 'attention_quantizcBy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_11' to 'attention_quantizcCy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_10' to 'attention_quantizcDy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_9' to 'attention_quantizcEy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizcFz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizcGz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantizcHz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantizcIz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizcJz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizcKz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizcLz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizcMA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizcNA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_87' to 'attention_quantizcOA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_86' to 'attention_quantizcPA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_85' to 'attention_quantizcQA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_84' to 'attention_quantizcRA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_83' to 'attention_quantizcSB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_82' to 'attention_quantizcTB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_81' to 'attention_quantizcUB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_80' to 'attention_quantizcVB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_79' to 'attention_quantizcWB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_78' to 'attention_quantizcXB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_77' to 'attention_quantizcYC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_76' to 'attention_quantizcZC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_75' to 'attention_quantizc0C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_74' to 'attention_quantizc1C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_73' to 'attention_quantizc2C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_72' to 'attention_quantizc3C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_71' to 'attention_quantizc4D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_70' to 'attention_quantizc5D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_69' to 'attention_quantizc6D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_68' to 'attention_quantizc7D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_67' to 'attention_quantizc8D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_66' to 'attention_quantizc9D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_65' to 'attention_quantizdaE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_64' to 'attention_quantizdbE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_63' to 'attention_quantizdcE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_62' to 'attention_quantizddE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_61' to 'attention_quantizdeE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_60' to 'attention_quantizdfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_59' to 'attention_quantizdgE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_58' to 'attention_quantizdhF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_57' to 'attention_quantizdiF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_56' to 'attention_quantizdjF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_55' to 'attention_quantizdkF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_54' to 'attention_quantizdlF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_53' to 'attention_quantizdmF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_52' to 'attention_quantizdnG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_51' to 'attention_quantizdoG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_50' to 'attention_quantizdpG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_49' to 'attention_quantizdqG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_48' to 'attention_quantizdrG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_43' to 'attention_quantizdsG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_42' to 'attention_quantizdtH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_41' to 'attention_quantizduH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_40' to 'attention_quantizdvH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_39' to 'attention_quantizdwH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_38' to 'attention_quantizdxH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_37' to 'attention_quantizdyH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_36' to 'attention_quantizdzI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_35' to 'attention_quantizdAI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_34' to 'attention_quantizdBI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_33' to 'attention_quantizdCI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_32' to 'attention_quantizdDI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_31' to 'attention_quantizdEI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_30' to 'attention_quantizdFJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_29' to 'attention_quantizdGJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_28' to 'attention_quantizdHJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_hidden_states_0' to 'attention_rms_hiddIJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_k_cache' to 'attention_updateddJJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_v_cache' to 'attention_updateddKJ' due to the length limit 20
