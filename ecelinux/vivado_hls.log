
****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019
  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019
    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.

source /opt/xilinx/Vivado/2019.2/scripts/vivado_hls/hls.tcl -notrace
INFO: [HLS 200-10] Running '/opt/xilinx/Vivado/2019.2/bin/unwrapped/lnx64.o/vivado_hls'
INFO: [HLS 200-10] For user 'pis7' on host 'en-ec-zhang-22.coecis.cornell.edu' (Linux_x86_64 version 4.18.0-553.27.1.el8_10.x86_64) on Thu Nov 28 18:15:24 EST 2024
INFO: [HLS 200-10] On os "Red Hat Enterprise Linux release 8.10 (Ootpa)"
INFO: [HLS 200-10] In directory '/home/pis7/ece6775-final/ecelinux'
Sourcing Tcl script 'run.tcl'
INFO: [HLS 200-10] Opening and resetting project '/home/pis7/ece6775-final/ecelinux/attention.prj'.
INFO: [HLS 200-10] Adding design file 'attention.cpp' to the project
INFO: [HLS 200-10] Adding test bench file 'attention_test.cpp' to the project
INFO: [HLS 200-10] Adding test bench file 'data_long' to the project
INFO: [HLS 200-10] Opening and resetting solution '/home/pis7/ece6775-final/ecelinux/attention.prj/solution1'.
INFO: [HLS 200-10] Cleaning up the solution database.
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'attention.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:01:09 ; elapsed = 00:01:14 . Memory (MB): peak = 1168.148 ; gain = 530.125 ; free physical = 291122 ; free virtual = 370478
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:01:09 ; elapsed = 00:01:14 . Memory (MB): peak = 1168.148 ; gain = 530.125 ; free physical = 291122 ; free virtual = 370478
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:01:14 ; elapsed = 00:01:19 . Memory (MB): peak = 1241.301 ; gain = 603.277 ; free physical = 290882 ; free virtual = 370273
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function 'hls::sqrt<42, 26>' into 'rms_norm<384>' (./layer.h:92) automatically.
INFO: [XFORM 203-602] Inlining function 'attention_abs' into 'quantize_activation<1, 384>134' (./layer.h:128) automatically.
INFO: [XFORM 203-602] Inlining function 'attention_max<ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' into 'quantize_activation<1, 384>134' (./layer.h:131) automatically.
INFO: [XFORM 203-602] Inlining function 'attention_round' into 'quantize_activation<1, 384>134' (./layer.h:137) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::exp<40, 24>' into 'softmax<1, 8, 6>' (./layer.h:311) automatically.
INFO: [XFORM 203-602] Inlining function 'init_1d_mem<1, ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' into 'attention<5, 1, 384, 384, 8, 48>' (attention.cpp:104) automatically.
INFO: [XFORM 203-602] Inlining function 'create_causal_mask<1>' into 'attention<5, 1, 384, 384, 8, 48>' (attention.cpp:191) automatically.
WARNING: [SYNCHK 200-23] /opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_sqrt_apfixed.h:272: variable-indexed range selection may cause suboptimal QoR.
WARNING: [SYNCHK 200-120] ./layer.h:89: multiplication is assumed not to overflow by default, otherwise, please add option '-fwrapv'.
INFO: [SYNCHK 200-10] 0 error(s), 2 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:01:16 ; elapsed = 00:01:21 . Memory (MB): peak = 1367.441 ; gain = 729.418 ; free physical = 290801 ; free virtual = 370205
INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'sqrt_fixed<42, 26>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_sqrt_apfixed.h:44:36).
INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'exp_reduce::exp<40, 24>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:41:26).
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (attention.cpp:25) in function 'dut' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (attention.cpp:57) in function 'dut' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'RMS_NORM_LOOP_1' (attention.cpp:91) in function 'attention<5, 1, 384, 384, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'SF_LOOP_2' (attention.cpp:187) in function 'attention<5, 1, 384, 384, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'CM_LOOP_2' (attention.cpp:194) in function 'attention<5, 1, 384, 384, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'CM_LOOP_3' (attention.cpp:195) in function 'attention<5, 1, 384, 384, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'ATTN_2D_LOOP_1' (attention.cpp:218) in function 'attention<5, 1, 384, 384, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'RMS_NORM_LOOP_2' (attention.cpp:224) in function 'attention<5, 1, 384, 384, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'GEMM_3D_FLOAT_LOOP_2' (./layer.h:272) in function 'GEMM_3D_float<8, 1, 6, 8, 6, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'SOFTMAX_LOOP_2' (./layer.h:303) in function 'softmax<1, 8, 6>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'CREATE_CAUSAL_MASK_LOOP_1' (./layer.h:290) in function 'create_causal_mask<1>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'CREATE_CAUSAL_MASK_LOOP_2' (./layer.h:291) in function 'create_causal_mask<1>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'GEMM_3D_FLOAT_LOOP_2' (./layer.h:272) in function 'GEMM_3D_float<8, 1, 48, 8, 48, 6>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'APPLY_ROTARY_POS_EMB_LOOP_2' (./layer.h:204) in function 'apply_rotary_pos_emb<1, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'APPLY_ROTARY_POS_EMB_LOOP_5' (./layer.h:216) in function 'apply_rotary_pos_emb<1, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'RESHAPE_2D_TO_3D_LOOP_1' (./layer.h:183) in function 'reshape_2D_to_3D<1, 8, 48>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'LINEAR_FORWARD_NO_MUL_LOOP_1' (./layer.h:156) in function 'linear_forward_no_mul<1, 384, 384>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'INIT_2D_MEM_LOOP_1' (./layer.h:38) in function 'init_2d_mem<1, 384, ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'QUANTIZE_ACTIVATION_LOOP_1' (./layer.h:125) in function 'quantize_activation<1, 384>' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'INIT_1D_MEM_LOOP_1' (./layer.h:26) in function 'init_1d_mem<1, ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'INIT_2D_MEM_LOOP_1' (./layer.h:38) in function 'init_2d_mem<1, 384, ap_int<8> >' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_sqrt_apfixed.h:267) in function 'sqrt_fixed<42, 26>' completely with a factor of 13.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_sqrt_apfixed.h:295) in function 'sqrt_fixed<42, 26>' completely with a factor of 17.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:277) in function 'exp_reduce::exp<40, 24>' completely with a factor of 19.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:284) in function 'exp_reduce::exp<40, 24>' completely with a factor of 46.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (attention.cpp:25) in function 'dut' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (attention.cpp:57) in function 'dut' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'RMS_NORM_LOOP_1' (attention.cpp:91) in function 'attention<5, 1, 384, 384, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'SF_LOOP_2' (attention.cpp:187) in function 'attention<5, 1, 384, 384, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'CM_LOOP_2' (attention.cpp:194) in function 'attention<5, 1, 384, 384, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'CM_LOOP_3' (attention.cpp:195) in function 'attention<5, 1, 384, 384, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'ATTN_2D_LOOP_1' (attention.cpp:218) in function 'attention<5, 1, 384, 384, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'RMS_NORM_LOOP_2' (attention.cpp:224) in function 'attention<5, 1, 384, 384, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'GEMM_3D_FLOAT_LOOP_2' (./layer.h:272) in function 'GEMM_3D_float<8, 1, 6, 8, 6, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'SOFTMAX_LOOP_2' (./layer.h:303) in function 'softmax<1, 8, 6>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'CREATE_CAUSAL_MASK_LOOP_1' (./layer.h:290) in function 'create_causal_mask<1>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'CREATE_CAUSAL_MASK_LOOP_2' (./layer.h:291) in function 'create_causal_mask<1>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'GEMM_3D_FLOAT_LOOP_2' (./layer.h:272) in function 'GEMM_3D_float<8, 1, 48, 8, 48, 6>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'APPLY_ROTARY_POS_EMB_LOOP_2' (./layer.h:204) in function 'apply_rotary_pos_emb<1, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'APPLY_ROTARY_POS_EMB_LOOP_5' (./layer.h:216) in function 'apply_rotary_pos_emb<1, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'RESHAPE_2D_TO_3D_LOOP_1' (./layer.h:183) in function 'reshape_2D_to_3D<1, 8, 48>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'LINEAR_FORWARD_NO_MUL_LOOP_1' (./layer.h:156) in function 'linear_forward_no_mul<1, 384, 384>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'INIT_2D_MEM_LOOP_1' (./layer.h:38) in function 'init_2d_mem<1, 384, ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'QUANTIZE_ACTIVATION_LOOP_1' (./layer.h:125) in function 'quantize_activation<1, 384>' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'INIT_1D_MEM_LOOP_1' (./layer.h:26) in function 'init_1d_mem<1, ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'INIT_2D_MEM_LOOP_1' (./layer.h:38) in function 'init_2d_mem<1, 384, ap_int<8> >' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q.V' (./layer.h:201) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k.V' (./layer.h:202) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'mask.V.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.V' (attention.cpp:100) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales.V' (attention.cpp:101) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj.V' (attention.cpp:144) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj.V' (attention.cpp:145) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj.V' (attention.cpp:146) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed.V' (attention.cpp:153) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed.V' (attention.cpp:154) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights.V' (attention.cpp:171) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask.V' (attention.cpp:190) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.V' (attention.cpp:232) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales.V' (attention.cpp:233) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask.V.0' (attention.cpp:190) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj_re.V' (attention.cpp:114) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj_re.V' (attention.cpp:115) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj_re.V' (attention.cpp:116) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output_2D.V' (attention.cpp:215) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'input.V' (attention.cpp:21) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'sin_tab.V' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'cos_tab.V' in dimension 1 automatically.
INFO: [XFORM 203-602] Inlining function 'hls::sqrt<42, 26>' into 'rms_norm<384>' (./layer.h:92) automatically.
INFO: [XFORM 203-602] Inlining function 'attention_abs' into 'quantize_activation<1, 384>' (./layer.h:128) automatically.
INFO: [XFORM 203-602] Inlining function 'attention_max<ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' into 'quantize_activation<1, 384>' (./layer.h:131) automatically.
INFO: [XFORM 203-602] Inlining function 'attention_round' into 'quantize_activation<1, 384>' (./layer.h:137) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::exp<40, 24>' into 'softmax<1, 8, 6>' (./layer.h:311) automatically.
INFO: [XFORM 203-602] Inlining function 'init_2d_mem<1, 384, ap_int<8> >' into 'attention<5, 1, 384, 384, 8, 48>' (attention.cpp:103) automatically.
INFO: [XFORM 203-602] Inlining function 'init_1d_mem<1, ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' into 'attention<5, 1, 384, 384, 8, 48>' (attention.cpp:104) automatically.
INFO: [XFORM 203-602] Inlining function 'create_causal_mask<1>' into 'attention<5, 1, 384, 384, 8, 48>' (attention.cpp:191) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_sqrt_apfixed.h:372:1) in function 'sqrt_fixed<42, 26>'... converting 142 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./layer.h:136:64) to (./layer.h:136:58) in function 'quantize_activation<1, 384>'... converting 5 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./layer.h:161:86) to (./layer.h:161:80) in function 'linear_forward_no_mul<1, 384, 384>'... converting 5 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:41:1) to (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:867:1) in function 'exp_reduce::exp<40, 24>'... converting 5 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (./layer.h:239:9) to (./layer.h:238:51) in function 'cache_update<8, 5, 48>'... converting 4 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'exp_reduce::exp<40, 24>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:41:1)...19 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:01:19 ; elapsed = 00:01:25 . Memory (MB): peak = 1500.078 ; gain = 862.055 ; free physical = 290647 ; free virtual = 370073
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims<6, 8, 48>' to 'transpose_last_two_d' (./layer.h:250:62)
WARNING: [XFORM 203-631] Renaming function 'reshape_2D_to_3D<1, 8, 48>' to 'reshape_2D_to_3D' (./layer.h:183:55)
WARNING: [XFORM 203-631] Renaming function 'quantize_activation<1, 384>' to 'quantize_activation' (./layer.h:60:58)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul<1, 384, 384>' to 'linear_forward_no_mu' (./layer.h:156:80)
WARNING: [XFORM 203-631] Renaming function 'init_2d_mem<1, 384, ap_fixed<40, 24, (ap_q_mode)5, (ap_o_mode)3, 0> >' to 'init_2d_mem' (./layer.h:38:48)
WARNING: [XFORM 203-631] Renaming function 'exp_reduce::exp<40, 24>' to 'exp<40, 24>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:41:1)
WARNING: [XFORM 203-631] Renaming function 'cache_update<8, 5, 48>' to 'cache_update' (./layer.h:236:51)
WARNING: [XFORM 203-631] Renaming function 'attention<5, 1, 384, 384, 8, 48>' to 'attention' (attention.cpp:38:53)
WARNING: [XFORM 203-631] Renaming function 'apply_rotary_pos_emb<1, 8, 48>' to 'apply_rotary_pos_emb' (./layer.h:201:59)
WARNING: [XFORM 203-631] Renaming function 'GEMM_3D_float<8, 1, 6, 8, 6, 48>' to 'GEMM_3D_float' (./layer.h:271:55)
WARNING: [XFORM 203-631] Renaming function 'GEMM_3D_float<8, 1, 48, 8, 48, 6>' to 'GEMM_3D_float.1' (./layer.h:271:55)
INFO: [HLS 200-472] Inferring partial write operation for 'output.V' (./layer.h:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'input[0].V' (./layer.h:311:26)
INFO: [HLS 200-472] Inferring partial write operation for 'input[0].V' (./layer.h:315:9)
INFO: [HLS 200-472] Inferring partial write operation for 'input[0].V' (./layer.h:94:17)
INFO: [HLS 200-472] Inferring partial write operation for 'output[0].V' (./layer.h:185:9)
INFO: [HLS 200-472] Inferring partial write operation for 'output_states[0].V' (./layer.h:139:11)
INFO: [HLS 200-472] Inferring partial write operation for 'output[0].V' (./layer.h:169:24)
INFO: [HLS 200-472] Inferring partial write operation for 'output[0].V' (./layer.h:166:11)
INFO: [HLS 200-472] Inferring partial write operation for 'mem[0].V' (./layer.h:39:7)
INFO: [HLS 200-472] Inferring partial write operation for 'input[0].V' (attention.cpp:27:35)
INFO: [HLS 200-472] Inferring partial write operation for 'cache_out.V' (./layer.h:239:9)
INFO: [HLS 200-472] Inferring partial write operation for 'quantized_hidden_sta' (./layer.h:39:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0].V' (attention.cpp:188:9)
INFO: [HLS 200-472] Inferring partial write operation for 'quantized_final_outp' (./layer.h:39:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D[0].V' (attention.cpp:220:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0].V' (./layer.h:206:30)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0].V' (./layer.h:207:30)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0].V' (./layer.h:208:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0].V' (./layer.h:209:9)
INFO: [HLS 200-472] Inferring partial write operation for 'output_q[0].V' (./layer.h:219:106)
INFO: [HLS 200-472] Inferring partial write operation for 'output_k[0].V' (./layer.h:221:106)
INFO: [HLS 200-472] Inferring partial write operation for 'output[0].V' (./layer.h:276:30)
INFO: [HLS 200-472] Inferring partial write operation for 'output[0].V' (./layer.h:276:30)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:23 ; elapsed = 00:01:29 . Memory (MB): peak = 1685.180 ; gain = 1047.156 ; free physical = 290480 ; free virtual = 369912
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'dut' ...
WARNING: [SYN 201-103] Legalizing function name 'sqrt_fixed<42, 26>' to 'sqrt_fixed_42_26_s'.
WARNING: [SYN 201-103] Legalizing function name 'rms_norm<384>' to 'rms_norm_384_s'.
WARNING: [SYN 201-103] Legalizing function name 'GEMM_3D_float.1' to 'GEMM_3D_float_1'.
WARNING: [SYN 201-103] Legalizing function name 'exp<40, 24>' to 'exp_40_24_s'.
WARNING: [SYN 201-103] Legalizing function name 'softmax<1, 8, 6>' to 'softmax_1_8_6_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'sqrt_fixed_42_26_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'sqrt_fixed<42, 26>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 18.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 89.87 seconds; current allocated memory: 674.753 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1 seconds; current allocated memory: 677.417 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm_384_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.28 seconds; current allocated memory: 678.350 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 678.825 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.6 seconds; current allocated memory: 679.497 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 679.862 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'init_2d_mem' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 679.977 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.07 seconds; current allocated memory: 680.045 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 680.398 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 680.830 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 681.004 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 681.155 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 681.485 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 681.877 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.28 seconds; current allocated memory: 682.092 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 682.355 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 682.571 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 682.788 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 682.985 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 683.231 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'exp_40_24_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'exp<40, 24>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 8.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 683.649 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 684.100 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax_1_8_6_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 684.458 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.28 seconds; current allocated memory: 684.917 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 685.171 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 685.418 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 685.873 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.92 seconds; current allocated memory: 688.104 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'dut' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.99 seconds; current allocated memory: 688.902 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.34 seconds; current allocated memory: 689.275 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'sqrt_fixed_42_26_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'sqrt_fixed_42_26_s'.
INFO: [HLS 200-111]  Elapsed time: 0.86 seconds; current allocated memory: 694.173 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm_384_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dut_mul_40s_42ns_81_2_1' to 'dut_mul_40s_42ns_bkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dut_udiv_33s_29ns_33_37_seq_1' to 'dut_udiv_33s_29nscud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dut_mul_72s_40s_72_5_1' to 'dut_mul_72s_40s_7dEe' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'dut_mul_40s_42ns_bkb': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'dut_mul_72s_40s_7dEe': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'dut_udiv_33s_29nscud': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm_384_s'.
INFO: [HLS 200-111]  Elapsed time: 2.34 seconds; current allocated memory: 705.203 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dut_udiv_40ns_40ns_40_44_seq_1' to 'dut_udiv_40ns_40neOg' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'dut_udiv_40ns_40neOg': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.85 seconds; current allocated memory: 707.418 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'init_2d_mem' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'init_2d_mem'.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 708.730 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dut_sdiv_72ns_61s_40_76_seq_1' to 'dut_sdiv_72ns_61sfYi' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'dut_sdiv_72ns_61sfYi': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 709.982 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 0.6 seconds; current allocated memory: 711.574 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_cos_tab_V_5' to 'apply_rotary_pos_g8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_sin_tab_V_5' to 'apply_rotary_pos_hbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0_V' to 'apply_rotary_pos_ibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0_V' to 'apply_rotary_pos_jbC' due to the length limit 20
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 712.808 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.61 seconds; current allocated memory: 714.773 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 716.237 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float_1' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float_1'.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 717.493 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'exp_40_24_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'exp_40_24_s_f_x_msb_3_table_V' to 'exp_40_24_s_f_x_mkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'exp_40_24_s_f_x_msb_2_table_V' to 'exp_40_24_s_f_x_mlbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'exp_40_24_s_exp_x_msb_1_table_V' to 'exp_40_24_s_exp_xmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dut_mul_50ns_47ns_97_2_1' to 'dut_mul_50ns_47nsncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dut_mul_50ns_50ns_100_2_1' to 'dut_mul_50ns_50nsocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'dut_mul_50ns_47nsncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'dut_mul_50ns_50nsocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'exp_40_24_s'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 719.375 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax_1_8_6_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'dut_sdiv_56ns_40s_40_60_seq_1' to 'dut_sdiv_56ns_40spcA' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'dut_sdiv_56ns_40spcA': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax_1_8_6_s'.
INFO: [HLS 200-111]  Elapsed time: 0.71 seconds; current allocated memory: 722.205 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.77 seconds; current allocated memory: 723.960 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_ln_weight_in_V' to 'attention_ln_weigqcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_ln_weight_V' to 'attention_ln_weigrcU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizsc4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_q_proj_re_0_V' to 'attention_q_proj_tde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_re_0_V' to 'attention_k_proj_udo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_v_proj_re_0_V' to 'attention_v_proj_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_q_proj_0_V' to 'attention_q_proj_wdI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_0_V' to 'attention_k_proj_xdS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_v_proj_0_V' to 'attention_v_proj_yd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_q_embed_0_V' to 'attention_q_embedzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_embed_0_V' to 'attention_k_embedAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_cache_upd_V' to 'attention_k_cacheBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_v_cache_upd_V' to 'attention_v_cacheCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed_V' to 'attention_k_proj_DeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_weights_0_V' to 'attention_attn_weEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_0' to 'attention_attn_ouFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_2D_0_V' to 'attention_attn_ouGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'dut_mul_58ns_56s_113_3_1' to 'dut_mul_58ns_56s_IfE' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'dut_mul_58ns_56s_IfE': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'attention'.
INFO: [HLS 200-111]  Elapsed time: 0.97 seconds; current allocated memory: 726.915 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'dut' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'dut/strm_in_V_V' to 'ap_fifo'.
INFO: [RTGEN 206-500] Setting interface mode on port 'dut/strm_out_V_V' to 'ap_fifo'.
INFO: [RTGEN 206-500] Setting interface mode on function 'dut' to 'ap_ctrl_hs'.
INFO: [RTGEN 206-100] Finished creating RTL model for 'dut'.
INFO: [HLS 200-111]  Elapsed time: 1.53 seconds; current allocated memory: 730.585 MB.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 114.29 MHz
INFO: [RTMG 210-282] Generating pipelined core: 'dut_mul_40s_42ns_bkb_MulnS_0'
INFO: [RTMG 210-282] Generating pipelined core: 'dut_udiv_33s_29nscud_div'
INFO: [RTMG 210-282] Generating pipelined core: 'dut_mul_72s_40s_7dEe_MulnS_1'
INFO: [RTMG 210-282] Generating pipelined core: 'dut_udiv_40ns_40neOg_div'
INFO: [RTMG 210-282] Generating pipelined core: 'dut_sdiv_72ns_61sfYi_div'
INFO: [RTMG 210-279] Implementing memory 'apply_rotary_pos_g8j_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'apply_rotary_pos_hbi_rom' using auto ROMs.
INFO: [RTMG 210-278] Implementing memory 'apply_rotary_pos_ibs_ram (RAM)' using block RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'dut_mul_50ns_47nsncg_MulnS_2'
INFO: [RTMG 210-282] Generating pipelined core: 'dut_mul_50ns_50nsocq_MulnS_3'
INFO: [RTMG 210-279] Implementing memory 'exp_40_24_s_f_x_mkbM_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'exp_40_24_s_f_x_mlbW_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'exp_40_24_s_exp_xmb6_rom' using auto ROMs.
INFO: [RTMG 210-282] Generating pipelined core: 'dut_sdiv_56ns_40spcA_div'
INFO: [RTMG 210-282] Generating pipelined core: 'dut_mul_58ns_56s_IfE_MulnS_4'
WARNING: [RTMG 210-274] Memory 'attention_ln_weigqcK' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_ln_weigqcK_rom' using block ROMs.
WARNING: [RTMG 210-274] Memory 'attention_q_weights' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_q_weights_rom' using block ROMs.
WARNING: [RTMG 210-274] Memory 'attention_k_weights' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_k_weights_rom' using block ROMs.
WARNING: [RTMG 210-274] Memory 'attention_v_weights' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_v_weights_rom' using block ROMs.
WARNING: [RTMG 210-274] Memory 'attention_k_cache_V' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_k_cache_V_rom' using block ROMs.
WARNING: [RTMG 210-274] Memory 'attention_v_cache_V' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_v_cache_V_rom' using block ROMs.
WARNING: [RTMG 210-274] Memory 'attention_ln_weigrcU' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_ln_weigrcU_rom' using block ROMs.
WARNING: [RTMG 210-274] Memory 'attention_o_weights' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_o_weights_rom' using block ROMs.
INFO: [RTMG 210-278] Implementing memory 'attention_quantizsc4_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_q_proj_wdI_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_k_cacheBew_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_attn_weEe0_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:01:48 ; elapsed = 00:02:05 . Memory (MB): peak = 1685.180 ; gain = 1047.156 ; free physical = 290362 ; free virtual = 369838
INFO: [VHDL 208-304] Generating VHDL RTL for dut.
INFO: [VLOG 209-307] Generating Verilog RTL for dut.
INFO: [COSIM 212-47] Using XSIM for RTL simulation.
INFO: [COSIM 212-14] Instrumenting C test bench ...
   Build using "/opt/xilinx/Vivado/2019.2/tps/lnx64/gcc-6.2.0/bin/g++"
   Compiling attention.cpp_pre.cpp.tb.cpp
   Compiling attention_test.cpp_pre.cpp.tb.cpp
   Compiling apatb_dut.cpp
   Generating cosim.tv.exe
INFO: [COSIM 212-302] Starting C TB testing ... 
result: 0.0192108, ground_truth: 0.0191956
result: 0.223618, ground_truth: 0.223801
result: -0.00708008, ground_truth: -0.00587463
result: -0.0716248, ground_truth: -0.0723877
result: 0.0582733, ground_truth: 0.059433
result: -0.178482, ground_truth: -0.178116
result: 0.09935, ground_truth: 0.0994568
result: 0.228073, ground_truth: 0.227631
result: 0.0487671, ground_truth: 0.0479126
result: 0.1716, ground_truth: 0.172043
result: -0.0611115, ground_truth: -0.0614624
result: -0.220978, ground_truth: -0.22139
result: 0.176865, ground_truth: 0.174255
result: 0.179092, ground_truth: 0.178909
result: -0.14003, ground_truth: -0.139908
result: 0.053421, ground_truth: 0.053772
result: -0.0392456, ground_truth: -0.0408478
result: 0.0390472, ground_truth: 0.0390167
result: -0.0983429, ground_truth: -0.100479
result: 0.212082, ground_truth: 0.212479
result: 0.220978, ground_truth: 0.221573
result: 0.0145569, ground_truth: 0.0135345
result: -0.0265045, ground_truth: -0.0250702
result: -0.0433044, ground_truth: -0.0426636
result: 0.13295, ground_truth: 0.132416
result: -0.172623, ground_truth: -0.172455
result: -0.0410767, ground_truth: -0.0418549
result: -0.0101166, ground_truth: -0.0123444
result: 0.0631256, ground_truth: 0.0624695
result: 0.126877, ground_truth: 0.125946
result: -0.0718384, ground_truth: -0.0707703
result: -0.118378, ground_truth: -0.117874
result: -0.0147705, ground_truth: -0.0135498
result: -0.0127411, ground_truth: -0.0127411
result: -0.143677, ground_truth: -0.144562
result: 0.202164, ground_truth: 0.201752
result: -0.057663, ground_truth: -0.0566101
result: 0.0999603, ground_truth: 0.0990601
result: -0.0629272, ground_truth: -0.0638885
result: 0.106232, ground_truth: 0.106934
result: -0.0232697, ground_truth: -0.0228577
result: -0.199326, ground_truth: -0.198334
result: 0.00505066, ground_truth: 0.00363159
result: -0.0756836, ground_truth: -0.0738068
result: -0.152176, ground_truth: -0.152649
result: 0.0198212, ground_truth: 0.0198059
result: -0.217545, ground_truth: -0.21492
result: -0.0536194, ground_truth: -0.0531769
result: -0.128296, ground_truth: -0.128784
result: 0.0447235, ground_truth: 0.0448761
result: 0.0137482, ground_truth: 0.0143433
result: 0.105835, ground_truth: 0.104507
result: -0.0273132, ground_truth: -0.0293274
result: 0.140839, ground_truth: 0.141922
result: 0.00444031, ground_truth: 0.00282288
result: -0.110291, ground_truth: -0.109589
result: 0.17363, ground_truth: 0.175278
result: 0.0661621, ground_truth: 0.0679169
result: 0.0435028, ground_truth: 0.0428467
result: 0.0273132, ground_truth: 0.0258636
result: 0.0601044, ground_truth: 0.0578156
result: -0.140839, ground_truth: -0.142746
result: -0.0149689, ground_truth: -0.0163879
result: -0.0789185, ground_truth: -0.0774384
result: -0.00909424, ground_truth: -0.00970459
result: -0.190018, ground_truth: -0.190247
result: 0.0795288, ground_truth: 0.0812683
result: 0.0133514, ground_truth: 0.0135345
result: 0.138214, ground_truth: 0.139282
result: 0.0847931, ground_truth: 0.0838928
result: 0.0764923, ground_truth: 0.0772247
result: -0.0157776, ground_truth: -0.0155792
result: -0.0149689, ground_truth: -0.0163879
result: -0.180908, ground_truth: -0.181351
result: 0.120804, ground_truth: 0.121094
result: -0.116364, ground_truth: -0.117462
result: 0.106445, ground_truth: 0.104721
result: 0.0845795, ground_truth: 0.0848999
result: -0.0562592, ground_truth: -0.055603
result: -0.076889, ground_truth: -0.0782471
result: 0.106033, ground_truth: 0.107346
result: 0.146713, ground_truth: 0.149399
result: 0.214905, ground_truth: 0.216721
result: 0.0127411, ground_truth: 0.0141449
result: -0.0507813, ground_truth: -0.049942
result: 0.0121307, ground_truth: 0.0115204
result: 0.126266, ground_truth: 0.126144
result: 0.138016, ground_truth: 0.138275
result: -0.234131, ground_truth: -0.233505
result: 0.0631256, ground_truth: 0.0628662
result: -0.138214, ground_truth: -0.137482
result: -0.0522003, ground_truth: -0.0533752
result: -0.0380402, ground_truth: -0.0374146
result: -0.0216522, ground_truth: -0.0212402
result: -0.132751, ground_truth: -0.132019
result: -0.105835, ground_truth: -0.105331
result: 0.145294, ground_truth: 0.145752
result: 0.0341949, ground_truth: 0.0333557
result: 0.106842, ground_truth: 0.106339
result: -0.10199, ground_truth: -0.102905
result: -0.0196228, ground_truth: -0.0204315
result: 0.0574646, ground_truth: 0.0570068
result: 0.110291, ground_truth: 0.110977
result: 0.00404358, ground_truth: 0.00444031
result: 0.094696, ground_truth: 0.0937958
result: 0.00708008, ground_truth: 0.00666809
result: 0.0161896, ground_truth: 0.0175781
result: -0.0730438, ground_truth: -0.0731964
result: -0.197708, ground_truth: -0.198532
result: 0.158646, ground_truth: 0.157486
result: 0.202774, ground_truth: 0.203781
result: 0.0400696, ground_truth: 0.0386047
result: -0.202774, ground_truth: -0.204407
result: -0.0115204, ground_truth: -0.0109253
result: -0.0109253, ground_truth: -0.0101166
result: -0.0582733, ground_truth: -0.0572205
result: -0.201752, ground_truth: -0.203995
result: -0.035614, ground_truth: -0.0339661
result: -0.0293427, ground_truth: -0.0291138
result: -0.0311584, ground_truth: -0.0311432
result: -0.115952, ground_truth: -0.115646
result: -0.0497742, ground_truth: -0.0515594
result: 0.248703, ground_truth: 0.249069
result: -0.135376, ground_truth: -0.134445
result: 0.0558472, ground_truth: 0.053772
result: -0.0214386, ground_truth: -0.0234528
result: -0.0938873, ground_truth: -0.0915833
result: 0.0762939, ground_truth: 0.0778351
result: 0.0400696, ground_truth: 0.0396118
result: -0.00646973, ground_truth: -0.006073
result: 0.100174, ground_truth: 0.0998688
result: 0.0734558, ground_truth: 0.0735779
result: -0.0546265, ground_truth: -0.0545959
result: 0.217941, ground_truth: 0.218536
result: 0.023056, ground_truth: 0.0234375
result: -0.138611, ground_truth: -0.138901
result: -0.246277, ground_truth: -0.246658
result: 0.0856018, ground_truth: 0.0834808
result: -0.148941, ground_truth: -0.15062
result: 0.160873, ground_truth: 0.162735
result: 0.0633392, ground_truth: 0.0662994
result: -0.0438995, ground_truth: -0.044281
result: -0.0817566, ground_truth: -0.0818787
result: 0.0983429, ground_truth: 0.0990601
result: -0.0135498, ground_truth: -0.0123444
result: 0.0206299, ground_truth: 0.021225
result: -0.138214, ground_truth: -0.137283
result: 0.0961151, ground_truth: 0.0952148
result: 0.175446, ground_truth: 0.176483
result: 0.0896454, ground_truth: 0.0883331
result: 0.0348053, ground_truth: 0.0345612
result: 0.0853882, ground_truth: 0.0832825
result: -0.145706, ground_truth: -0.146576
result: 0.13942, ground_truth: 0.138275
result: 0.180511, ground_truth: 0.181747
result: -0.0455322, ground_truth: -0.044281
result: -0.09935, ground_truth: -0.100891
result: -0.0914612, ground_truth: -0.0934143
result: -0.150955, ground_truth: -0.151031
result: 0.0370331, ground_truth: 0.0359802
result: -0.0884247, ground_truth: -0.0889587
result: -0.00323486, ground_truth: -0.00102234
result: 0.0214386, ground_truth: 0.0206146
result: 0.0167847, ground_truth: 0.0159607
result: -0.0776978, ground_truth: -0.0786591
result: -0.00201416, ground_truth: -0.00222778
result: -0.0649567, ground_truth: -0.0641022
result: 0.165939, ground_truth: 0.167191
result: -0.0683899, ground_truth: -0.0671234
result: -0.0505829, ground_truth: -0.0495453
result: -0.0149689, ground_truth: -0.0149689
result: 0.0313568, ground_truth: 0.032135
result: 0.101181, ground_truth: 0.100677
result: -0.199127, ground_truth: -0.198532
result: -0.0856018, ground_truth: -0.086731
result: 0.13092, ground_truth: 0.131805
result: -0.139023, ground_truth: -0.140717
result: 0.0625305, ground_truth: 0.0630646
result: 0.0967255, ground_truth: 0.0966339
result: 0.158249, ground_truth: 0.157288
result: 0.136795, ground_truth: 0.137268
result: -0.00404358, ground_truth: -0.00202942
result: 0.0216522, ground_truth: 0.0238495
result: -0.14975, ground_truth: -0.150833
result: -0.0153656, ground_truth: -0.0171967
result: 0.225632, ground_truth: 0.227234
result: -0.082962, ground_truth: -0.0834961
result: 0.242233, ground_truth: 0.240982
result: 0.192856, ground_truth: 0.194077
result: 0.124252, ground_truth: 0.12413
result: -0.0722351, ground_truth: -0.071167
result: 0.0526123, ground_truth: 0.0523529
result: -0.00363159, ground_truth: -0.0030365
result: -0.0354004, ground_truth: -0.0366058
result: -0.346054, ground_truth: -0.345306
result: 0.00970459, ground_truth: 0.0101013
result: 0.0965271, ground_truth: 0.0960236
result: -0.0226593, ground_truth: -0.0214386
result: -0.017807, ground_truth: -0.016983
result: -0.0783081, ground_truth: -0.0776367
result: 0.122421, ground_truth: 0.120895
result: -0.0435028, ground_truth: -0.0444794
result: -0.141449, ground_truth: -0.143143
result: -0.0107117, ground_truth: -0.00950623
result: -0.0105133, ground_truth: -0.0105133
result: 0.0979462, ground_truth: 0.097641
result: 0.0839844, ground_truth: 0.0850983
result: 0.0653534, ground_truth: 0.0661011
result: 0.0671844, ground_truth: 0.0673218
result: 0.0639496, ground_truth: 0.0648956
result: 0.297485, ground_truth: 0.29921
result: -0.333298, ground_truth: -0.333588
result: -0.277451, ground_truth: -0.276367
result: 0.0524139, ground_truth: 0.0507355
result: -0.0957184, ground_truth: -0.0964355
result: -0.0384369, ground_truth: -0.03862
result: 0.204391, ground_truth: 0.202362
result: 0.211884, ground_truth: 0.212265
result: -0.0882263, ground_truth: -0.0877533
result: 0.151367, ground_truth: 0.151016
result: -0.0942993, ground_truth: -0.0952301
result: -0.0455322, ground_truth: -0.0434723
result: -0.00323486, ground_truth: -0.00364685
result: 0.0641479, ground_truth: 0.0648956
result: -0.183136, ground_truth: -0.183578
result: -0.094696, ground_truth: -0.0956268
result: -0.0509949, ground_truth: -0.0493317
result: -0.17099, ground_truth: -0.170441
result: 0.147522, ground_truth: 0.145157
result: 0.33046, ground_truth: 0.331146
result: 0.0390472, ground_truth: 0.0371857
result: -0.261047, ground_truth: -0.259995
result: 0.0866089, ground_truth: 0.0855103
result: -0.336945, ground_truth: -0.336212
result: -0.041687, ground_truth: -0.0412445
result: -0.268539, ground_truth: -0.269089
result: -0.270157, ground_truth: -0.270706
result: 0.113724, ground_truth: 0.11058
result: -0.196289, ground_truth: -0.195908
result: 0.0617218, ground_truth: 0.0618591
result: 0.0376282, ground_truth: 0.0398254
result: -0.121826, ground_truth: -0.121506
result: -0.0317688, ground_truth: -0.0315399
result: -0.100174, ground_truth: -0.10231
result: 0.223404, ground_truth: 0.222992
result: -0.127899, ground_truth: -0.12738
result: -0.159256, ground_truth: -0.156693
result: -0.141449, ground_truth: -0.141327
result: 0.273605, ground_truth: 0.272919
result: -0.103806, ground_truth: -0.103928
result: -0.0623169, ground_truth: -0.0630798
result: 0.105225, ground_truth: 0.104721
result: 0.075882, ground_truth: 0.0778351
result: 0.0424957, ground_truth: 0.0426483
result: 0.0938873, ground_truth: 0.0927887
result: 0.0109253, ground_truth: 0.00909424
result: -0.0627289, ground_truth: -0.0628815
result: -0.12648, ground_truth: -0.124542
result: 0.00950623, ground_truth: 0.0101013
result: -0.202972, ground_truth: -0.202988
result: 0.227859, ground_truth: 0.226425
result: -0.0562592, ground_truth: -0.0574188
result: -0.0787201, ground_truth: -0.0780487
result: -0.0479584, ground_truth: -0.0471191
result: -0.0275116, ground_truth: -0.0281067
result: -0.119598, ground_truth: -0.118881
result: -0.0285339, ground_truth: -0.0299225
result: 0.14975, ground_truth: 0.149994
result: -0.106033, ground_truth: -0.107361
result: -0.0987549, ground_truth: -0.0996704
result: -0.094696, ground_truth: -0.094223
result: -0.100769, ground_truth: -0.099472
result: 0.0550385, ground_truth: 0.0563965
result: 0.0202332, ground_truth: 0.0210114
result: 0.0981445, ground_truth: 0.0998688
result: -0.0236664, ground_truth: -0.0232544
result: 0.0641479, ground_truth: 0.0652924
result: -0.193665, ground_truth: -0.194702
result: 0.0750732, ground_truth: 0.0731812
result: -0.201157, ground_truth: -0.199753
result: -0.076889, ground_truth: -0.0778503
result: 0.128098, ground_truth: 0.128983
result: -0.0141602, ground_truth: -0.0137482
result: -0.215927, ground_truth: -0.214706
result: 0.0584717, ground_truth: 0.0586243
result: -0.0200348, ground_truth: -0.0184021
result: 0.215118, ground_truth: 0.215103
result: -0.322372, ground_truth: -0.322067
result: -0.160065, ground_truth: -0.161331
result: 0.158249, ground_truth: 0.1595
result: -0.153595, ground_truth: -0.153458
result: 0.129105, ground_truth: 0.127151
result: -0.0420837, ground_truth: -0.0402374
result: -0.0601044, ground_truth: -0.0604553
result: 0.112305, ground_truth: 0.112396
result: -0.113724, ground_truth: -0.112823
result: 0.126068, ground_truth: 0.124725
result: 0.0285339, ground_truth: 0.0301208
result: -0.128708, ground_truth: -0.126968
result: -0.0103149, ground_truth: -0.0111237
result: 0.0874176, ground_truth: 0.0875244
result: -0.0912628, ground_truth: -0.0903778
result: 0.0447235, ground_truth: 0.0464935
result: 0.0317688, ground_truth: 0.0309296
result: 0.0675812, ground_truth: 0.0662994
result: -0.103607, ground_truth: -0.101898
result: 0.113922, ground_truth: 0.114212
result: 0.118378, ground_truth: 0.117661
result: -0.330673, ground_truth: -0.33136
result: 0.0938873, ground_truth: 0.0931854
result: 0.0781097, ground_truth: 0.0794373
result: 0.0493774, ground_truth: 0.0507355
result: 0.119385, ground_truth: 0.118469
result: -0.306992, ground_truth: -0.304672
result: -0.225632, ground_truth: -0.226242
result: -0.13942, ground_truth: -0.139297
result: 0.0740662, ground_truth: 0.0721741
result: -0.0350037, ground_truth: -0.0331573
result: 0.0137482, ground_truth: 0.0135345
result: 0.190018, ground_truth: 0.187408
result: 0.0536194, ground_truth: 0.0527649
result: -0.247498, ground_truth: -0.247665
result: 0.138214, ground_truth: 0.137268
result: 0.158447, ground_truth: 0.159103
result: 0.134979, ground_truth: 0.13504
result: -0.145493, ground_truth: -0.146378
result: -0.136993, ground_truth: -0.135468
result: -0.0914612, ground_truth: -0.0921936
result: -0.199127, ground_truth: -0.199341
result: 0.110489, ground_truth: 0.111588
result: -0.015976, ground_truth: -0.0163879
result: -0.0105133, ground_truth: -0.0105133
result: 0.151169, ground_truth: 0.151413
result: -0.119186, ground_truth: -0.118484
result: 0.046936, ground_truth: 0.0464935
result: -0.0018158, ground_truth: -0.00141907
result: -0.100174, ground_truth: -0.100082
result: -0.113113, ground_truth: -0.113022
result: 0.101181, ground_truth: 0.102295
result: -0.0639496, ground_truth: -0.0646973
result: -0.19043, ground_truth: -0.191467
result: -0.0190125, ground_truth: -0.0194092
result: -0.152374, ground_truth: -0.153656
result: -0.0631256, ground_truth: -0.0624847
result: -0.0783081, ground_truth: -0.0776367
result: 0.161087, ground_truth: 0.161728
result: -0.0605011, ground_truth: -0.0588379
result: 0.145493, ground_truth: 0.144745
result: -0.214096, ground_truth: -0.213699
result: 0.094696, ground_truth: 0.0964203
result: -0.057663, ground_truth: -0.0600586
result: -0.0244751, ground_truth: -0.0238647
result: -0.21875, ground_truth: -0.217133
result: -0.116364, ground_truth: -0.11525
result: -0.0532227, ground_truth: -0.0537872
result: 0.217941, ground_truth: 0.219757
result: -0.0345917, ground_truth: -0.0355835
result: -0.0354004, ground_truth: -0.0345764
result: 0.230499, ground_truth: 0.231476
result: -0.0584717, ground_truth: -0.0590363
result: 0.199127, ground_truth: 0.201752
result: -0.137405, ground_truth: -0.136871
result: 0.104019, ground_truth: 0.104507
result: -0.118378, ground_truth: -0.117676
result: -0.0428925, ground_truth: -0.0430756
result: 0.0667725, ground_truth: 0.0675201
result: 0.0851898, ground_truth: 0.0847015
result: -0.09935, ground_truth: -0.100479
result: 0.128494, ground_truth: 0.128372
result: 0.132751, ground_truth: 0.131409
result: 0.0864105, ground_truth: 0.0848999
result: -0.310837, ground_truth: -0.310944
result: 0.0455322, ground_truth: 0.043869
result: -0.0198212, ground_truth: -0.0204315
result: -0.00221252, ground_truth: -0.00404358
result: -0.134171, ground_truth: -0.135864
result: 0.150146, ground_truth: 0.150208
result: -0.0499725, ground_truth: -0.0481262
result: 0.0714264, ground_truth: 0.0715637
result: -0.041687, ground_truth: -0.0422668
result: -0.1026, ground_truth: -0.100891
result: 0.0979462, ground_truth: 0.097641
result: -0.272583, ground_truth: -0.272736
result: -0.238785, ground_truth: -0.240387

[32mRMSE: [0m0.0011349
[35mattention           : [0m[35m     1 calls; [0m[35m333.710 msecs total time
[0mINFO: [COSIM 212-333] Generating C post check test bench ...
INFO: [COSIM 212-12] Generating RTL test bench ...
INFO: [COSIM 212-1] *** C/RTL co-simulation file generation completed. ***
INFO: [COSIM 212-323] Starting verilog simulation. 
INFO: [COSIM 212-15] Starting XSIM ...
INFO: [XSIM 43-3496] Using init file passed via -initfile option "/opt/xilinx/Vivado/2019.2/data/xsim/ip/xsim_ip.ini".
Vivado Simulator 2019.2
Copyright 1986-1999, 2001-2019 Xilinx, Inc. All Rights Reserved.
Running: /opt/xilinx/Vivado/2019.2/bin/unwrapped/lnx64.o/xelab xil_defaultlib.apatb_dut_top glbl -prj dut.prj -L smartconnect_v1_0 -L axi_protocol_checker_v1_1_12 -L axi_protocol_checker_v1_1_13 -L axis_protocol_checker_v1_1_11 -L axis_protocol_checker_v1_1_12 -L xil_defaultlib -L unisims_ver -L xpm --initfile /opt/xilinx/Vivado/2019.2/data/xsim/ip/xsim_ip.ini --lib ieee_proposed=./ieee_proposed -s dut 
Multi-threading is on. Using 62 slave threads.
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/glbl.v" into library work
INFO: [VRFC 10-311] analyzing module glbl
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut.autotb.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module apatb_dut_top
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/AESL_autofifo_strm_in_V_V.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module AESL_autofifo_strm_in_V_V
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/AESL_autofifo_strm_out_V_V.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module AESL_autofifo_strm_out_V_V
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/sqrt_fixed_42_26_s.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module sqrt_fixed_42_26_s
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/rms_norm_384_s.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module rms_norm_384_s
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/quantize_activation.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module quantize_activation
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/init_2d_mem.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module init_2d_mem
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/linear_forward_no_mu.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module linear_forward_no_mu
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/reshape_2D_to_3D.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module reshape_2D_to_3D
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/apply_rotary_pos_emb.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module apply_rotary_pos_emb
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/cache_update.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module cache_update
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/transpose_last_two_d.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module transpose_last_two_d
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/GEMM_3D_float_1.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module GEMM_3D_float_1
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/exp_40_24_s.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module exp_40_24_s
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/softmax_1_8_6_s.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module softmax_1_8_6_s
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/GEMM_3D_float.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module GEMM_3D_float
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_mul_40s_42ns_bkb.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_mul_40s_42ns_bkb_MulnS_0
INFO: [VRFC 10-311] analyzing module dut_mul_40s_42ns_bkb
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_udiv_33s_29nscud.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_udiv_33s_29nscud_div_u
INFO: [VRFC 10-311] analyzing module dut_udiv_33s_29nscud_div
INFO: [VRFC 10-311] analyzing module dut_udiv_33s_29nscud
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_mul_72s_40s_7dEe.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_mul_72s_40s_7dEe_MulnS_1
INFO: [VRFC 10-311] analyzing module dut_mul_72s_40s_7dEe
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_udiv_40ns_40neOg.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_udiv_40ns_40neOg_div_u
INFO: [VRFC 10-311] analyzing module dut_udiv_40ns_40neOg_div
INFO: [VRFC 10-311] analyzing module dut_udiv_40ns_40neOg
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_sdiv_72ns_61sfYi.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_sdiv_72ns_61sfYi_div_u
INFO: [VRFC 10-311] analyzing module dut_sdiv_72ns_61sfYi_div
INFO: [VRFC 10-311] analyzing module dut_sdiv_72ns_61sfYi
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/apply_rotary_pos_g8j.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module apply_rotary_pos_g8j_rom
INFO: [VRFC 10-311] analyzing module apply_rotary_pos_g8j
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/apply_rotary_pos_hbi.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module apply_rotary_pos_hbi_rom
INFO: [VRFC 10-311] analyzing module apply_rotary_pos_hbi
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/apply_rotary_pos_ibs.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module apply_rotary_pos_ibs_ram
INFO: [VRFC 10-311] analyzing module apply_rotary_pos_ibs
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_mul_50ns_47nsncg.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_mul_50ns_47nsncg_MulnS_2
INFO: [VRFC 10-311] analyzing module dut_mul_50ns_47nsncg
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_mul_50ns_50nsocq.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_mul_50ns_50nsocq_MulnS_3
INFO: [VRFC 10-311] analyzing module dut_mul_50ns_50nsocq
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/exp_40_24_s_f_x_mkbM.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module exp_40_24_s_f_x_mkbM_rom
INFO: [VRFC 10-311] analyzing module exp_40_24_s_f_x_mkbM
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/exp_40_24_s_f_x_mlbW.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module exp_40_24_s_f_x_mlbW_rom
INFO: [VRFC 10-311] analyzing module exp_40_24_s_f_x_mlbW
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/exp_40_24_s_exp_xmb6.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module exp_40_24_s_exp_xmb6_rom
INFO: [VRFC 10-311] analyzing module exp_40_24_s_exp_xmb6
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_sdiv_56ns_40spcA.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_sdiv_56ns_40spcA_div_u
INFO: [VRFC 10-311] analyzing module dut_sdiv_56ns_40spcA_div
INFO: [VRFC 10-311] analyzing module dut_sdiv_56ns_40spcA
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut_mul_58ns_56s_IfE.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module dut_mul_58ns_56s_IfE_MulnS_4
INFO: [VRFC 10-311] analyzing module dut_mul_58ns_56s_IfE
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_ln_weigqcK.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_ln_weigqcK_rom
INFO: [VRFC 10-311] analyzing module attention_ln_weigqcK
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_q_weights.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_q_weights_rom
INFO: [VRFC 10-311] analyzing module attention_q_weights
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_k_weights.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_k_weights_rom
INFO: [VRFC 10-311] analyzing module attention_k_weights
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_v_weights.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_v_weights_rom
INFO: [VRFC 10-311] analyzing module attention_v_weights
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_k_cache_V.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_k_cache_V_rom
INFO: [VRFC 10-311] analyzing module attention_k_cache_V
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_v_cache_V.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_v_cache_V_rom
INFO: [VRFC 10-311] analyzing module attention_v_cache_V
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_ln_weigrcU.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_ln_weigrcU_rom
INFO: [VRFC 10-311] analyzing module attention_ln_weigrcU
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_o_weights.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_o_weights_rom
INFO: [VRFC 10-311] analyzing module attention_o_weights
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_quantizsc4.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_quantizsc4_ram
INFO: [VRFC 10-311] analyzing module attention_quantizsc4
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_q_proj_wdI.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_q_proj_wdI_ram
INFO: [VRFC 10-311] analyzing module attention_q_proj_wdI
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_k_cacheBew.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_k_cacheBew_ram
INFO: [VRFC 10-311] analyzing module attention_k_cacheBew
INFO: [VRFC 10-2263] Analyzing SystemVerilog file "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/attention_attn_weEe0.v" into library xil_defaultlib
INFO: [VRFC 10-311] analyzing module attention_attn_weEe0_ram
INFO: [VRFC 10-311] analyzing module attention_attn_weEe0
Starting static elaboration
Pass Through NonSizing Optimizer
Completed static elaboration
Starting simulation data flow analysis
Completed simulation data flow analysis
Time Resolution for simulation is 1ps
Compiling module xil_defaultlib.apply_rotary_pos_ibs_ram
Compiling module xil_defaultlib.apply_rotary_pos_ibs(DataWidth=4...
Compiling module xil_defaultlib.attention_ln_weigqcK_rom
Compiling module xil_defaultlib.attention_ln_weigqcK(DataWidth=4...
Compiling module xil_defaultlib.attention_q_weights_rom
Compiling module xil_defaultlib.attention_q_weights(DataWidth=8,...
Compiling module xil_defaultlib.attention_k_weights_rom
Compiling module xil_defaultlib.attention_k_weights(DataWidth=8,...
Compiling module xil_defaultlib.attention_v_weights_rom
Compiling module xil_defaultlib.attention_v_weights(DataWidth=8,...
Compiling module xil_defaultlib.attention_k_cache_V_rom
Compiling module xil_defaultlib.attention_k_cache_V(DataWidth=40...
Compiling module xil_defaultlib.attention_v_cache_V_rom
Compiling module xil_defaultlib.attention_v_cache_V(DataWidth=40...
Compiling module xil_defaultlib.attention_ln_weigrcU_rom
Compiling module xil_defaultlib.attention_ln_weigrcU(DataWidth=4...
Compiling module xil_defaultlib.attention_o_weights_rom
Compiling module xil_defaultlib.attention_o_weights(DataWidth=8,...
Compiling module xil_defaultlib.attention_quantizsc4_ram
Compiling module xil_defaultlib.attention_quantizsc4(DataWidth=8...
Compiling module xil_defaultlib.attention_q_proj_wdI_ram
Compiling module xil_defaultlib.attention_q_proj_wdI(DataWidth=4...
Compiling module xil_defaultlib.attention_k_cacheBew_ram
Compiling module xil_defaultlib.attention_k_cacheBew(DataWidth=4...
Compiling module xil_defaultlib.attention_attn_weEe0_ram
Compiling module xil_defaultlib.attention_attn_weEe0(DataWidth=4...
Compiling module xil_defaultlib.sqrt_fixed_42_26_s
Compiling module xil_defaultlib.dut_mul_40s_42ns_bkb_MulnS_0
Compiling module xil_defaultlib.dut_mul_40s_42ns_bkb(ID=1,NUM_ST...
Compiling module xil_defaultlib.dut_udiv_33s_29nscud_div_u(in0_W...
Compiling module xil_defaultlib.dut_udiv_33s_29nscud_div(in0_WID...
Compiling module xil_defaultlib.dut_udiv_33s_29nscud(ID=1,NUM_ST...
Compiling module xil_defaultlib.dut_mul_72s_40s_7dEe_MulnS_1
Compiling module xil_defaultlib.dut_mul_72s_40s_7dEe(ID=1,NUM_ST...
Compiling module xil_defaultlib.rms_norm_384_s
Compiling module xil_defaultlib.exp_40_24_s_f_x_mkbM_rom
Compiling module xil_defaultlib.exp_40_24_s_f_x_mkbM(DataWidth=3...
Compiling module xil_defaultlib.exp_40_24_s_f_x_mlbW_rom
Compiling module xil_defaultlib.exp_40_24_s_f_x_mlbW(DataWidth=4...
Compiling module xil_defaultlib.exp_40_24_s_exp_xmb6_rom
Compiling module xil_defaultlib.exp_40_24_s_exp_xmb6(DataWidth=5...
Compiling module xil_defaultlib.dut_mul_50ns_47nsncg_MulnS_2
Compiling module xil_defaultlib.dut_mul_50ns_47nsncg(ID=1,NUM_ST...
Compiling module xil_defaultlib.dut_mul_50ns_50nsocq_MulnS_3
Compiling module xil_defaultlib.dut_mul_50ns_50nsocq(ID=1,NUM_ST...
Compiling module xil_defaultlib.exp_40_24_s
Compiling module xil_defaultlib.dut_sdiv_56ns_40spcA_div_u(in0_W...
Compiling module xil_defaultlib.dut_sdiv_56ns_40spcA_div(in0_WID...
Compiling module xil_defaultlib.dut_sdiv_56ns_40spcA(ID=1,NUM_ST...
Compiling module xil_defaultlib.softmax_1_8_6_s
Compiling module xil_defaultlib.dut_sdiv_72ns_61sfYi_div_u(in0_W...
Compiling module xil_defaultlib.dut_sdiv_72ns_61sfYi_div(in0_WID...
Compiling module xil_defaultlib.dut_sdiv_72ns_61sfYi(ID=1,NUM_ST...
Compiling module xil_defaultlib.linear_forward_no_mu
Compiling module xil_defaultlib.dut_udiv_40ns_40neOg_div_u(in0_W...
Compiling module xil_defaultlib.dut_udiv_40ns_40neOg_div(in0_WID...
Compiling module xil_defaultlib.dut_udiv_40ns_40neOg(ID=1,NUM_ST...
Compiling module xil_defaultlib.quantize_activation
Compiling module xil_defaultlib.apply_rotary_pos_g8j_rom
Compiling module xil_defaultlib.apply_rotary_pos_g8j(DataWidth=1...
Compiling module xil_defaultlib.apply_rotary_pos_hbi_rom
Compiling module xil_defaultlib.apply_rotary_pos_hbi(DataWidth=1...
Compiling module xil_defaultlib.apply_rotary_pos_emb
Compiling module xil_defaultlib.GEMM_3D_float
Compiling module xil_defaultlib.GEMM_3D_float_1
Compiling module xil_defaultlib.cache_update
Compiling module xil_defaultlib.transpose_last_two_d
Compiling module xil_defaultlib.reshape_2D_to_3D
Compiling module xil_defaultlib.init_2d_mem
Compiling module xil_defaultlib.dut_mul_58ns_56s_IfE_MulnS_4
Compiling module xil_defaultlib.dut_mul_58ns_56s_IfE(ID=1,NUM_ST...
Compiling module xil_defaultlib.attention
Compiling module xil_defaultlib.dut
Compiling module xil_defaultlib.AESL_autofifo_strm_in_V_V
Compiling module xil_defaultlib.AESL_autofifo_strm_out_V_V
Compiling module xil_defaultlib.apatb_dut_top
Compiling module work.glbl
Built simulation snapshot dut

****** Webtalk v2019.2 (64-bit)
  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019
  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019
    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.

source /home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/xsim.dir/dut/webtalk/xsim_webtalk.tcl -notrace
INFO: [Common 17-206] Exiting Webtalk at Thu Nov 28 18:18:48 2024...

****** xsim v2019.2 (64-bit)
  **** SW Build 2708876 on Wed Nov  6 21:39:14 MST 2019
  **** IP Build 2700528 on Thu Nov  7 00:09:20 MST 2019
    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.

source xsim.dir/dut/xsim_script.tcl
# xsim {dut} -autoloadwcfg -tclbatch {dut.tcl}
Vivado Simulator 2019.2
Time resolution is 1 ps
source dut.tcl
## run all
////////////////////////////////////////////////////////////////////////////////////
// Inter-Transaction Progress: Completed Transaction / Total Transaction
// Intra-Transaction Progress: Measured Latency / Latency Estimation * 100%
//
// RTL Simulation : "Inter-Transaction Progress" ["Intra-Transaction Progress"] @ "Simulation Time"
////////////////////////////////////////////////////////////////////////////////////
// RTL Simulation : 0 / 1 [0.00%] @ "125000"
// RTL Simulation : 1 / 1 [100.00%] @ "23878395000"
////////////////////////////////////////////////////////////////////////////////////
$finish called at time : 23878435 ns : File "/home/pis7/ece6775-final/ecelinux/attention.prj/solution1/sim/verilog/dut.autotb.v" Line 271
run: Time (s): cpu = 00:00:00.01 ; elapsed = 00:01:37 . Memory (MB): peak = 1677.863 ; gain = 0.000 ; free physical = 290112 ; free virtual = 369676
## quit
INFO: [Common 17-206] Exiting xsim at Thu Nov 28 18:20:33 2024...
INFO: [COSIM 212-316] Starting C post checking ...
result: 0.0192108, ground_truth: 0.0191956
result: 0.223618, ground_truth: 0.223801
result: -0.00708008, ground_truth: -0.00587463
result: -0.0716248, ground_truth: -0.0723877
result: 0.0582733, ground_truth: 0.059433
result: -0.178482, ground_truth: -0.178116
result: 0.09935, ground_truth: 0.0994568
result: 0.228073, ground_truth: 0.227631
result: 0.0487671, ground_truth: 0.0479126
result: 0.1716, ground_truth: 0.172043
result: -0.0611115, ground_truth: -0.0614624
result: -0.220978, ground_truth: -0.22139
result: 0.176865, ground_truth: 0.174255
result: 0.179092, ground_truth: 0.178909
result: -0.14003, ground_truth: -0.139908
result: 0.053421, ground_truth: 0.053772
result: -0.0392456, ground_truth: -0.0408478
result: 0.0390472, ground_truth: 0.0390167
result: -0.0983429, ground_truth: -0.100479
result: 0.212082, ground_truth: 0.212479
result: 0.220978, ground_truth: 0.221573
result: 0.0145569, ground_truth: 0.0135345
result: -0.0265045, ground_truth: -0.0250702
result: -0.0433044, ground_truth: -0.0426636
result: 0.13295, ground_truth: 0.132416
result: -0.172623, ground_truth: -0.172455
result: -0.0410767, ground_truth: -0.0418549
result: -0.0101166, ground_truth: -0.0123444
result: 0.0631256, ground_truth: 0.0624695
result: 0.126877, ground_truth: 0.125946
result: -0.0718384, ground_truth: -0.0707703
result: -0.118378, ground_truth: -0.117874
result: -0.0147705, ground_truth: -0.0135498
result: -0.0127411, ground_truth: -0.0127411
result: -0.143677, ground_truth: -0.144562
result: 0.202164, ground_truth: 0.201752
result: -0.057663, ground_truth: -0.0566101
result: 0.0999603, ground_truth: 0.0990601
result: -0.0629272, ground_truth: -0.0638885
result: 0.106232, ground_truth: 0.106934
result: -0.0232697, ground_truth: -0.0228577
result: -0.199326, ground_truth: -0.198334
result: 0.00505066, ground_truth: 0.00363159
result: -0.0756836, ground_truth: -0.0738068
result: -0.152176, ground_truth: -0.152649
result: 0.0198212, ground_truth: 0.0198059
result: -0.217545, ground_truth: -0.21492
result: -0.0536194, ground_truth: -0.0531769
result: -0.128296, ground_truth: -0.128784
result: 0.0447235, ground_truth: 0.0448761
result: 0.0137482, ground_truth: 0.0143433
result: 0.105835, ground_truth: 0.104507
result: -0.0273132, ground_truth: -0.0293274
result: 0.140839, ground_truth: 0.141922
result: 0.00444031, ground_truth: 0.00282288
result: -0.110291, ground_truth: -0.109589
result: 0.17363, ground_truth: 0.175278
result: 0.0661621, ground_truth: 0.0679169
result: 0.0435028, ground_truth: 0.0428467
result: 0.0273132, ground_truth: 0.0258636
result: 0.0601044, ground_truth: 0.0578156
result: -0.140839, ground_truth: -0.142746
result: -0.0149689, ground_truth: -0.0163879
result: -0.0789185, ground_truth: -0.0774384
result: -0.00909424, ground_truth: -0.00970459
result: -0.190018, ground_truth: -0.190247
result: 0.0795288, ground_truth: 0.0812683
result: 0.0133514, ground_truth: 0.0135345
result: 0.138214, ground_truth: 0.139282
result: 0.0847931, ground_truth: 0.0838928
result: 0.0764923, ground_truth: 0.0772247
result: -0.0157776, ground_truth: -0.0155792
result: -0.0149689, ground_truth: -0.0163879
result: -0.180908, ground_truth: -0.181351
result: 0.120804, ground_truth: 0.121094
result: -0.116364, ground_truth: -0.117462
result: 0.106445, ground_truth: 0.104721
result: 0.0845795, ground_truth: 0.0848999
result: -0.0562592, ground_truth: -0.055603
result: -0.076889, ground_truth: -0.0782471
result: 0.106033, ground_truth: 0.107346
result: 0.146713, ground_truth: 0.149399
result: 0.214905, ground_truth: 0.216721
result: 0.0127411, ground_truth: 0.0141449
result: -0.0507813, ground_truth: -0.049942
result: 0.0121307, ground_truth: 0.0115204
result: 0.126266, ground_truth: 0.126144
result: 0.138016, ground_truth: 0.138275
result: -0.234131, ground_truth: -0.233505
result: 0.0631256, ground_truth: 0.0628662
result: -0.138214, ground_truth: -0.137482
result: -0.0522003, ground_truth: -0.0533752
result: -0.0380402, ground_truth: -0.0374146
result: -0.0216522, ground_truth: -0.0212402
result: -0.132751, ground_truth: -0.132019
result: -0.105835, ground_truth: -0.105331
result: 0.145294, ground_truth: 0.145752
result: 0.0341949, ground_truth: 0.0333557
result: 0.106842, ground_truth: 0.106339
result: -0.10199, ground_truth: -0.102905
result: -0.0196228, ground_truth: -0.0204315
result: 0.0574646, ground_truth: 0.0570068
result: 0.110291, ground_truth: 0.110977
result: 0.00404358, ground_truth: 0.00444031
result: 0.094696, ground_truth: 0.0937958
result: 0.00708008, ground_truth: 0.00666809
result: 0.0161896, ground_truth: 0.0175781
result: -0.0730438, ground_truth: -0.0731964
result: -0.197708, ground_truth: -0.198532
result: 0.158646, ground_truth: 0.157486
result: 0.202774, ground_truth: 0.203781
result: 0.0400696, ground_truth: 0.0386047
result: -0.202774, ground_truth: -0.204407
result: -0.0115204, ground_truth: -0.0109253
result: -0.0109253, ground_truth: -0.0101166
result: -0.0582733, ground_truth: -0.0572205
result: -0.201752, ground_truth: -0.203995
result: -0.035614, ground_truth: -0.0339661
result: -0.0293427, ground_truth: -0.0291138
result: -0.0311584, ground_truth: -0.0311432
result: -0.115952, ground_truth: -0.115646
result: -0.0497742, ground_truth: -0.0515594
result: 0.248703, ground_truth: 0.249069
result: -0.135376, ground_truth: -0.134445
result: 0.0558472, ground_truth: 0.053772
result: -0.0214386, ground_truth: -0.0234528
result: -0.0938873, ground_truth: -0.0915833
result: 0.0762939, ground_truth: 0.0778351
result: 0.0400696, ground_truth: 0.0396118
result: -0.00646973, ground_truth: -0.006073
result: 0.100174, ground_truth: 0.0998688
result: 0.0734558, ground_truth: 0.0735779
result: -0.0546265, ground_truth: -0.0545959
result: 0.217941, ground_truth: 0.218536
result: 0.023056, ground_truth: 0.0234375
result: -0.138611, ground_truth: -0.138901
result: -0.246277, ground_truth: -0.246658
result: 0.0856018, ground_truth: 0.0834808
result: -0.148941, ground_truth: -0.15062
result: 0.160873, ground_truth: 0.162735
result: 0.0633392, ground_truth: 0.0662994
result: -0.0438995, ground_truth: -0.044281
result: -0.0817566, ground_truth: -0.0818787
result: 0.0983429, ground_truth: 0.0990601
result: -0.0135498, ground_truth: -0.0123444
result: 0.0206299, ground_truth: 0.021225
result: -0.138214, ground_truth: -0.137283
result: 0.0961151, ground_truth: 0.0952148
result: 0.175446, ground_truth: 0.176483
result: 0.0896454, ground_truth: 0.0883331
result: 0.0348053, ground_truth: 0.0345612
result: 0.0853882, ground_truth: 0.0832825
result: -0.145706, ground_truth: -0.146576
result: 0.13942, ground_truth: 0.138275
result: 0.180511, ground_truth: 0.181747
result: -0.0455322, ground_truth: -0.044281
result: -0.09935, ground_truth: -0.100891
result: -0.0914612, ground_truth: -0.0934143
result: -0.150955, ground_truth: -0.151031
result: 0.0370331, ground_truth: 0.0359802
result: -0.0884247, ground_truth: -0.0889587
result: -0.00323486, ground_truth: -0.00102234
result: 0.0214386, ground_truth: 0.0206146
result: 0.0167847, ground_truth: 0.0159607
result: -0.0776978, ground_truth: -0.0786591
result: -0.00201416, ground_truth: -0.00222778
result: -0.0649567, ground_truth: -0.0641022
result: 0.165939, ground_truth: 0.167191
result: -0.0683899, ground_truth: -0.0671234
result: -0.0505829, ground_truth: -0.0495453
result: -0.0149689, ground_truth: -0.0149689
result: 0.0313568, ground_truth: 0.032135
result: 0.101181, ground_truth: 0.100677
result: -0.199127, ground_truth: -0.198532
result: -0.0856018, ground_truth: -0.086731
result: 0.13092, ground_truth: 0.131805
result: -0.139023, ground_truth: -0.140717
result: 0.0625305, ground_truth: 0.0630646
result: 0.0967255, ground_truth: 0.0966339
result: 0.158249, ground_truth: 0.157288
result: 0.136795, ground_truth: 0.137268
result: -0.00404358, ground_truth: -0.00202942
result: 0.0216522, ground_truth: 0.0238495
result: -0.14975, ground_truth: -0.150833
result: -0.0153656, ground_truth: -0.0171967
result: 0.225632, ground_truth: 0.227234
result: -0.082962, ground_truth: -0.0834961
result: 0.242233, ground_truth: 0.240982
result: 0.192856, ground_truth: 0.194077
result: 0.124252, ground_truth: 0.12413
result: -0.0722351, ground_truth: -0.071167
result: 0.0526123, ground_truth: 0.0523529
result: -0.00363159, ground_truth: -0.0030365
result: -0.0354004, ground_truth: -0.0366058
result: -0.346054, ground_truth: -0.345306
result: 0.00970459, ground_truth: 0.0101013
result: 0.0965271, ground_truth: 0.0960236
result: -0.0226593, ground_truth: -0.0214386
result: -0.017807, ground_truth: -0.016983
result: -0.0783081, ground_truth: -0.0776367
result: 0.122421, ground_truth: 0.120895
result: -0.0435028, ground_truth: -0.0444794
result: -0.141449, ground_truth: -0.143143
result: -0.0107117, ground_truth: -0.00950623
result: -0.0105133, ground_truth: -0.0105133
result: 0.0979462, ground_truth: 0.097641
result: 0.0839844, ground_truth: 0.0850983
result: 0.0653534, ground_truth: 0.0661011
result: 0.0671844, ground_truth: 0.0673218
result: 0.0639496, ground_truth: 0.0648956
result: 0.297485, ground_truth: 0.29921
result: -0.333298, ground_truth: -0.333588
result: -0.277451, ground_truth: -0.276367
result: 0.0524139, ground_truth: 0.0507355
result: -0.0957184, ground_truth: -0.0964355
result: -0.0384369, ground_truth: -0.03862
result: 0.204391, ground_truth: 0.202362
result: 0.211884, ground_truth: 0.212265
result: -0.0882263, ground_truth: -0.0877533
result: 0.151367, ground_truth: 0.151016
result: -0.0942993, ground_truth: -0.0952301
result: -0.0455322, ground_truth: -0.0434723
result: -0.00323486, ground_truth: -0.00364685
result: 0.0641479, ground_truth: 0.0648956
result: -0.183136, ground_truth: -0.183578
result: -0.094696, ground_truth: -0.0956268
result: -0.0509949, ground_truth: -0.0493317
result: -0.17099, ground_truth: -0.170441
result: 0.147522, ground_truth: 0.145157
result: 0.33046, ground_truth: 0.331146
result: 0.0390472, ground_truth: 0.0371857
result: -0.261047, ground_truth: -0.259995
result: 0.0866089, ground_truth: 0.0855103
result: -0.336945, ground_truth: -0.336212
result: -0.041687, ground_truth: -0.0412445
result: -0.268539, ground_truth: -0.269089
result: -0.270157, ground_truth: -0.270706
result: 0.113724, ground_truth: 0.11058
result: -0.196289, ground_truth: -0.195908
result: 0.0617218, ground_truth: 0.0618591
result: 0.0376282, ground_truth: 0.0398254
result: -0.121826, ground_truth: -0.121506
result: -0.0317688, ground_truth: -0.0315399
result: -0.100174, ground_truth: -0.10231
result: 0.223404, ground_truth: 0.222992
result: -0.127899, ground_truth: -0.12738
result: -0.159256, ground_truth: -0.156693
result: -0.141449, ground_truth: -0.141327
result: 0.273605, ground_truth: 0.272919
result: -0.103806, ground_truth: -0.103928
result: -0.0623169, ground_truth: -0.0630798
result: 0.105225, ground_truth: 0.104721
result: 0.075882, ground_truth: 0.0778351
result: 0.0424957, ground_truth: 0.0426483
result: 0.0938873, ground_truth: 0.0927887
result: 0.0109253, ground_truth: 0.00909424
result: -0.0627289, ground_truth: -0.0628815
result: -0.12648, ground_truth: -0.124542
result: 0.00950623, ground_truth: 0.0101013
result: -0.202972, ground_truth: -0.202988
result: 0.227859, ground_truth: 0.226425
result: -0.0562592, ground_truth: -0.0574188
result: -0.0787201, ground_truth: -0.0780487
result: -0.0479584, ground_truth: -0.0471191
result: -0.0275116, ground_truth: -0.0281067
result: -0.119598, ground_truth: -0.118881
result: -0.0285339, ground_truth: -0.0299225
result: 0.14975, ground_truth: 0.149994
result: -0.106033, ground_truth: -0.107361
result: -0.0987549, ground_truth: -0.0996704
result: -0.094696, ground_truth: -0.094223
result: -0.100769, ground_truth: -0.099472
result: 0.0550385, ground_truth: 0.0563965
result: 0.0202332, ground_truth: 0.0210114
result: 0.0981445, ground_truth: 0.0998688
result: -0.0236664, ground_truth: -0.0232544
result: 0.0641479, ground_truth: 0.0652924
result: -0.193665, ground_truth: -0.194702
result: 0.0750732, ground_truth: 0.0731812
result: -0.201157, ground_truth: -0.199753
result: -0.076889, ground_truth: -0.0778503
result: 0.128098, ground_truth: 0.128983
result: -0.0141602, ground_truth: -0.0137482
result: -0.215927, ground_truth: -0.214706
result: 0.0584717, ground_truth: 0.0586243
result: -0.0200348, ground_truth: -0.0184021
result: 0.215118, ground_truth: 0.215103
result: -0.322372, ground_truth: -0.322067
result: -0.160065, ground_truth: -0.161331
result: 0.158249, ground_truth: 0.1595
result: -0.153595, ground_truth: -0.153458
result: 0.129105, ground_truth: 0.127151
result: -0.0420837, ground_truth: -0.0402374
result: -0.0601044, ground_truth: -0.0604553
result: 0.112305, ground_truth: 0.112396
result: -0.113724, ground_truth: -0.112823
result: 0.126068, ground_truth: 0.124725
result: 0.0285339, ground_truth: 0.0301208
result: -0.128708, ground_truth: -0.126968
result: -0.0103149, ground_truth: -0.0111237
result: 0.0874176, ground_truth: 0.0875244
result: -0.0912628, ground_truth: -0.0903778
result: 0.0447235, ground_truth: 0.0464935
result: 0.0317688, ground_truth: 0.0309296
result: 0.0675812, ground_truth: 0.0662994
result: -0.103607, ground_truth: -0.101898
result: 0.113922, ground_truth: 0.114212
result: 0.118378, ground_truth: 0.117661
result: -0.330673, ground_truth: -0.33136
result: 0.0938873, ground_truth: 0.0931854
result: 0.0781097, ground_truth: 0.0794373
result: 0.0493774, ground_truth: 0.0507355
result: 0.119385, ground_truth: 0.118469
result: -0.306992, ground_truth: -0.304672
result: -0.225632, ground_truth: -0.226242
result: -0.13942, ground_truth: -0.139297
result: 0.0740662, ground_truth: 0.0721741
result: -0.0350037, ground_truth: -0.0331573
result: 0.0137482, ground_truth: 0.0135345
result: 0.190018, ground_truth: 0.187408
result: 0.0536194, ground_truth: 0.0527649
result: -0.247498, ground_truth: -0.247665
result: 0.138214, ground_truth: 0.137268
result: 0.158447, ground_truth: 0.159103
result: 0.134979, ground_truth: 0.13504
result: -0.145493, ground_truth: -0.146378
result: -0.136993, ground_truth: -0.135468
result: -0.0914612, ground_truth: -0.0921936
result: -0.199127, ground_truth: -0.199341
result: 0.110489, ground_truth: 0.111588
result: -0.015976, ground_truth: -0.0163879
result: -0.0105133, ground_truth: -0.0105133
result: 0.151169, ground_truth: 0.151413
result: -0.119186, ground_truth: -0.118484
result: 0.046936, ground_truth: 0.0464935
result: -0.0018158, ground_truth: -0.00141907
result: -0.100174, ground_truth: -0.100082
result: -0.113113, ground_truth: -0.113022
result: 0.101181, ground_truth: 0.102295
result: -0.0639496, ground_truth: -0.0646973
result: -0.19043, ground_truth: -0.191467
result: -0.0190125, ground_truth: -0.0194092
result: -0.152374, ground_truth: -0.153656
result: -0.0631256, ground_truth: -0.0624847
result: -0.0783081, ground_truth: -0.0776367
result: 0.161087, ground_truth: 0.161728
result: -0.0605011, ground_truth: -0.0588379
result: 0.145493, ground_truth: 0.144745
result: -0.214096, ground_truth: -0.213699
result: 0.094696, ground_truth: 0.0964203
result: -0.057663, ground_truth: -0.0600586
result: -0.0244751, ground_truth: -0.0238647
result: -0.21875, ground_truth: -0.217133
result: -0.116364, ground_truth: -0.11525
result: -0.0532227, ground_truth: -0.0537872
result: 0.217941, ground_truth: 0.219757
result: -0.0345917, ground_truth: -0.0355835
result: -0.0354004, ground_truth: -0.0345764
result: 0.230499, ground_truth: 0.231476
result: -0.0584717, ground_truth: -0.0590363
result: 0.199127, ground_truth: 0.201752
result: -0.137405, ground_truth: -0.136871
result: 0.104019, ground_truth: 0.104507
result: -0.118378, ground_truth: -0.117676
result: -0.0428925, ground_truth: -0.0430756
result: 0.0667725, ground_truth: 0.0675201
result: 0.0851898, ground_truth: 0.0847015
result: -0.09935, ground_truth: -0.100479
result: 0.128494, ground_truth: 0.128372
result: 0.132751, ground_truth: 0.131409
result: 0.0864105, ground_truth: 0.0848999
result: -0.310837, ground_truth: -0.310944
result: 0.0455322, ground_truth: 0.043869
result: -0.0198212, ground_truth: -0.0204315
result: -0.00221252, ground_truth: -0.00404358
result: -0.134171, ground_truth: -0.135864
result: 0.150146, ground_truth: 0.150208
result: -0.0499725, ground_truth: -0.0481262
result: 0.0714264, ground_truth: 0.0715637
result: -0.041687, ground_truth: -0.0422668
result: -0.1026, ground_truth: -0.100891
result: 0.0979462, ground_truth: 0.097641
result: -0.272583, ground_truth: -0.272736
result: -0.238785, ground_truth: -0.240387

[32mRMSE: [0m0.0011349
[35mattention           : [0m[35m     1 calls; [0m[35m 21.389 msecs total time
[0mINFO: [COSIM 212-1000] *** C/RTL co-simulation finished: PASS ***
INFO: [COSIM 212-211] II is measurable only when transaction number is greater than 1 in RTL simulation. Otherwise, they will be marked as all NA. If user wants to calculate them, please make sure there are at least 2 transactions in RTL simulation.
INFO: [HLS 200-112] Total elapsed time: 310.17 seconds; peak allocated memory: 730.585 MB.
INFO: [Common 17-206] Exiting vivado_hls at Thu Nov 28 18:20:34 2024...
