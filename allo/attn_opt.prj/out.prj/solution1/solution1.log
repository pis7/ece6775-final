==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:35 ; elapsed = 00:00:38 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 621320 ; free virtual = 759612
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:35 ; elapsed = 00:00:38 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 621320 ; free virtual = 759612
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:42 ; elapsed = 00:00:45 . Memory (MB): peak = 1296.152 ; gain = 658.125 ; free physical = 621149 ; free virtual = 759467
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:399) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:598) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:45 ; elapsed = 00:00:48 . Memory (MB): peak = 1302.082 ; gain = 664.055 ; free physical = 621097 ; free virtual = 759423
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:459) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:475) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:480) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:486) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:492) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6.1' (kernel.cpp:529) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-7.1' (kernel.cpp:537) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:573) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j9' (kernel.cpp:583) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-12' (kernel.cpp:593) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-12.1' (kernel.cpp:594) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_3_i11' (kernel.cpp:600) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j10' (kernel.cpp:601) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-14.1' (kernel.cpp:611) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:620) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-16' (kernel.cpp:628) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_6_s4' (kernel.cpp:633) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18' (kernel.cpp:642) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:658) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-20' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:422) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:373) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:381) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:361) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:362) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:343) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:259) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:267) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:276) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:236) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:221) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:133) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:137) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:459) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:475) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:480) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:486) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:492) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6.1' (kernel.cpp:529) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-7.1' (kernel.cpp:537) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:573) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j9' (kernel.cpp:583) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-12' (kernel.cpp:593) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-12.1' (kernel.cpp:594) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_3_i11' (kernel.cpp:600) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j10' (kernel.cpp:601) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-14.1' (kernel.cpp:611) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:620) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-16' (kernel.cpp:628) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_6_s4' (kernel.cpp:633) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18' (kernel.cpp:642) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:658) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-20' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:422) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:373) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:381) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:361) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:362) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:343) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:259) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:267) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:276) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:236) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:221) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:133) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:139) in function 'linear_forward_no_mul' completely with a factor of 8.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:155) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:257) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:265) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v214.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:458) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:474) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:527) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:535) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:571) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:592) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:609) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:618) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:641) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:657) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:592) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:399) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:137:53) to (kernel.cpp:137:46) in function 'linear_forward_no_mul'... converting 65 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:50 ; elapsed = 00:00:54 . Memory (MB): peak = 1382.086 ; gain = 744.059 ; free physical = 620984 ; free virtual = 759326
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:134:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:327:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:133:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v197' (kernel.cpp:331:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0]' (kernel.cpp:376:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0]' (kernel.cpp:410:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0]' (kernel.cpp:400:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v146[0]' (kernel.cpp:240:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v146[0]' (kernel.cpp:242:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v140[0]' (kernel.cpp:225:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v187' (kernel.cpp:311:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v187' (kernel.cpp:316:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:461:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:482:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:488:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:494:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:531:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:539:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:548:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:556:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:575:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:588:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:605:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:613:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:622:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:630:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:644:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:261:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:269:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v157[0]' (kernel.cpp:285:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v158[0]' (kernel.cpp:293:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v246[0]' (kernel.cpp:430:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v204[0]' (kernel.cpp:351:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:08 ; elapsed = 00:01:12 . Memory (MB): peak = 1568.156 ; gain = 930.129 ; free physical = 620882 ; free virtual = 759228
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 72.69 seconds; current allocated memory: 532.063 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 533.417 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 533.816 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 534.294 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.34 seconds; current allocated memory: 534.877 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 535.438 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_7', kernel.cpp:204) and 'select' operation ('select_ln150', kernel.cpp:150).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_7', kernel.cpp:204) and 'select' operation ('select_ln150', kernel.cpp:150).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 3, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_7', kernel.cpp:204) and 'select' operation ('select_ln150', kernel.cpp:150).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 4, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_7', kernel.cpp:204) and 'select' operation ('select_ln150', kernel.cpp:150).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 19, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_7', kernel.cpp:204) and 'select' operation ('select_ln150', kernel.cpp:150).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 27, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_7', kernel.cpp:204) and 'select' operation ('select_ln150', kernel.cpp:150).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 31, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_7', kernel.cpp:204) and 'select' operation ('select_ln150', kernel.cpp:150).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 32, Depth = 69.
WARNING: [SCHED 204-21] Estimated clock period (15.789ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'linear_forward_no_mu' consists of the following:
	'load' operation ('v80_load', kernel.cpp:150) on array 'v80' [57]  (3.25 ns)
	'icmp' operation ('icmp_ln179', kernel.cpp:179) [59]  (0.959 ns)
	'select' operation ('select_ln179', kernel.cpp:179) [61]  (0 ns)
	'select' operation ('select_ln179_1', kernel.cpp:179) [63]  (0.993 ns)
	'mul' operation ('mul_ln195', kernel.cpp:195) [67]  (4.17 ns)
	'sitofp' operation ('v1', kernel.cpp:196) [69]  (6.41 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.78 seconds; current allocated memory: 537.667 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.94 seconds; current allocated memory: 540.698 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.05 seconds; current allocated memory: 541.177 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 541.328 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 541.471 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 541.632 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 541.942 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 542.418 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 542.740 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 543.064 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 543.239 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 543.458 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 543.683 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 543.938 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 544.277 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 544.911 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 545.283 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 545.536 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 546.616 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.86 seconds; current allocated memory: 549.610 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 1.35 seconds; current allocated memory: 553.427 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 0.98 seconds; current allocated memory: 559.903 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 561.927 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_sitofp_32s_32_6_1' to 'attention_sitofp_tde' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sitofp_tde': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 568.386 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 1.78 seconds; current allocated memory: 578.423 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 579.291 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_udo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.43 seconds; current allocated memory: 580.747 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.64 seconds; current allocated memory: 582.959 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 584.646 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.43 seconds; current allocated memory: 586.001 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuwdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuwdI': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.51 seconds; current allocated memory: 588.051 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.74 seconds; current allocated memory: 590.443 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v256' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v258' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v260' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v262' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizxdS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_yd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_hidden_states_0' to 'attention_rms_hidAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_k_cache' to 'attention_updatedBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_v_cache' to 'attention_updatedCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_weights_0' to 'attention_attn_weDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_softmax_attn_weights' to 'attention_softmaxEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_0' to 'attention_attn_ouFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_2D' to 'attention_attn_ouGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_attn_output_0' to 'attention_rms_attHfu' due to the length limit 20
WARNING: [RTGEN 206-101] Port 'attention/v271' has no fanin or fanout and is left dangling.
               Please use C simulation to confirm this function argument can be read from or written to.
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'attention'.
INFO: [HLS 200-111]  Elapsed time: 0.86 seconds; current allocated memory: 594.541 MB.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were NOT satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 63.34 MHz
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_41nibs_MulnS_0'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_44njbC_MulnS_1'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_45nkbM_MulnS_2'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_43slbW_MulnS_3'
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatbkb_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatcud_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatdEe_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floateOg_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatfYi_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatg8j_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floathbi_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'apply_rotary_pos_udo_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_quantizxdS_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_q_proj_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_v_proj_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_k_proj_yd2_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_rms_hidAem_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_updatedBew_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_attn_weDeQ_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:01:26 ; elapsed = 00:01:40 . Memory (MB): peak = 1568.156 ; gain = 930.129 ; free physical = 620757 ; free virtual = 759139
INFO==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
ERROR: [HLS 200-70] Compilation errors found: In file included from kernel.cpp:1:
kernel.cpp:582:3: error: use of undeclared identifier 'GEMM_3D_ap_fixed'
  GEMM_3D_ap_fixed<32, 20>(q_embed, k_proj_transposed, attn_weights);
  ^
kernel.cpp:582:28: warning: expression result unused [-Wunused-value]
  GEMM_3D_ap_fixed<32, 20>(q_embed, k_proj_transposed, attn_weights);
                           ^~~~~~~
kernel.cpp:582:37: warning: expression result unused [-Wunused-value]
  GEMM_3D_ap_fixed<32, 20>(q_embed, k_proj_transposed, attn_weights);
                                    ^~~~~~~~~~~~~~~~~
kernel.cpp:582:26: error: comparison between pointer and integer ('int' and 'ap_fixed<32, 20> (*)[1][6]')
  GEMM_3D_ap_fixed<32, 20>(q_embed, k_proj_transposed, attn_weights);
                       ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
kernel.cpp:629:3: error: use of undeclared identifier 'GEMM_3D_ap_fixed'
  GEMM_3D_ap_fixed<32, 20>2(softmax_attn_weights, updated_v_cache, attn_output);
  ^
kernel.cpp:629:28: error: called object type 'int' is not a function or function pointer
  GEMM_3D_ap_fixed<32, 20>2(softmax_attn_weights, updated_v_cache, attn_output);
                          ~^
In file included from kernel.cpp:1:
In file included from kernel.cpp:8:
In file included from /opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_axi_sdata.h:86:
In file included from /opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_int.h:367:
In file included from /opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_fixed.h:55:
/opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_fixed_base.h:838:13: warning: shift count is negative [-Wshift-count-negative]
      ret.V <<= (_AP_I - _AP_W);
            ^   ~~~~~~~~~~~~~~~
/opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_fixed_base.h:869:69: note: in instantiation of member function 'ap_fixed_base<32, 20, true, 5, 3, 0>::to_ap_int_base' requested here
  inline __attribute__((always_inline)) int to_int() const { return to_ap_int_base().to_int(); }
                                                                    ^
/opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_fixed_base.h:1042:71: note: in instantiation of member function 'ap_fixed_base<32, 20, true, 5, 3, 0>::to_int' requested here
  inline __attribute__((always_inline)) operator int() const { return to_int(); }
                                                                      ^
kernel.cpp:106:23: note: in instantiation of member function 'ap_fixed_base<32, 20, true, 5, 3, 0>::operator int' requested here
        int32_t v66 = v65;
                      ^
3 warnings and 4 errors generated.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
ERROR: [HLS 200-70] Compilation errors found: In file included from kernel.cpp:1:
kernel.cpp:582:3: error: use of undeclared identifier 'GEMM_3D_ap_fixed'
  GEMM_3D_ap_fixed<32, 20>(q_embed, k_proj_transposed, attn_weights);
  ^
kernel.cpp:582:28: warning: expression result unused [-Wunused-value]
  GEMM_3D_ap_fixed<32, 20>(q_embed, k_proj_transposed, attn_weights);
                           ^~~~~~~
kernel.cpp:582:37: warning: expression result unused [-Wunused-value]
  GEMM_3D_ap_fixed<32, 20>(q_embed, k_proj_transposed, attn_weights);
                                    ^~~~~~~~~~~~~~~~~
kernel.cpp:582:26: error: comparison between pointer and integer ('int' and 'ap_fixed<32, 20> (*)[1][6]')
  GEMM_3D_ap_fixed<32, 20>(q_embed, k_proj_transposed, attn_weights);
                       ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
In file included from kernel.cpp:1:
In file included from kernel.cpp:8:
In file included from /opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_axi_sdata.h:86:
In file included from /opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_int.h:367:
In file included from /opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_fixed.h:55:
/opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_fixed_base.h:838:13: warning: shift count is negative [-Wshift-count-negative]
      ret.V <<= (_AP_I - _AP_W);
            ^   ~~~~~~~~~~~~~~~
/opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_fixed_base.h:869:69: note: in instantiation of member function 'ap_fixed_base<32, 20, true, 5, 3, 0>::to_ap_int_base' requested here
  inline __attribute__((always_inline)) int to_int() const { return to_ap_int_base().to_int(); }
                                                                    ^
/opt/xilinx/Vivado/2019.2/common/technology/autopilot/ap_fixed_base.h:1042:71: note: in instantiation of member function 'ap_fixed_base<32, 20, true, 5, 3, 0>::to_int' requested here
  inline __attribute__((always_inline)) operator int() const { return to_int(); }
                                                                      ^
kernel.cpp:106:23: note: in instantiation of member function 'ap_fixed_base<32, 20, true, 5, 3, 0>::operator int' requested here
        int32_t v66 = v65;
                      ^
3 warnings and 2 errors generated.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:01:06 ; elapsed = 00:01:10 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 621409 ; free virtual = 759731
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:01:06 ; elapsed = 00:01:10 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 621409 ; free virtual = 759731
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<ap_fixed<32, 20, (ap_q_mode)5, (ap_o_mode)3, 0> >' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:01:15 ; elapsed = 00:01:20 . Memory (MB): peak = 1424.152 ; gain = 786.125 ; free physical = 621110 ; free virtual = 759478
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 68, 60>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 60, 55>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:350) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 55, 50>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:352) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 17, 6, 50, 45>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:354) automatically.
INFO: [XFORM 203-602] Inlining function 'fabs_fixed<33, 21>' into 'pow_apfixed_reduce::pow<32, 20>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_pow_apfixed.h:94) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::pow<32, 20>' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::pow<32, 20>' into 'softmax' (kernel.cpp:402) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:601) automatically.
WARNING: [SYNCHK 200-23] /opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_pow_apfixed.h:75: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:01:20 ; elapsed = 00:01:24 . Memory (MB): peak = 1434.117 ; gain = 796.090 ; free physical = 621008 ; free virtual = 759394
INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'log_apfixed_reduce::log<75, 21>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:500:9).
INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'exp_reduce::exp_core<32, 20, 54>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:873:30).
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:462) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:483) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:489) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:495) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6.1' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-7.1' (kernel.cpp:513) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-8.1' (kernel.cpp:521) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:532) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:540) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-14.1' (kernel.cpp:576) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j9' (kernel.cpp:586) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-16' (kernel.cpp:596) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-16.1' (kernel.cpp:597) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_3_i11' (kernel.cpp:603) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j10' (kernel.cpp:604) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:614) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19.1' (kernel.cpp:623) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-20' (kernel.cpp:631) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_6_s4' (kernel.cpp:636) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:661) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-24' (kernel.cpp:665) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:425) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:376) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:364) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:365) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:346) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:262) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:279) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:239) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:224) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:136) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:140) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:729) in function 'log_apfixed_reduce::log<75, 21>' completely with a factor of 75.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1310) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 19.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1317) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 46.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1512) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1518) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1521) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 42.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:462) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:483) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:489) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:495) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6.1' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-7.1' (kernel.cpp:513) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-8.1' (kernel.cpp:521) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:532) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:540) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-14.1' (kernel.cpp:576) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j9' (kernel.cpp:586) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-16' (kernel.cpp:596) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-16.1' (kernel.cpp:597) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_3_i11' (kernel.cpp:603) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j10' (kernel.cpp:604) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:614) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19.1' (kernel.cpp:623) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-20' (kernel.cpp:631) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_6_s4' (kernel.cpp:636) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:661) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-24' (kernel.cpp:665) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:425) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:376) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:364) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:365) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:346) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:262) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:279) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:239) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:224) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:136) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:142) in function 'linear_forward_no_mul' completely with a factor of 16.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:158) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q.V' (kernel.cpp:260) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k.V' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v214.V.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states.V' (kernel.cpp:461) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales.V' (kernel.cpp:477) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed.V' (kernel.cpp:530) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed.V' (kernel.cpp:538) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights.V' (kernel.cpp:574) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.V' (kernel.cpp:595) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights.V' (kernel.cpp:612) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output.V' (kernel.cpp:621) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output.V' (kernel.cpp:644) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales.V' (kernel.cpp:660) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.V.0' (kernel.cpp:595) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj.V' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj.V' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj.V' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states'  in dimension 2 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output'  in dimension 2 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'v261' (kernel.cpp:446) in dimension 1 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'v259' (kernel.cpp:444) in dimension 1 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'v257' (kernel.cpp:442) in dimension 1 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'v263' (kernel.cpp:448) in dimension 1 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output'  in dimension 3 completely.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.5.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.5.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.5.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.5.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.6.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.6.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.6.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.6.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.7.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.7.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.7.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.7.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.8.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.8.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.8.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.8.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.9.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.9.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.9.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.9.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.10.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.10.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.10.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.10.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.11.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.11.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.11.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.11.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.12.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.12.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.12.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.12.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.13.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.13.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.13.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.13.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.14.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.14.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.14.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.14.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.15.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.15.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.15.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.15.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.5.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.5.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.5.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.5.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.6.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.6.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.6.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.6.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.7.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.7.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.7.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.7.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.8.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.8.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.8.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.8.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.9.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.9.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.9.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.9.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.10.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.10.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.10.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.10.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.11.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.11.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.11.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.11.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.12.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.12.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.12.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.12.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.13.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.13.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.13.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.13.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.14.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.14.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.14.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.14.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.15.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.15.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.15.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.15.3' in dimension 1 automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 68, 60>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 60, 55>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:350) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 55, 50>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:352) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 17, 6, 50, 45>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:354) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' into 'log_apfixed_reduce::log<75, 21>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:771) automatically.
INFO: [XFORM 203-602] Inlining function 'fabs_fixed<33, 21>' into 'pow_apfixed_reduce::pow<32, 20>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_pow_apfixed.h:94) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::pow<32, 20>' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::pow<32, 20>' into 'softmax' (kernel.cpp:402) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:601) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:98:47) to (kernel.cpp:120:9) in function 'quantize_activation'... converting 3 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:727:44) to (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:747:17) in function 'log_apfixed_reduce::log<75, 21>'... converting 76 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:140:53) to (kernel.cpp:140:46) in function 'linear_forward_no_mul'... converting 369 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:873:1) to (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1993:5) in function 'exp_reduce::exp_core<32, 20, 54>'... converting 5 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'log_apfixed_reduce::log<75, 21>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:178:90)...11 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...64 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'exp_reduce::exp_core<32, 20, 54>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:873:5)...22 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:01:29 ; elapsed = 00:01:35 . Memory (MB): peak = 1584.156 ; gain = 946.129 ; free physical = 620827 ; free virtual = 759240
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'l_S_j_0_j2' (kernel.cpp:137:52) in function 'linear_forward_no_mul' : 

the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:330:45)
WARNING: [XFORM 203-631] Renaming function 'pow_apfixed_reduce::pow<32, 20>' to 'pow<32, 20>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_pow_apfixed.h:63:29)
WARNING: [XFORM 203-631] Renaming function 'log_apfixed_reduce::log<75, 21>' to 'log<75, 21>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:178:90)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:136:46)
WARNING: [XFORM 203-631] Renaming function 'exp_reduce::exp_core<32, 20, 54>' to 'exp_core<32, 20, 54>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:873:5)
INFO: [HLS 200-472] Inferring partial write operation for 'v197.V' (kernel.cpp:334:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0].V' (kernel.cpp:379:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0].V' (kernel.cpp:403:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0].V' (kernel.cpp:413:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v146[0].V' (kernel.cpp:243:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v146[0].V' (kernel.cpp:245:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0].V' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v140[0].V' (kernel.cpp:228:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0][0][0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v187.V' (kernel.cpp:314:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v187.V' (kernel.cpp:319:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:464:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re.V' (kernel.cpp:485:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re.V' (kernel.cpp:491:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re.V' (kernel.cpp:497:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0].V' (kernel.cpp:534:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0].V' (kernel.cpp:542:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache.V' (kernel.cpp:551:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache.V' (kernel.cpp:559:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0].V' (kernel.cpp:578:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0].V' (kernel.cpp:591:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:616:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0].V' (kernel.cpp:625:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D.V' (kernel.cpp:633:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D.V' (kernel.cpp:640:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0].V' (kernel.cpp:647:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0].V' (kernel.cpp:264:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0].V' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v157[0].V' (kernel.cpp:288:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v158[0].V' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v246[0].V' (kernel.cpp:433:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v204[0].V' (kernel.cpp:354:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:51 ; elapsed = 00:01:57 . Memory (MB): peak = 1840.156 ; gain = 1202.129 ; free physical = 620628 ; free virtual = 759050
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'log<75, 21>' to 'log_75_21_s'.
WARNING: [SYN 201-103] Legalizing function name 'exp_core<32, 20, 54>' to 'exp_core_32_20_54_s'.
WARNING: [SYN 201-103] Legalizing function name 'pow<32, 20>' to 'pow_32_20_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'log_75_21_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'log<75, 21>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 30.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 117.59 seconds; current allocated memory: 786.423 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.16 seconds; current allocated memory: 790.046 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'exp_core_32_20_54_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'exp_core<32, 20, 54>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 13.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.44 seconds; current allocated memory: 791.112 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 791.783 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_32_20_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 792.227 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 793.056 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.64 seconds; current allocated memory: 793.783 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 794.224 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.65 seconds; current allocated memory: 795.600 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 796.981 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 6.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.08 seconds; current allocated memory: 800.874 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 2.32 seconds; current allocated memory: 806.496 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 2.53 seconds; current allocated memory: 807.371 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 807.523 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 807.634 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 807.808 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 808.139 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 808.544 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 808.839 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 809.159 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 809.333 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 809.552 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 809.794 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 810.032 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 810.367 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 810.975 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.66 seconds; current allocated memory: 811.648 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 811.886 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 813.010 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 4.27 seconds; current allocated memory: 818.958 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'log_75_21_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_6' to 'log_75_21_s_log_abkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_5' to 'log_75_21_s_log_acud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_9' to 'log_75_21_s_log_adEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_s' to 'log_75_21_s_log_aeOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_7' to 'log_75_21_s_log_afYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_8' to 'log_75_21_s_log_ag8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_85ns_6ns_91_5_1' to 'attention_mul_85nhbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_68ns_4ns_72_5_1' to 'attention_mul_68nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_60ns_6ns_66_5_1' to 'attention_mul_60njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_55ns_6ns_61_2_1' to 'attention_mul_55nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_7s_68ns_73_5_1' to 'attention_mul_7s_lbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_50ns_6ns_56_2_1' to 'attention_mul_50nmb6' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_50nmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_55nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_60njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_68nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_7s_lbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_85nhbi': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'log_75_21_s'.
INFO: [HLS 200-111]  Elapsed time: 2.57 seconds; current allocated memory: 827.454 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'exp_core_32_20_54_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'exp_core_32_20_54_s_f_x_msb_4_table_V' to 'exp_core_32_20_54ncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'exp_core_32_20_54_s_f_x_msb_3_table_V' to 'exp_core_32_20_54ocq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'exp_core_32_20_54_s_f_x_msb_2_table_V' to 'exp_core_32_20_54pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'exp_core_32_20_54_s_exp_x_msb_1_table_V' to 'exp_core_32_20_54qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_36ns_44ns_80_3_1' to 'attention_mul_36nrcU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_48ns_50ns_98_2_1' to 'attention_mul_48nsc4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_50ns_50ns_100_2_1' to 'attention_mul_50ntde' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_36nrcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_48nsc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_50ntde': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'exp_core_32_20_54_s'.
INFO: [HLS 200-111]  Elapsed time: 2.59 seconds; current allocated memory: 841.988 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_32_20_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_60s_32s_92_5_1' to 'attention_mul_60sudo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_60sudo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_32_20_s'.
INFO: [HLS 200-111]  Elapsed time: 0.77 seconds; current allocated memory: 845.674 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_46ns_44s_89_2_1' to 'attention_mul_46nvdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_27ns_32ns_32_31_seq_1' to 'attention_sdiv_27wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_46nvdy': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_27wdI': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.03 seconds; current allocated memory: 848.606 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_udiv_32ns_32ns_32_36_seq_1' to 'attention_udiv_32xdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_udiv_32xdS': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.94 seconds; current allocated memory: 851.828 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_43ns_32s_32_47_seq_1' to 'attention_sdiv_43yd2' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_43yd2': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 1.18 seconds; current allocated memory: 864.906 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 4.13 seconds; current allocated memory: 886.770 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.72 seconds; current allocated memory: 887.656 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0_V' to 'apply_rotary_pos_zec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0_V' to 'apply_rotary_pos_Aem' due to the length limit 20
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.78 seconds; current allocated memory: 889.041 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.9 seconds; current allocated memory: 891.295 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.85 seconds; current allocated memory: 892.949 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.75 seconds; current allocated memory: 894.208 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_44ns_32s_32_48_seq_1' to 'attention_sdiv_44Bew' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_44Bew': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.79 seconds; current allocated memory: 896.235 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 1.29 seconds; current allocated memory: 898.635 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v256_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v258_V' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v260_V' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v262_V' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_V' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_63' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_62' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_61' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_60' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_59' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_58' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_57' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_56' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_31' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_30' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_29' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_28' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_27' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_26' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_25' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_24' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_23' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_22' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_21' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_20' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_19' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_18' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_17' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantiz5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantiz7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantiz8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantiz9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantizbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantizbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantizbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizbdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizbek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizbfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_55' to 'attention_quantizbgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_54' to 'attention_quantizbhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_53' to 'attention_quantizbil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_52' to 'attention_quantizbjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_51' to 'attention_quantizbkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_50' to 'attention_quantizbll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_49' to 'attention_quantizbml' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_48' to 'attention_quantizbnm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_47' to 'attention_quantizbom' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_46' to 'attention_quantizbpm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_45' to 'attention_quantizbqm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_44' to 'attention_quantizbrm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_43' to 'attention_quantizbsm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_42' to 'attention_quantizbtn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_41' to 'attention_quantizbun' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_40' to 'attention_quantizbvn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_39' to 'attention_quantizbwn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_38' to 'attention_quantizbxn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_37' to 'attention_quantizbyn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_36' to 'attention_quantizbzo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_35' to 'attention_quantizbAo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_34' to 'attention_quantizbBo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_33' to 'attention_quantizbCo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_32' to 'attention_quantizbDo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_q_proj_V_0' to 'attention_q_proj_bEo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_V_0' to 'attention_k_proj_bFp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_v_proj_V_0' to 'attention_v_proj_bGp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed_V' to 'attention_k_proj_bHp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_63' to 'attention_quantizbIp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_62' to 'attention_quantizbJp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_61' to 'attention_quantizbKp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_60' to 'attention_quantizbLp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_59' to 'attention_quantizbMq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_58' to 'attention_quantizbNq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_57' to 'attention_quantizbOq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_56' to 'attention_quantizbPq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_31' to 'attention_quantizbQq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_30' to 'attention_quantizbRq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_29' to 'attention_quantizbSr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_28' to 'attention_quantizbTr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_27' to 'attention_quantizbUr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_26' to 'attention_quantizbVr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_25' to 'attention_quantizbWr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_24' to 'attention_quantizbXr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_23' to 'attention_quantizbYs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_22' to 'attention_quantizbZs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_21' to 'attention_quantizb0s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_20' to 'attention_quantizb1s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_19' to 'attention_quantizb2s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_18' to 'attention_quantizb3s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_17' to 'attention_quantizb4t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_16' to 'attention_quantizb5t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_15' to 'attention_quantizb6t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_14' to 'attention_quantizb7t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_13' to 'attention_quantizb8t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_12' to 'attention_quantizb9t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_11' to 'attention_quantizcau' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_10' to 'attention_quantizcbu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_9' to 'attention_quantizccu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizcdu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizceu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantizcfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantizcgu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizchv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizciv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizcjv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizckv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizclv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_55' to 'attention_quantizcmv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_54' to 'attention_quantizcnw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_53' to 'attention_quantizcow' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_52' to 'attention_quantizcpw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_51' to 'attention_quantizcqw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_50' to 'attention_quantizcrw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_49' to 'attention_quantizcsw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_48' to 'attention_quantizctx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_47' to 'attention_quantizcux' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_46' to 'attention_quantizcvx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_45' to 'attention_quantizcwx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_44' to 'attention_quantizcxx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_43' to 'attention_quantizcyx' due to the length limit 20
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:01:06 ; elapsed = 00:01:11 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 621416 ; free virtual = 759738
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:01:06 ; elapsed = 00:01:11 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 621416 ; free virtual = 759738
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<ap_fixed<32, 20, (ap_q_mode)5, (ap_o_mode)3, 0> >' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:01:15 ; elapsed = 00:01:20 . Memory (MB): peak = 1424.152 ; gain = 786.125 ; free physical = 621114 ; free virtual = 759483
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 68, 60>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 60, 55>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:350) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 55, 50>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:352) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 17, 6, 50, 45>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:354) automatically.
INFO: [XFORM 203-602] Inlining function 'fabs_fixed<33, 21>' into 'pow_apfixed_reduce::pow<32, 20>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_pow_apfixed.h:94) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::pow<32, 20>' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::pow<32, 20>' into 'softmax' (kernel.cpp:402) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:601) automatically.
WARNING: [SYNCHK 200-23] /opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_pow_apfixed.h:75: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:01:20 ; elapsed = 00:01:25 . Memory (MB): peak = 1434.121 ; gain = 796.094 ; free physical = 621010 ; free virtual = 759396
INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'log_apfixed_reduce::log<75, 21>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:500:9).
INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'exp_reduce::exp_core<32, 20, 54>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:873:30).
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:462) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:483) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:489) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:495) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6.1' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-7.1' (kernel.cpp:513) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-8.1' (kernel.cpp:521) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:532) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:540) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-14.1' (kernel.cpp:576) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j9' (kernel.cpp:586) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-16' (kernel.cpp:596) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-16.1' (kernel.cpp:597) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_3_i11' (kernel.cpp:603) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j10' (kernel.cpp:604) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:614) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19.1' (kernel.cpp:623) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-20' (kernel.cpp:631) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_6_s4' (kernel.cpp:636) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:661) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-24' (kernel.cpp:665) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:425) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:376) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:364) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:365) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:346) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:262) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:279) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:239) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:224) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:136) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:140) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:729) in function 'log_apfixed_reduce::log<75, 21>' completely with a factor of 75.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1310) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 19.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1317) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 46.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1512) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1518) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 5.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1521) in function 'exp_reduce::exp_core<32, 20, 54>' completely with a factor of 42.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:462) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:483) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:489) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:495) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6.1' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-7.1' (kernel.cpp:513) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-8.1' (kernel.cpp:521) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:532) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:540) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-14.1' (kernel.cpp:576) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j9' (kernel.cpp:586) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-16' (kernel.cpp:596) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-16.1' (kernel.cpp:597) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_3_i11' (kernel.cpp:603) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j10' (kernel.cpp:604) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:614) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19.1' (kernel.cpp:623) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-20' (kernel.cpp:631) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_6_s4' (kernel.cpp:636) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:661) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-24' (kernel.cpp:665) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:425) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:376) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:364) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:365) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:346) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:262) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:279) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:239) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:224) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:136) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:142) in function 'linear_forward_no_mul' completely with a factor of 24.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:158) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q.V' (kernel.cpp:260) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k.V' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v214.V.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states.V' (kernel.cpp:461) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales.V' (kernel.cpp:477) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed.V' (kernel.cpp:530) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed.V' (kernel.cpp:538) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights.V' (kernel.cpp:574) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.V' (kernel.cpp:595) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights.V' (kernel.cpp:612) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output.V' (kernel.cpp:621) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output.V' (kernel.cpp:644) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales.V' (kernel.cpp:660) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.V.0' (kernel.cpp:595) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj.V' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj.V' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj.V' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v261' (kernel.cpp:446) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v259' (kernel.cpp:444) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v257' (kernel.cpp:442) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v263' (kernel.cpp:448) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output'  in dimension 3 completely.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.5.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.5.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.5.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.5.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.6.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.6.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.6.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.6.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.7.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.7.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.7.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.7.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.8.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.8.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.8.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.8.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.9.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.9.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.9.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.9.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.10.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.10.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.10.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.10.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.11.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.11.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.11.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.11.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.12.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.12.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.12.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.12.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.13.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.13.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.13.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.13.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.14.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.14.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.14.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.14.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.15.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.15.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.15.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.15.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.16.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.16.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.16.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.16.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.17.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.17.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.17.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.17.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.18.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.18.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.18.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.18.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.19.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.19.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.19.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.19.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.20.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.20.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.20.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.20.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.21.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.21.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.21.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.21.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.22.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.22.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.22.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.22.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.23.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.23.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.23.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states.23.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.5.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.5.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.5.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.5.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.6.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.6.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.6.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.6.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.7.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.7.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.7.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.7.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.8.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.8.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.8.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.8.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.9.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.9.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.9.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.9.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.10.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.10.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.10.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.10.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.11.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.11.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.11.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.11.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.12.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.12.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.12.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.12.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.13.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.13.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.13.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.13.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.14.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.14.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.14.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.14.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.15.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.15.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.15.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.15.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.16.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.16.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.16.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.16.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.17.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.17.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.17.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.17.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.18.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.18.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.18.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.18.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.19.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.19.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.19.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.19.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.20.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.20.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.20.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.20.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.21.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.21.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.21.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.21.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.22.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.22.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.22.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.22.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.23.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.23.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.23.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output.23.3' in dimension 1 automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 68, 60>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 60, 55>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:350) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 55, 50>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:352) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::range_reduce<ap_fixed<74, 7, (ap_q_mode)5, (ap_o_mode)3, 0>, 17, 6, 50, 45>' into 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:354) automatically.
INFO: [XFORM 203-602] Inlining function 'log_apfixed_reduce::log_traits<5>::range_reduction<68>' into 'log_apfixed_reduce::log<75, 21>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:771) automatically.
INFO: [XFORM 203-602] Inlining function 'fabs_fixed<33, 21>' into 'pow_apfixed_reduce::pow<32, 20>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_pow_apfixed.h:94) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::pow<32, 20>' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'hls::pow<32, 20>' into 'softmax' (kernel.cpp:402) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:601) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:98:47) to (kernel.cpp:120:9) in function 'quantize_activation'... converting 3 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:727:44) to (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:747:17) in function 'log_apfixed_reduce::log<75, 21>'... converting 76 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:175:33) to (kernel.cpp:140:46) in function 'linear_forward_no_mul'... converting 669 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:873:1) to (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:1993:5) in function 'exp_reduce::exp_core<32, 20, 54>'... converting 5 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'log_apfixed_reduce::log<75, 21>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:178:90)...11 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...96 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'exp_reduce::exp_core<32, 20, 54>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:873:5)...22 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:01:31 ; elapsed = 00:01:38 . Memory (MB): peak = 1584.156 ; gain = 946.129 ; free physical = 620808 ; free virtual = 759222
WARNING: [XFORM 203-542] Cannot flatten a loop nest 'l_S_j_0_j2' (kernel.cpp:137:52) in function 'linear_forward_no_mul' : 

the outer loop is not a perfect loop because there is nontrivial logic in the loop latch.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:330:45)
WARNING: [XFORM 203-631] Renaming function 'pow_apfixed_reduce::pow<32, 20>' to 'pow<32, 20>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_pow_apfixed.h:63:29)
WARNING: [XFORM 203-631] Renaming function 'log_apfixed_reduce::log<75, 21>' to 'log<75, 21>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_log_apfixed.h:178:90)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:136:46)
WARNING: [XFORM 203-631] Renaming function 'exp_reduce::exp_core<32, 20, 54>' to 'exp_core<32, 20, 54>' (/opt/xilinx/Vivado/2019.2/common/technology/autopilot/hls_exp_apfixed.h:873:5)
INFO: [HLS 200-472] Inferring partial write operation for 'v197.V' (kernel.cpp:334:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0].V' (kernel.cpp:379:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0].V' (kernel.cpp:403:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v218[0].V' (kernel.cpp:413:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v146[0].V' (kernel.cpp:243:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v146[0].V' (kernel.cpp:245:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0].V' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v140[0].V' (kernel.cpp:228:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0][0][0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v187.V' (kernel.cpp:314:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v187.V' (kernel.cpp:319:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:464:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re.V' (kernel.cpp:485:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re.V' (kernel.cpp:491:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re.V' (kernel.cpp:497:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0].V' (kernel.cpp:534:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0].V' (kernel.cpp:542:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache.V' (kernel.cpp:551:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache.V' (kernel.cpp:559:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0].V' (kernel.cpp:578:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0].V' (kernel.cpp:591:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:616:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0].V' (kernel.cpp:625:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D.V' (kernel.cpp:633:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D.V' (kernel.cpp:640:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0].V' (kernel.cpp:647:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0].V' (kernel.cpp:264:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0].V' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v157[0].V' (kernel.cpp:288:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v158[0].V' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v246[0].V' (kernel.cpp:433:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v204[0].V' (kernel.cpp:354:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:02:20 ; elapsed = 00:02:27 . Memory (MB): peak = 1840.156 ; gain = 1202.129 ; free physical = 620630 ; free virtual = 759052
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'log<75, 21>' to 'log_75_21_s'.
WARNING: [SYN 201-103] Legalizing function name 'exp_core<32, 20, 54>' to 'exp_core_32_20_54_s'.
WARNING: [SYN 201-103] Legalizing function name 'pow<32, 20>' to 'pow_32_20_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'log_75_21_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'log<75, 21>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 30.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 147.21 seconds; current allocated memory: 799.484 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.4 seconds; current allocated memory: 803.107 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'exp_core_32_20_54_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'exp_core<32, 20, 54>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 13.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.6 seconds; current allocated memory: 804.191 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 804.846 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_32_20_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 805.310 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 806.119 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.63 seconds; current allocated memory: 806.845 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 807.303 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.75 seconds; current allocated memory: 808.960 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.73 seconds; current allocated memory: 810.701 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 16.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 4.12 seconds; current allocated memory: 817.767 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 5.06 seconds; current allocated memory: 836.011 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 5.1 seconds; current allocated memory: 837.349 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 837.502 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 837.612 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 837.787 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 838.096 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 838.537 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 838.836 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 839.156 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 839.332 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 839.551 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 839.793 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 840.031 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 840.364 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 840.974 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.67 seconds; current allocated memory: 841.643 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 841.885 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 843.076 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 4.56 seconds; current allocated memory: 849.255 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'log_75_21_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_6' to 'log_75_21_s_log_abkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_5' to 'log_75_21_s_log_acud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_9' to 'log_75_21_s_log_adEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_s' to 'log_75_21_s_log_aeOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_7' to 'log_75_21_s_log_afYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'log_75_21_s_log_apfixed_reduce_8' to 'log_75_21_s_log_ag8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_85ns_6ns_91_5_1' to 'attention_mul_85nhbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_68ns_4ns_72_5_1' to 'attention_mul_68nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_60ns_6ns_66_5_1' to 'attention_mul_60njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_55ns_6ns_61_2_1' to 'attention_mul_55nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_7s_68ns_73_5_1' to 'attention_mul_7s_lbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_50ns_6ns_56_2_1' to 'attention_mul_50nmb6' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_50nmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_55nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_60njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_68nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_7s_lbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_85nhbi': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'log_75_21_s'.
INFO: [HLS 200-111]  Elapsed time: 3.01 seconds; current allocated memory: 858.127 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'exp_core_32_20_54_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'exp_core_32_20_54_s_f_x_msb_4_table_V' to 'exp_core_32_20_54ncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'exp_core_32_20_54_s_f_x_msb_3_table_V' to 'exp_core_32_20_54ocq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'exp_core_32_20_54_s_f_x_msb_2_table_V' to 'exp_core_32_20_54pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'exp_core_32_20_54_s_exp_x_msb_1_table_V' to 'exp_core_32_20_54qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_36ns_44ns_80_3_1' to 'attention_mul_36nrcU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_48ns_50ns_98_2_1' to 'attention_mul_48nsc4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_50ns_50ns_100_2_1' to 'attention_mul_50ntde' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_36nrcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_48nsc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_50ntde': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'exp_core_32_20_54_s'.
INFO: [HLS 200-111]  Elapsed time: 2.59 seconds; current allocated memory: 872.695 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_32_20_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_60s_32s_92_5_1' to 'attention_mul_60sudo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_60sudo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_32_20_s'.
INFO: [HLS 200-111]  Elapsed time: 0.75 seconds; current allocated memory: 876.346 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_46ns_44s_89_2_1' to 'attention_mul_46nvdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_27ns_32ns_32_31_seq_1' to 'attention_sdiv_27wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_46nvdy': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_27wdI': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 0.93 seconds; current allocated memory: 879.279 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_udiv_32ns_32ns_32_36_seq_1' to 'attention_udiv_32xdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_udiv_32xdS': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.98 seconds; current allocated memory: 883.095 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_urem_7ns_6ns_6_11_1' to 'attention_urem_7nyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_43ns_32s_32_47_seq_1' to 'attention_sdiv_43zec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_am_addmul_5ns_7ns_10ns_18_1_1' to 'attention_am_addmAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_am_addmul_6ns_7ns_10ns_18_1_1' to 'attention_am_addmBew' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_am_addmAem': 8 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_am_addmBew': 8 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_43zec': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_urem_7nyd2': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 1.61 seconds; current allocated memory: 904.021 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 7.82 seconds; current allocated memory: 943.464 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.83 seconds; current allocated memory: 944.323 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0_V' to 'apply_rotary_pos_CeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0_V' to 'apply_rotary_pos_DeQ' due to the length limit 20
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.85 seconds; current allocated memory: 945.710 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 1.04 seconds; current allocated memory: 947.910 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.98 seconds; current allocated memory: 949.590 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.85 seconds; current allocated memory: 950.864 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_44ns_32s_32_48_seq_1' to 'attention_sdiv_44Ee0' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_44Ee0': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.86 seconds; current allocated memory: 952.822 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 1.38 seconds; current allocated memory: 955.238 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v256_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v257_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v258_V' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v259_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v260_V' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v261_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v262_V' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_V' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272_V' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_95' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_94' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_93' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_92' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_91' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_90' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_89' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_88' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_47' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_46' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_45' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_44' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_27' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_26' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_25' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_24' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_23' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_22' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_21' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_20' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_19' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_18' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_17' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantiz5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantiz7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantiz8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantiz9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantizbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantizbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantizbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantizbdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantizbek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantizbfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizbgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizbhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizbil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_87' to 'attention_quantizbjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_86' to 'attention_quantizbkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_85' to 'attention_quantizbll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_84' to 'attention_quantizbml' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_83' to 'attention_quantizbnm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_82' to 'attention_quantizbom' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_81' to 'attention_quantizbpm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_80' to 'attention_quantizbqm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_79' to 'attention_quantizbrm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_78' to 'attention_quantizbsm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_77' to 'attention_quantizbtn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_76' to 'attention_quantizbun' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_75' to 'attention_quantizbvn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_74' to 'attention_quantizbwn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_73' to 'attention_quantizbxn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_72' to 'attention_quantizbyn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_71' to 'attention_quantizbzo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_70' to 'attention_quantizbAo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_69' to 'attention_quantizbBo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_68' to 'attention_quantizbCo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_67' to 'attention_quantizbDo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_66' to 'attention_quantizbEo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_65' to 'attention_quantizbFp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_64' to 'attention_quantizbGp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_63' to 'attention_quantizbHp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_62' to 'attention_quantizbIp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_61' to 'attention_quantizbJp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_60' to 'attention_quantizbKp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_59' to 'attention_quantizbLp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_58' to 'attention_quantizbMq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_57' to 'attention_quantizbNq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_56' to 'attention_quantizbOq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_55' to 'attention_quantizbPq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_54' to 'attention_quantizbQq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_53' to 'attention_quantizbRq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_52' to 'attention_quantizbSr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_51' to 'attention_quantizbTr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_50' to 'attention_quantizbUr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_49' to 'attention_quantizbVr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_48' to 'attention_quantizbWr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_43' to 'attention_quantizbXr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_42' to 'attention_quantizbYs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_41' to 'attention_quantizbZs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_40' to 'attention_quantizb0s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_39' to 'attention_quantizb1s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_38' to 'attention_quantizb2s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_37' to 'attention_quantizb3s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_36' to 'attention_quantizb4t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_35' to 'attention_quantizb5t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_34' to 'attention_quantizb6t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_33' to 'attention_quantizb7t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_32' to 'attention_quantizb8t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_31' to 'attention_quantizb9t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_30' to 'attention_quantizcau' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_29' to 'attention_quantizcbu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_28' to 'attention_quantizccu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_q_proj_V_0' to 'attention_q_proj_cdu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_V_0' to 'attention_k_proj_ceu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_v_proj_V_0' to 'attention_v_proj_cfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed_V' to 'attention_k_proj_cgu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_95' to 'attention_quantizchv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_94' to 'attention_quantizciv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_93' to 'attention_quantizcjv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_92' to 'attention_quantizckv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_91' to 'attention_quantizclv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_90' to 'attention_quantizcmv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_89' to 'attention_quantizcnw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_88' to 'attention_quantizcow' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_47' to 'attention_quantizcpw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_46' to 'attention_quantizcqw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_45' to 'attention_quantizcrw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_44' to 'attention_quantizcsw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_27' to 'attention_quantizctx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_26' to 'attention_quantizcux' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_25' to 'attention_quantizcvx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_24' to 'attention_quantizcwx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_23' to 'attention_quantizcxx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_22' to 'attention_quantizcyx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_21' to 'attention_quantizczy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_20' to 'attention_quantizcAy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_19' to 'attention_quantizcBy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_18' to 'attention_quantizcCy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_17' to 'attention_quantizcDy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_16' to 'attention_quantizcEy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_15' to 'attention_quantizcFz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_14' to 'attention_quantizcGz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_13' to 'attention_quantizcHz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_12' to 'attention_quantizcIz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_11' to 'attention_quantizcJz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_10' to 'attention_quantizcKz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_9' to 'attention_quantizcLz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizcMA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizcNA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantizcOA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantizcPA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizcQA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizcRA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizcSB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizcTB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizcUB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_87' to 'attention_quantizcVB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_86' to 'attention_quantizcWB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_85' to 'attention_quantizcXB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_84' to 'attention_quantizcYC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_83' to 'attention_quantizcZC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_82' to 'attention_quantizc0C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_81' to 'attention_quantizc1C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_80' to 'attention_quantizc2C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_79' to 'attention_quantizc3C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_78' to 'attention_quantizc4D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_77' to 'attention_quantizc5D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_76' to 'attention_quantizc6D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_75' to 'attention_quantizc7D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_74' to 'attention_quantizc8D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_73' to 'attention_quantizc9D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_72' to 'attention_quantizdaE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_71' to 'attention_quantizdbE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_70' to 'attention_quantizdcE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_69' to 'attention_quantizddE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_68' to 'attention_quantizdeE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_67' to 'attention_quantizdfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_66' to 'attention_quantizdgE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_65' to 'attention_quantizdhF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_64' to 'attention_quantizdiF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_63' to 'attention_quantizdjF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_62' to 'attention_quantizdkF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_61' to 'attention_quantizdlF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_60' to 'attention_quantizdmF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_59' to 'attention_quantizdnG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_58' to 'attention_quantizdoG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_57' to 'attention_quantizdpG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_56' to 'attention_quantizdqG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_55' to 'attention_quantizdrG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_54' to 'attention_quantizdsG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_53' to 'attention_quantizdtH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_52' to 'attention_quantizduH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_51' to 'attention_quantizdvH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_50' to 'attention_quantizdwH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_49' to 'attention_quantizdxH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_48' to 'attention_quantizdyH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_43' to 'attention_quantizdzI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_42' to 'attention_quantizdAI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_41' to 'attention_quantizdBI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_40' to 'attention_quantizdCI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_39' to 'attention_quantizdDI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_38' to 'attention_quantizdEI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_37' to 'attention_quantizdFJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_36' to 'attention_quantizdGJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_35' to 'attention_quantizdHJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_34' to 'attention_quantizdIJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_33' to 'attention_quantizdJJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_32' to 'attention_quantizdKJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_31' to 'attention_quantizdLJ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_30' to 'attention_quantizdMK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_29' to 'attention_quantizdNK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_28' to 'attention_quantizdOK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_hidden_states_0' to 'attention_rms_hiddPK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_q_proj_re_V' to 'attention_q_proj_dQK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_re_V' to 'attention_k_proj_dRK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_v_proj_re_V' to 'attention_v_proj_dSL' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_q_embed_0_V' to 'attention_q_embeddTL' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_embed_0_V' to 'attention_k_embeddUL' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_k_cache_V' to 'attention_updateddVL' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_v_cache_V' to 'attention_updateddWL' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_weights_0_V' to 'attention_attn_wedXL' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_softmax_attn_weights' to 'attention_softmaxdYM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_0_V' to 'attention_attn_oudZM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_2D_V' to 'attention_attn_oud0M' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_attn_output_0_V' to 'attention_rms_attd1M' due to the length limit 20
WARNING: [RTGEN 206-101] Port 'attention/v271' has no fanin or fanout and is left dangling.
               Please use C simulation to confirm this function argument can be read from or written to.
INFO: [RTGEN 206-100] Generating core module 'attention_mul_46nvdy': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'attention'.
INFO: [HLS 200-111]  Elapsed time: 5.17 seconds; current allocated memory: 966.964 MB.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 114.29 MHz
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_85nhbi_MulnS_0'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_68nibs_MulnS_1'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_60njbC_MulnS_2'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_55nkbM_MulnS_3'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_7s_lbW_MulnS_4'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_50nmb6_MulnS_5'
INFO: [RTMG 210-279] Implementing memory 'log_75_21_s_log_abkb_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'log_75_21_s_log_acud_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'log_75_21_s_log_adEe_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'log_75_21_s_log_aeOg_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'log_75_21_s_log_afYi_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'log_75_21_s_log_ag8j_rom' using auto ROMs.
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_36nrcU_MulnS_6'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_48nsc4_MulnS_7'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_50ntde_MulnS_8'
INFO: [RTMG 210-279] Implementing memory 'exp_core_32_20_54ncg_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'exp_core_32_20_54ocq_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'exp_core_32_20_54pcA_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'exp_core_32_20_54qcK_rom' using auto ROMs.
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_60sudo_MulnS_9'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_46nvdy_MulnS_10'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_sdiv_27wdI_div'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_udiv_32xdS_div'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_urem_7nyd2_div'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_sdiv_43zec_div'
INFO: [RTMG 210-278] Implementing memory 'apply_rotary_pos_CeG_ram (RAM)' using block RAMs.
INFO: [RTMG 210-282] Generating pipelined core: 'attention_sdiv_44Ee0_div'
INFO: [RTMG 210-278] Implementing memory 'attention_quantizFfa_ram (RAM)' using distributed RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_q_proj_cdu_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_v_proj_cfu_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_k_proj_cgu_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_updateddVL_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_attn_wedXL_ram (RAM)' using block RAMs.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:36 ; elapsed = 00:00:42 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579301 ; free virtual = 757139
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:36 ; elapsed = 00:00:42 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579301 ; free virtual = 757139
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:43 ; elapsed = 00:00:50 . Memory (MB): peak = 1247.277 ; gain = 609.250 ; free physical = 579106 ; free virtual = 756971
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:407) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:661) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:45 ; elapsed = 00:00:52 . Memory (MB): peak = 1386.344 ; gain = 748.316 ; free physical = 579029 ; free virtual = 756904
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:479) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:495) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:500) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:506) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:512) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:531) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:544) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:552) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:592) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:600) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:636) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:646) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:657) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:664) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:674) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:683) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:691) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:696) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:705) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:721) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:727) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:730) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:745) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:753) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:430) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:381) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:389) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:369) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:370) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:351) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:267) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:275) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:284) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:244) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:229) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:479) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:495) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:500) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:506) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:512) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:531) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:544) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:552) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:592) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:600) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:636) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:646) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:657) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:664) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:674) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:683) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:691) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:696) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:705) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:721) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:727) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:730) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:745) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:753) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:430) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:381) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:389) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:369) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:370) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:351) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:267) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:275) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:284) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:244) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:229) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 24.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:160) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:265) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:273) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v217.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:478) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:494) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:530) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:590) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:598) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:634) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:655) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:672) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:681) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:704) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:720) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:726) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:655) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v260' (kernel.cpp:447) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v262' (kernel.cpp:449) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:451) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:453) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'v260' (kernel.cpp:447) in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v262' (kernel.cpp:449) in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:451) in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:453) in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:407) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:53) to (kernel.cpp:142:46) in function 'linear_forward_no_mul'... converting 193 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:215:34) to (kernel.cpp:139:45) in function 'linear_forward_no_mul'... converting 10 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:517:31) to (kernel.cpp:591:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:711:3) to (kernel.cpp:754:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:01:05 ; elapsed = 00:01:15 . Memory (MB): peak = 1509.188 ; gain = 871.160 ; free physical = 578875 ; free virtual = 756770
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:139:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:335:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:138:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v200' (kernel.cpp:339:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v221[0]' (kernel.cpp:384:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v221[0]' (kernel.cpp:418:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v221[0]' (kernel.cpp:408:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v149[0]' (kernel.cpp:248:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v149[0]' (kernel.cpp:250:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v143[0]' (kernel.cpp:233:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v190' (kernel.cpp:319:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v190' (kernel.cpp:324:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:481:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:502:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:508:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:514:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:594:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:602:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:611:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:619:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:638:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:651:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:668:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:676:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:685:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:693:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:700:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:707:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:269:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:277:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v160[0]' (kernel.cpp:293:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v161[0]' (kernel.cpp:301:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v249[0]' (kernel.cpp:438:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v207[0]' (kernel.cpp:359:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:46 ; elapsed = 00:01:56 . Memory (MB): peak = 1701.188 ; gain = 1063.160 ; free physical = 578732 ; free virtual = 756634
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 116.67 seconds; current allocated memory: 638.271 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.77 seconds; current allocated memory: 639.627 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.87 seconds; current allocated memory: 640.024 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 640.502 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.51 seconds; current allocated memory: 641.087 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 641.649 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 1, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 2, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 3, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 4, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 67, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 82, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 90, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 94, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
WARNING: [SCHED 204-68] The II Violation in module 'linear_forward_no_mu' (Loop: l_S_j_0_j2_l_S_k0_0_k0): Unable to enforce a carried dependence constraint (II = 95, distance = 1, offset = 0)
   between 'fadd' operation ('v134_0_22', kernel.cpp:209) and 'select' operation ('select_ln155_1', kernel.cpp:155).
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 96, Depth = 147.
WARNING: [SCHED 204-21] Estimated clock period (15.21ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'linear_forward_no_mu' consists of the following:
	'fadd' operation ('v134_0_22', kernel.cpp:209) [3225]  (7.26 ns)
	'phi' operation ('v140_0', kernel.cpp:209) with incoming values : ('v134_0_22', kernel.cpp:209) [602]  (0 ns)
	'select' operation ('select_ln155_1', kernel.cpp:155) [612]  (0.698 ns)
	'fadd' operation ('v2', kernel.cpp:209) [1294]  (7.26 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 17.09 seconds; current allocated memory: 651.416 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 10.76 seconds; current allocated memory: 666.160 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 10.27 seconds; current allocated memory: 667.351 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 667.504 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 667.647 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 667.813 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 668.138 MB.
INFO: [BIND 205-100]==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:36 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579452 ; free virtual = 757290
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:36 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579452 ; free virtual = 757290
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1247.418 ; gain = 609.391 ; free physical = 579229 ; free virtual = 757100
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:407) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:661) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:45 ; elapsed = 00:00:50 . Memory (MB): peak = 1386.449 ; gain = 748.422 ; free physical = 579157 ; free virtual = 757038
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:479) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:495) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:500) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:506) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:512) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:531) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:544) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:552) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:592) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:600) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:636) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:646) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:657) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:664) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:674) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:683) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:691) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:696) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:705) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:721) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:727) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:730) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:745) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:753) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:430) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:381) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:389) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:369) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:370) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:351) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:267) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:275) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:284) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:244) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:229) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:479) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:495) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:500) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:506) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:512) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:531) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:544) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:552) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:592) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:600) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:636) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:646) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:657) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:664) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:674) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:683) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:691) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:696) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:705) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:721) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:727) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:730) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:745) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:753) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:430) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:381) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:389) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:369) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:370) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:351) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:267) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:275) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:284) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:244) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:229) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 24.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:160) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:265) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:273) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v217.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:478) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:494) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:530) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:590) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:598) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:634) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:655) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:672) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:681) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:704) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:720) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:726) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:655) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v260' (kernel.cpp:447) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v262' (kernel.cpp:449) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:451) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:453) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'v260' (kernel.cpp:447) in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v262' (kernel.cpp:449) in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:451) in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:453) in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:407) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:53) to (kernel.cpp:142:46) in function 'linear_forward_no_mul'... converting 193 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:215:34) to (kernel.cpp:139:45) in function 'linear_forward_no_mul'... converting 10 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:517:31) to (kernel.cpp:591:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:711:3) to (kernel.cpp:754:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...96 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:01:06 ; elapsed = 00:01:11 . Memory (MB): peak = 1445.188 ; gain = 807.160 ; free physical = 579001 ; free virtual = 756902
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:139:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:335:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:138:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v200' (kernel.cpp:339:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v221[0]' (kernel.cpp:384:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v221[0]' (kernel.cpp:418:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v221[0]' (kernel.cpp:408:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v149[0]' (kernel.cpp:248:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v149[0]' (kernel.cpp:250:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v143[0]' (kernel.cpp:233:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v190' (kernel.cpp:319:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v190' (kernel.cpp:324:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:481:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:502:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:508:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:514:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:594:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:602:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:611:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:619:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:638:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:651:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:668:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:676:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:685:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:693:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:700:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:707:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:269:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:277:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v160[0]' (kernel.cpp:293:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v161[0]' (kernel.cpp:301:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v249[0]' (kernel.cpp:438:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v207[0]' (kernel.cpp:359:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:48 ; elapsed = 00:01:54 . Memory (MB): peak = 1701.188 ; gain = 1063.160 ; free physical = 578869 ; free virtual = 756776
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 114.57 seconds; current allocated memory: 644.641 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.78 seconds; current allocated memory: 645.999 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.89 seconds; current allocated memory: 646.380 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 646.874 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 647.460 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 648.019 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('v78_2_0_load', kernel.cpp:196) on array 'v78_2_0' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'v78_2_0'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('v78_0_0_load_22', kernel.cpp:196) on array 'v78_0_0' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'v78_0_0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 12, Depth = 89.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 28.01 seconds; current allocated memory: 656.614 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 8.66 seconds; current allocated memory: 670.091 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 8.68 seconds; current allocated memory: 671.150 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 671.306 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 671.411 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 671.577 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 671.923 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 672.358 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.61 seconds; current allocated memory: 672.653 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 673.015 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 673.206 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 673.422 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 673.606 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 673.897 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 674.237 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 674.850 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.81 seconds; current allocated memory: 675.288 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 675.540 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.98 seconds; current allocated memory: 681.309 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 14.92 seconds; current allocated memory: 693.707 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 12.87 seconds; current allocated memory: 699.115 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.46 seconds; current allocated memory: 705.578 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.71 seconds; current allocated memory: 707.567 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_92_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_urem_11ns_6ns_11_15_1' to 'attention_urem_11udo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mux_2432_8_1_1' to 'attention_mux_243vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_52ns_32s_52_56_1' to 'attention_sdiv_52wdI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_13ns_11ns_24_1_1' to 'attention_mul_mulxdS' due to the length limit 20
INFO: [RTGEN 206-104] Estimated max fanout for 'linear_forward_no_mu' is 5760 from HDL expression: ((1'b0 == ap_block_pp0_stage1) & (1'b1 == ap_CS_fsm_pp0_stage1) & (ap_enable_reg_pp0_iter0 == 1'b1))
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mux_243vdy': 24 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_52wdI': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_urem_11udo': 1 instance(s).
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:41 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579299 ; free virtual = 757138
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:41 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579299 ; free virtual = 757138
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:45 ; elapsed = 00:00:49 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579091 ; free virtual = 756962
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:412) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:664) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:51 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579015 ; free virtual = 756896
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:480) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:496) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:501) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:507) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:513) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:532) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:547) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:555) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:595) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:603) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:639) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:649) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:659) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:660) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:666) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:667) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:677) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:686) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:694) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:699) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:708) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:724) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:730) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:733) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:750) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:758) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:435) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:386) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:394) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:374) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:375) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:356) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:272) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:280) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:289) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:249) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:234) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:139) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:144) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:224) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:480) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:496) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:501) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:507) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:513) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:532) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:547) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:555) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:595) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:603) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:639) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:649) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:659) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:660) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:666) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:667) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:677) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:686) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:694) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:699) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:708) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:724) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:730) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:733) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:750) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:758) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:435) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:386) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:394) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:374) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:375) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:356) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:272) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:280) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:289) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:249) in function 'rotate_half' completely with a factor of 1.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579450 ; free virtual = 757289
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579450 ; free virtual = 757289
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579268 ; free virtual = 757139
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:412) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:664) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579192 ; free virtual = 757073
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:480) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:496) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:501) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:507) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:513) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:532) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:547) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:555) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:595) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:603) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:639) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:649) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:659) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:660) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:666) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:667) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:677) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:686) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:694) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:699) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:708) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:724) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:730) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:733) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:750) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:758) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:435) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:386) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:394) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:374) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:375) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:356) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:272) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:280) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:289) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:249) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:234) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:139) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:144) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:224) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:480) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:496) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:501) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:507) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:513) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:532) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:547) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:555) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:595) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:603) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:639) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:649) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:659) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:660) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:666) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:667) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:677) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:686) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:694) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:699) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:708) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:724) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:730) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:733) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:750) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:758) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:435) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:386) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:394) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:374) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:375) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:356) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:272) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:280) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:289) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:249) in function 'rotate_half' completely with a factor of 1.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579425 ; free virtual = 757263
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579424 ; free virtual = 757263
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579200 ; free virtual = 757071
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:411) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:663) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579122 ; free virtual = 757004
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:479) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:495) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:500) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:506) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:512) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:531) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:546) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:554) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:594) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:602) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:638) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:648) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:658) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:659) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:665) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:666) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:676) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:685) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:693) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:698) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:707) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:723) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:732) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:749) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:757) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:434) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:385) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:393) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:374) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:355) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:271) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:279) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:288) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:248) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:233) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:143) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:223) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:479) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:495) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:500) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:506) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:512) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:531) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:546) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:554) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:594) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:602) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:638) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:648) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:658) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:659) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:665) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:666) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:676) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:685) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:693) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:698) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:707) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:723) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:732) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:749) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:757) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:434) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:385) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:393) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:374) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:355) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:271) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:279) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:288) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:248) in function 'rotate_half' completely with a factor of 1.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:36 ; elapsed = 00:00:39 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579443 ; free virtual = 757282
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:36 ; elapsed = 00:00:39 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579443 ; free virtual = 757282
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:47 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579262 ; free virtual = 757132
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:411) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:659) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:49 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579188 ; free virtual = 757069
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:479) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:495) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:500) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:506) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:512) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:531) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:542) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:550) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:590) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:598) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:634) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:644) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:654) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:661) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:672) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:681) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:689) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:694) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:703) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:719) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:725) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:728) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:742) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:750) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:434) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:385) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:393) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:374) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:355) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:271) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:279) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:288) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:248) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:233) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:143) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:223) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:479) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:495) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:500) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:506) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:512) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:531) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:542) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:550) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:590) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:598) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:634) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:644) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:654) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:661) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:672) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:681) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:689) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:694) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:703) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:719) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:725) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:728) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:742) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:750) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:434) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:385) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:393) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:374) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:355) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:271) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:279) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:288) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:248) in function 'rotate_half' completely with a factor of 1.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579445 ; free virtual = 757284
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579445 ; free virtual = 757284
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579244 ; free virtual = 757115
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:411) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:652) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579166 ; free virtual = 757048
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:472) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:488) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:493) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:524) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:535) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:583) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:627) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:637) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:647) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:648) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:654) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:665) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:674) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:687) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:696) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:712) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:718) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:721) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:735) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:743) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:434) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:385) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:393) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:374) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:355) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:271) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:279) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:288) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:248) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:233) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:143) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:223) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:472) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:488) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:493) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:524) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:535) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:583) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:627) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:637) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:647) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:648) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:654) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:665) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:674) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:687) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:696) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:712) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:718) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:721) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:735) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:743) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:434) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:385) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:393) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:374) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:355) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:271) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:279) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:288) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:248) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:233) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:138) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:145) in function 'linear_forward_no_mul' completely with a factor of 24.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:162) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:223) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:269) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:277) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:471) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:487) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:523) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:581) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:625) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:646) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:663) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:672) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:695) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:711) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:717) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:646) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:455) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:453) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:451) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:457) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 3 completely.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 3 completely.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23.3' in dimension 1 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:411) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:143:53) to (kernel.cpp:143:46) in function 'linear_forward_no_mul'... converting 193 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:217:34) to (kernel.cpp:139:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:510:31) to (kernel.cpp:582:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:702:3) to (kernel.cpp:744:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...96 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:52 ; elapsed = 00:00:58 . Memory (MB): peak = 1523.949 ; gain = 885.922 ; free physical = 579013 ; free virtual = 756914
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:139:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:339:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:138:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:343:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:388:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:422:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:412:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:252:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:254:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:237:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:323:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:328:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:474:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:495:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:585:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:602:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:629:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:642:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:659:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:676:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:684:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:691:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:698:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:273:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:281:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:297:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:305:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:442:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:363:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:11 ; elapsed = 00:01:17 . Memory (MB): peak = 1587.949 ; gain = 949.922 ; free physical = 578866 ; free virtual = 756774
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 77.54 seconds; current allocated memory: 615.833 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 617.190 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 617.586 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 618.065 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 618.653 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.2 seconds; current allocated memory: 619.214 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 119.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.92 seconds; current allocated memory: 623.955 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.96 seconds; current allocated memory: 630.812 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 2 seconds; current allocated memory: 631.886 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.08 seconds; current allocated memory: 632.037 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 632.158 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 632.323 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 632.663 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 633.107 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 633.398 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 633.766 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 633.936 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 634.154 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 634.374 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 634.627 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 634.990 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 635.582 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 636.033 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 636.286 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 638.180 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.44 seconds; current allocated memory: 644.192 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 2.95 seconds; current allocated memory: 649.649 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 0.95 seconds; current allocated memory: 656.124 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 658.150 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_103ns_68s_103_107_1' to 'attention_sdiv_10udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_10udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.71 seconds; current allocated memory: 670.977 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 3.5 seconds; current allocated memory: 696.819 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 697.688 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.43 seconds; current allocated memory: 699.172 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 701.285 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.43 seconds; current allocated memory: 703.009 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.43 seconds; current allocated memory: 704.396 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 706.388 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.67 seconds; current allocated memory: 708.787 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_96' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_95' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_94' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_93' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_92' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_91' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_90' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_89' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_88' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_47' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_46' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_45' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_44' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_27' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_26' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_25' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_24' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_23' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_22' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_21' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_20' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_19' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_18' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_17' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantiz5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantiz7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantiz8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantiz9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_87' to 'attention_quantizbdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_86' to 'attention_quantizbek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_85' to 'attention_quantizbfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_84' to 'attention_quantizbgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_83' to 'attention_quantizbhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_82' to 'attention_quantizbil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_81' to 'attention_quantizbjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_80' to 'attention_quantizbkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_79' to 'attention_quantizbll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_78' to 'attention_quantizbml' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_77' to 'attention_quantizbnm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_76' to 'attention_quantizbom' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_75' to 'attention_quantizbpm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_74' to 'attention_quantizbqm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_73' to 'attention_quantizbrm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_72' to 'attention_quantizbsm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_71' to 'attention_quantizbtn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_70' to 'attention_quantizbun' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_69' to 'attention_quantizbvn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_68' to 'attention_quantizbwn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_67' to 'attention_quantizbxn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_66' to 'attention_quantizbyn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_65' to 'attention_quantizbzo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_64' to 'attention_quantizbAo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_63' to 'attention_quantizbBo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_62' to 'attention_quantizbCo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_61' to 'attention_quantizbDo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_60' to 'attention_quantizbEo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_59' to 'attention_quantizbFp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_58' to 'attention_quantizbGp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_57' to 'attention_quantizbHp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_56' to 'attention_quantizbIp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_55' to 'attention_quantizbJp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_54' to 'attention_quantizbKp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_53' to 'attention_quantizbLp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_52' to 'attention_quantizbMq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_51' to 'attention_quantizbNq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_50' to 'attention_quantizbOq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_49' to 'attention_quantizbPq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_48' to 'attention_quantizbQq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_43' to 'attention_quantizbRq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_42' to 'attention_quantizbSr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_41' to 'attention_quantizbTr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_40' to 'attention_quantizbUr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_39' to 'attention_quantizbVr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_38' to 'attention_quantizbWr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_37' to 'attention_quantizbXr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_36' to 'attention_quantizbYs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_35' to 'attention_quantizbZs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_34' to 'attention_quantizb0s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_33' to 'attention_quantizb1s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_32' to 'attention_quantizb2s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_31' to 'attention_quantizb3s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_30' to 'attention_quantizb4t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_29' to 'attention_quantizb5t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_28' to 'attention_quantizb6t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_b7t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_96' to 'attention_quantizb8t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_95' to 'attention_quantizb9t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_94' to 'attention_quantizcau' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_93' to 'attention_quantizcbu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_92' to 'attention_quantizccu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_91' to 'attention_quantizcdu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_90' to 'attention_quantizceu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_89' to 'attention_quantizcfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_88' to 'attention_quantizcgu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_47' to 'attention_quantizchv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_46' to 'attention_quantizciv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_45' to 'attention_quantizcjv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_44' to 'attention_quantizckv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_27' to 'attention_quantizclv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_26' to 'attention_quantizcmv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_25' to 'attention_quantizcnw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_24' to 'attention_quantizcow' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_23' to 'attention_quantizcpw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_22' to 'attention_quantizcqw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_21' to 'attention_quantizcrw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_20' to 'attention_quantizcsw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_19' to 'attention_quantizctx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_18' to 'attention_quantizcux' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_17' to 'attention_quantizcvx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_16' to 'attention_quantizcwx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_15' to 'attention_quantizcxx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_14' to 'attention_quantizcyx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_13' to 'attention_quantizczy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_12' to 'attention_quantizcAy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_11' to 'attention_quantizcBy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_10' to 'attention_quantizcCy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_9' to 'attention_quantizcDy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizcEy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizcFz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantizcGz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantizcHz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizcIz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizcJz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizcKz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizcLz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizcMA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_87' to 'attention_quantizcNA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_86' to 'attention_quantizcOA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_85' to 'attention_quantizcPA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_84' to 'attention_quantizcQA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_83' to 'attention_quantizcRA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_82' to 'attention_quantizcSB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_81' to 'attention_quantizcTB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_80' to 'attention_quantizcUB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_79' to 'attention_quantizcVB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_78' to 'attention_quantizcWB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_77' to 'attention_quantizcXB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_76' to 'attention_quantizcYC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_75' to 'attention_quantizcZC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_74' to 'attention_quantizc0C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_73' to 'attention_quantizc1C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_72' to 'attention_quantizc2C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_71' to 'attention_quantizc3C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_70' to 'attention_quantizc4D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_69' to 'attention_quantizc5D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_68' to 'attention_quantizc6D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_67' to 'attention_quantizc7D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_66' to 'attention_quantizc8D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_65' to 'attention_quantizc9D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_64' to 'attention_quantizdaE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_63' to 'attention_quantizdbE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_62' to 'attention_quantizdcE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_61' to 'attention_quantizddE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_60' to 'attention_quantizdeE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_59' to 'attention_quantizdfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_58' to 'attention_quantizdgE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_57' to 'attention_quantizdhF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_56' to 'attention_quantizdiF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_55' to 'attention_quantizdjF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_54' to 'attention_quantizdkF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_53' to 'attention_quantizdlF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_52' to 'attention_quantizdmF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_51' to 'attention_quantizdnG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_50' to 'attention_quantizdoG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_49' to 'attention_quantizdpG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_48' to 'attention_quantizdqG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_43' to 'attention_quantizdrG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_42' to 'attention_quantizdsG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_41' to 'attention_quantizdtH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_40' to 'attention_quantizduH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_39' to 'attention_quantizdvH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_38' to 'attention_quantizdwH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_37' to 'attention_quantizdxH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_36' to 'attention_quantizdyH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_35' to 'attention_quantizdzI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_34' to 'attention_quantizdAI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_33' to 'attention_quantizdBI' due to the length limit 20
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:41 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579294 ; free virtual = 757133
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:41 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579294 ; free virtual = 757133
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:49 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579085 ; free virtual = 756956
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:660) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579008 ; free virtual = 756890
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:494) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:511) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:530) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:690) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:704) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:720) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:726) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:752) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:494) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:511) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:530) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:690) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:704) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:720) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:726) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:752) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 24.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:161) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:276) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:477) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:493) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:529) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:597) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:633) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:654) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:671) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:680) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:703) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:719) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:725) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:654) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:450) in dimension 1 with a cyclic factor 18.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:452) in dimension 1 with a cyclic factor 18.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:454) in dimension 1 with a cyclic factor 18.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:456) in dimension 1 with a cyclic factor 18.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v782.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v783.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v784.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v785.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v786.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v787.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v788.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v789.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7810.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7811.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7812.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7813.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7814.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7815.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7816.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7817.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7818.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7819.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7820.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7821.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7822.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7823.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:178:33) to (kernel.cpp:142:46) in function 'linear_forward_no_mul'... converting 285 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:216:34) to (kernel.cpp:138:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:516:31) to (kernel.cpp:590:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:710:3) to (kernel.cpp:753:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...96 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:52 ; elapsed = 00:00:57 . Memory (MB): peak = 1523.949 ; gain = 885.922 ; free physical = 578860 ; free virtual = 756761
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:138:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:338:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:137:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:342:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:387:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:421:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:411:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:236:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:327:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:480:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:513:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:601:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:618:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:650:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:675:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:692:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:699:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:706:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:280:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:304:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:441:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:362:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:30 ; elapsed = 00:01:36 . Memory (MB): peak = 1587.949 ; gain = 949.922 ; free physical = 578731 ; free virtual = 756638
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 96.02 seconds; current allocated memory: 620.174 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 621.527 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 621.927 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 622.406 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 622.991 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 623.554 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('v80_6_load_2', kernel.cpp:155) on array 'v80_6' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'v80_6'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 153.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.52 seconds; current allocated memory: 629.759 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.48 seconds; current allocated memory: 631.426 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 3.46 seconds; current allocated memory: 632.742 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 632.895 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 633.017 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 633.180 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.2 seconds; current allocated memory: 633.543 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 634.017 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 634.305 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 634.632 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 634.805 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 635.023 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 635.245 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 635.501 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 635.857 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 636.489 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 636.890 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 637.144 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 638.995 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 4.02 seconds; current allocated memory: 645.217 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 3.4 seconds; current allocated memory: 650.930 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10]==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:41 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579295 ; free virtual = 757134
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:41 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579295 ; free virtual = 757134
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:45 ; elapsed = 00:00:49 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579084 ; free virtual = 756955
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:660) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579008 ; free virtual = 756889
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:494) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:511) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:530) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:690) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:704) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:720) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:726) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:752) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:494) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:511) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:530) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:690) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:704) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:720) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:726) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:752) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 24.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:161) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:276) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:477) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:493) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:529) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:597) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:633) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:654) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:671) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:680) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:703) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:719) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:725) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:654) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:450) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:452) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:454) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:456) in dimension 1 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 24.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v782.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v783.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v784.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v785.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v786.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v787.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v788.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v789.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7810.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7811.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7812.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7813.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7814.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7815.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7816.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7817.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7818.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7819.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7820.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7821.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7822.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7823.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.16.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.17.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.18.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.19.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.20.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.21.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.22.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.23.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.16.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.17.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.18.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.19.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.20.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.21.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.22.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.23.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:53) to (kernel.cpp:142:46) in function 'linear_forward_no_mul'... converting 193 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:216:34) to (kernel.cpp:138:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:516:31) to (kernel.cpp:590:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:710:3) to (kernel.cpp:753:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...96 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:52 ; elapsed = 00:00:57 . Memory (MB): peak = 1523.949 ; gain = 885.922 ; free physical = 578859 ; free virtual = 756760
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:138:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:338:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:137:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:342:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:387:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:421:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:411:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:236:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:327:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:480:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:513:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:601:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:618:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:650:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:675:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:692:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:699:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:706:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:280:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:304:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:441:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:362:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:11 ; elapsed = 00:01:17 . Memory (MB): peak = 1587.949 ; gain = 949.922 ; free physical = 578757 ; free virtual = 756664
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 77.11 seconds; current allocated memory: 615.643 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.46 seconds; current allocated memory: 616.998 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.61 seconds; current allocated memory: 617.396 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 617.877 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 618.462 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 619.023 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 119.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.98 seconds; current allocated memory: 623.783 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 2.36 seconds; current allocated memory: 630.642 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 2.47 seconds; current allocated memory: 631.716 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 631.867 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 631.987 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 632.151 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 632.493 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 632.932 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 633.225 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 633.584 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 633.761 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 633.980 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 634.203 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 634.456 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 634.798 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 635.393 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 635.868 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 636.120 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.52 seconds; current allocated memory: 638.029 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.8 seconds; current allocated memory: 644.011 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 3.19 seconds; current allocated memory: 649.452 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.12 seconds; current allocated memory: 655.912 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 657.954 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_103ns_68s_103_107_1' to 'attention_sdiv_10udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_10udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.93 seconds; current allocated memory: 670.761 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 4.39 seconds; current allocated memory: 696.605 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 697.473 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.78 seconds; current allocated memory: 698.941 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.96 seconds; current allocated memory: 701.070 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.79 seconds; current allocated memory: 702.779 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.73 seconds; current allocated memory: 704.165 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.81 seconds; current allocated memory: 706.173 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 1.1 seconds; current allocated memory: 708.541 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_16' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_17' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_18' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_19' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_20' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_21' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_22' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_23' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_96' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_95' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_94' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_93' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_92' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_91' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_90' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_89' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_88' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_47' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_46' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_45' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_44' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_27' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_26' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_25' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_24' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_23' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_22' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_21' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_20' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_19' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_18' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_17' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantiz5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantiz7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantiz8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantiz9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_87' to 'attention_quantizbdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_86' to 'attention_quantizbek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_85' to 'attention_quantizbfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_84' to 'attention_quantizbgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_83' to 'attention_quantizbhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_82' to 'attention_quantizbil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_81' to 'attention_quantizbjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_80' to 'attention_quantizbkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_79' to 'attention_quantizbll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_78' to 'attention_quantizbml' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_77' to 'attention_quantizbnm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_76' to 'attention_quantizbom' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_75' to 'attention_quantizbpm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_74' to 'attention_quantizbqm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_73' to 'attention_quantizbrm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_72' to 'attention_quantizbsm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_71' to 'attention_quantizbtn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_70' to 'attention_quantizbun' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_69' to 'attention_quantizbvn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_68' to 'attention_quantizbwn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_67' to 'attention_quantizbxn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_66' to 'attention_quantizbyn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_65' to 'attention_quantizbzo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_64' to 'attention_quantizbAo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_63' to 'attention_quantizbBo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_62' to 'attention_quantizbCo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_61' to 'attention_quantizbDo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_60' to 'attention_quantizbEo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_59' to 'attention_quantizbFp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_58' to 'attention_quantizbGp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_57' to 'attention_quantizbHp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_56' to 'attention_quantizbIp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_55' to 'attention_quantizbJp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_54' to 'attention_quantizbKp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_53' to 'attention_quantizbLp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_52' to 'attention_quantizbMq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_51' to 'attention_quantizbNq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_50' to 'attention_quantizbOq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_49' to 'attention_quantizbPq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_48' to 'attention_quantizbQq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_43' to 'attention_quantizbRq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_42' to 'attention_quantizbSr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_41' to 'attention_quantizbTr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_40' to 'attention_quantizbUr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_39' to 'attention_quantizbVr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_38' to 'attention_quantizbWr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_37' to 'attention_quantizbXr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_36' to 'attention_quantizbYs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_35' to 'attention_quantizbZs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_34' to 'attention_quantizb0s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_33' to 'attention_quantizb1s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_32' to 'attention_quantizb2s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_31' to 'attention_quantizb3s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_30' to 'attention_quantizb4t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_29' to 'attention_quantizb5t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_28' to 'attention_quantizb6t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_b7t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_96' to 'attention_quantizb8t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_95' to 'attention_quantizb9t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_94' to 'attention_quantizcau' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_93' to 'attention_quantizcbu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_92' to 'attention_quantizccu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_91' to 'attention_quantizcdu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_90' to 'attention_quantizceu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_89' to 'attention_quantizcfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_88' to 'attention_quantizcgu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_47' to 'attention_quantizchv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_46' to 'attention_quantizciv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_45' to 'attention_quantizcjv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_44' to 'attention_quantizckv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_27' to 'attention_quantizclv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_26' to 'attention_quantizcmv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_25' to 'attention_quantizcnw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_24' to 'attention_quantizcow' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_23' to 'attention_quantizcpw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_22' to 'attention_quantizcqw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_21' to 'attention_quantizcrw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_20' to 'attention_quantizcsw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_19' to 'attention_quantizctx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_18' to 'attention_quantizcux' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_17' to 'attention_quantizcvx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_16' to 'attention_quantizcwx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_15' to 'attention_quantizcxx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_14' to 'attention_quantizcyx' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_13' to 'attention_quantizczy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_12' to 'attention_quantizcAy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_11' to 'attention_quantizcBy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_10' to 'attention_quantizcCy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_9' to 'attention_quantizcDy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizcEy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizcFz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantizcGz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantizcHz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizcIz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizcJz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizcKz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizcLz' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizcMA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_87' to 'attention_quantizcNA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_86' to 'attention_quantizcOA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_85' to 'attention_quantizcPA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_84' to 'attention_quantizcQA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_83' to 'attention_quantizcRA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_82' to 'attention_quantizcSB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_81' to 'attention_quantizcTB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_80' to 'attention_quantizcUB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_79' to 'attention_quantizcVB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_78' to 'attention_quantizcWB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_77' to 'attention_quantizcXB' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_76' to 'attention_quantizcYC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_75' to 'attention_quantizcZC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_74' to 'attention_quantizc0C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_73' to 'attention_quantizc1C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_72' to 'attention_quantizc2C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_71' to 'attention_quantizc3C' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_70' to 'attention_quantizc4D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_69' to 'attention_quantizc5D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_68' to 'attention_quantizc6D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_67' to 'attention_quantizc7D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_66' to 'attention_quantizc8D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_65' to 'attention_quantizc9D' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_64' to 'attention_quantizdaE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_63' to 'attention_quantizdbE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_62' to 'attention_quantizdcE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_61' to 'attention_quantizddE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_60' to 'attention_quantizdeE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_59' to 'attention_quantizdfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_58' to 'attention_quantizdgE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_57' to 'attention_quantizdhF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_56' to 'attention_quantizdiF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_55' to 'attention_quantizdjF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_54' to 'attention_quantizdkF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_53' to 'attention_quantizdlF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_52' to 'attention_quantizdmF' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_51' to 'attention_quantizdnG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_50' to 'attention_quantizdoG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_49' to 'attention_quantizdpG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_48' to 'attention_quantizdqG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_43' to 'attention_quantizdrG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_42' to 'attention_quantizdsG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_41' to 'attention_quantizdtH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_40' to 'attention_quantizduH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_39' to 'attention_quantizdvH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_38' to 'attention_quantizdwH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_37' to 'attention_quantizdxH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_36' to 'attention_quantizdyH' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_35' to 'attention_quantizdzI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_34' to 'attention_quantizdAI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_33' to 'attention_quantizdBI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_32' to 'attention_quantizdCI' due to the length limit 20
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579277 ; free virtual = 757116
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579277 ; free virtual = 757116
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579066 ; free virtual = 756938
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:660) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 578992 ; free virtual = 756873
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:494) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:511) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:530) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:690) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:704) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:720) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:726) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:752) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:494) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:511) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:530) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:690) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:704) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:720) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:726) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:752) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 16.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:161) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:276) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:477) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:493) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:529) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:597) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:633) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:654) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:671) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:680) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:703) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:719) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:725) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:654) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:450) in dimension 1 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:452) in dimension 1 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:454) in dimension 1 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:456) in dimension 1 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 16.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 16.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v782.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v783.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v784.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v785.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v786.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v787.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v788.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v789.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7810.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7811.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7812.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7813.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7814.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7815.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.12.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.13.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.14.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.15.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.12.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.13.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.14.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.15.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:53) to (kernel.cpp:142:46) in function 'linear_forward_no_mul'... converting 129 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:216:34) to (kernel.cpp:138:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:516:31) to (kernel.cpp:590:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:710:3) to (kernel.cpp:753:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...64 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:51 ; elapsed = 00:00:56 . Memory (MB): peak = 1523.949 ; gain = 885.922 ; free physical = 578851 ; free virtual = 756748
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:138:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:338:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:137:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:342:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:387:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:421:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:411:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:236:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:327:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:480:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:513:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:601:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:618:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:650:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:675:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:692:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:699:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:706:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:280:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:304:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:441:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:362:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:06 ; elapsed = 00:01:11 . Memory (MB): peak = 1587.949 ; gain = 949.922 ; free physical = 578698 ; free virtual = 756602
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 71.32 seconds; current allocated memory: 612.434 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 613.792 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.55 seconds; current allocated memory: 614.187 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 614.664 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 615.249 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 615.813 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 112.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.73 seconds; current allocated memory: 619.215 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.52 seconds; current allocated memory: 623.984 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.69 seconds; current allocated memory: 624.767 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 624.919 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 625.040 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 625.204 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 625.551 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 625.989 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.47 seconds; current allocated memory: 626.282 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 626.643 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 626.816 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 627.035 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 627.222 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 627.512 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 627.855 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 628.451 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 628.920 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 629.171 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 631.002 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.23 seconds; current allocated memory: 636.197 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 2.62 seconds; current allocated memory: 641.139 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.09 seconds; current allocated memory: 647.603 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 649.632 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.74 seconds; current allocated memory: 659.610 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 3.11 seconds; current allocated memory: 677.592 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.57 seconds; current allocated memory: 678.431 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.57 seconds; current allocated memory: 679.898 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.74 seconds; current allocated memory: 682.093 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.67 seconds; current allocated memory: 683.773 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.62 seconds; current allocated memory: 685.157 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.72 seconds; current allocated memory: 687.194 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.97 seconds; current allocated memory: 689.533 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_12' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_13' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_14' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_15' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_64' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_63' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_62' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_61' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_60' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_59' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_58' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_57' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_56' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_31' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_30' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_29' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_28' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_27' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_26' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_25' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_24' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_23' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_22' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_21' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_20' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_19' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_18' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_17' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantiz5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantiz7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantiz8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantiz9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_55' to 'attention_quantizbdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_54' to 'attention_quantizbek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_53' to 'attention_quantizbfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_52' to 'attention_quantizbgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_51' to 'attention_quantizbhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_50' to 'attention_quantizbil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_49' to 'attention_quantizbjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_48' to 'attention_quantizbkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_47' to 'attention_quantizbll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_46' to 'attention_quantizbml' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_45' to 'attention_quantizbnm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_44' to 'attention_quantizbom' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_43' to 'attention_quantizbpm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_42' to 'attention_quantizbqm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_41' to 'attention_quantizbrm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_40' to 'attention_quantizbsm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_39' to 'attention_quantizbtn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_38' to 'attention_quantizbun' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_37' to 'attention_quantizbvn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_36' to 'attention_quantizbwn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_35' to 'attention_quantizbxn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_34' to 'attention_quantizbyn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_33' to 'attention_quantizbzo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_32' to 'attention_quantizbAo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_bBo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_64' to 'attention_quantizbCo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_63' to 'attention_quantizbDo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_62' to 'attention_quantizbEo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_61' to 'attention_quantizbFp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_60' to 'attention_quantizbGp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_59' to 'attention_quantizbHp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_58' to 'attention_quantizbIp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_57' to 'attention_quantizbJp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_56' to 'attention_quantizbKp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_31' to 'attention_quantizbLp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_30' to 'attention_quantizbMq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_29' to 'attention_quantizbNq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_28' to 'attention_quantizbOq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_27' to 'attention_quantizbPq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_26' to 'attention_quantizbQq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_25' to 'attention_quantizbRq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_24' to 'attention_quantizbSr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_23' to 'attention_quantizbTr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_22' to 'attention_quantizbUr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_21' to 'attention_quantizbVr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_20' to 'attention_quantizbWr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_19' to 'attention_quantizbXr' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_18' to 'attention_quantizbYs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_17' to 'attention_quantizbZs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_16' to 'attention_quantizb0s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_15' to 'attention_quantizb1s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_14' to 'attention_quantizb2s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_13' to 'attention_quantizb3s' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_12' to 'attention_quantizb4t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_11' to 'attention_quantizb5t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_10' to 'attention_quantizb6t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_9' to 'attention_quantizb7t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizb8t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizb9t' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantizcau' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantizcbu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizccu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizcdu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizceu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizcfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizcgu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_55' to 'attention_quantizchv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_54' to 'attention_quantizciv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_53' to 'attention_quantizcjv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_52' to 'attention_quantizckv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_51' to 'attention_quantizclv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_50' to 'attention_quantizcmv' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_49' to 'attention_quantizcnw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_48' to 'attention_quantizcow' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_47' to 'attention_quantizcpw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_46' to 'attention_quantizcqw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_45' to 'attention_quantizcrw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_44' to 'attention_quantizcsw' due to the length limit 20
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579275 ; free virtual = 757114
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579275 ; free virtual = 757114
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579068 ; free virtual = 756938
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:660) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 578990 ; free virtual = 756872
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:494) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:511) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:530) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:690) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:704) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:720) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:726) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:752) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:494) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:511) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:530) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:690) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:704) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:720) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:726) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:752) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 12.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:161) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:276) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:477) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:493) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:529) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:597) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:633) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:654) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:671) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:680) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:703) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:719) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:725) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:654) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:450) in dimension 1 with a cyclic factor 12.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:452) in dimension 1 with a cyclic factor 12.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:454) in dimension 1 with a cyclic factor 12.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:456) in dimension 1 with a cyclic factor 12.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 12.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 12.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v782.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v783.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v784.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v785.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v786.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v787.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v788.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v789.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7810.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v7811.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.8.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.9.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.10.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.11.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:53) to (kernel.cpp:142:46) in function 'linear_forward_no_mul'... converting 97 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:216:34) to (kernel.cpp:138:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:516:31) to (kernel.cpp:590:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:710:3) to (kernel.cpp:753:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...48 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:50 ; elapsed = 00:00:55 . Memory (MB): peak = 1523.949 ; gain = 885.922 ; free physical = 578845 ; free virtual = 756746
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:138:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:338:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:137:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:342:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:387:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:421:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:411:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:236:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:327:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:480:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:513:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:601:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:618:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:650:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:675:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:692:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:699:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:706:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:280:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:304:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:441:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:362:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:02 ; elapsed = 00:01:08 . Memory (MB): peak = 1589.188 ; gain = 951.160 ; free physical = 578696 ; free virtual = 756603
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 68.56 seconds; current allocated memory: 610.697 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 612.054 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 612.449 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 612.928 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 613.512 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 614.078 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 112.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.62 seconds; current allocated memory: 616.714 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.12 seconds; current allocated memory: 620.486 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.26 seconds; current allocated memory: 621.098 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 621.251 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 621.410 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 621.575 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 621.881 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 622.357 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 622.649 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 622.970 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 623.147 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 623.366 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 623.587 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 623.842 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 624.182 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 624.816 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 625.249 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 625.504 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 627.301 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 3.24 seconds; current allocated memory: 632.030 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 2.38 seconds; current allocated memory: 636.647 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.06 seconds; current allocated memory: 643.107 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 645.146 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.71 seconds; current allocated memory: 653.687 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 2.3 seconds; current allocated memory: 667.577 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.47 seconds; current allocated memory: 668.492 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.62 seconds; current allocated memory: 669.917 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.66 seconds; current allocated memory: 672.133 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.64 seconds; current allocated memory: 673.813 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.58 seconds; current allocated memory: 675.161 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.68 seconds; current allocated memory: 677.236 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.85 seconds; current allocated memory: 679.603 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_8' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_9' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_10' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_11' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_48' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_47' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_46' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_45' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_44' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_43' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_42' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_41' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_40' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_31' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_30' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_29' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_28' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_27' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_26' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_25' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_24' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_23' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_22' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_21' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_20' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_19' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_18' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_17' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantiz5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantiz7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantiz8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantiz9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_39' to 'attention_quantizbdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_38' to 'attention_quantizbek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_37' to 'attention_quantizbfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_36' to 'attention_quantizbgk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_35' to 'attention_quantizbhl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_34' to 'attention_quantizbil' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_33' to 'attention_quantizbjl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_32' to 'attention_quantizbkl' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_bll' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_48' to 'attention_quantizbml' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_47' to 'attention_quantizbnm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_46' to 'attention_quantizbom' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_45' to 'attention_quantizbpm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_44' to 'attention_quantizbqm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_43' to 'attention_quantizbrm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_42' to 'attention_quantizbsm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_41' to 'attention_quantizbtn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_40' to 'attention_quantizbun' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_31' to 'attention_quantizbvn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_30' to 'attention_quantizbwn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_29' to 'attention_quantizbxn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_28' to 'attention_quantizbyn' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_27' to 'attention_quantizbzo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_26' to 'attention_quantizbAo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_25' to 'attention_quantizbBo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_24' to 'attention_quantizbCo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_23' to 'attention_quantizbDo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_22' to 'attention_quantizbEo' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_21' to 'attention_quantizbFp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_20' to 'attention_quantizbGp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_19' to 'attention_quantizbHp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_18' to 'attention_quantizbIp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_17' to 'attention_quantizbJp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_16' to 'attention_quantizbKp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_15' to 'attention_quantizbLp' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_14' to 'attention_quantizbMq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_13' to 'attention_quantizbNq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_12' to 'attention_quantizbOq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_11' to 'attention_quantizbPq' due to the length limit 20
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579298 ; free virtual = 757137
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 579298 ; free virtual = 757137
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579087 ; free virtual = 756958
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:660) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579012 ; free virtual = 756894
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:494) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:511) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:530) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:690) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:704) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:720) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:726) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:752) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:494) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:511) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:530) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:690) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:704) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:720) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:726) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:752) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 8.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:161) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:276) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:477) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:493) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:529) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:597) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:633) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:654) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:671) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:680) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:703) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:719) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:725) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:654) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:450) in dimension 1 with a cyclic factor 8.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:452) in dimension 1 with a cyclic factor 8.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:454) in dimension 1 with a cyclic factor 8.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:456) in dimension 1 with a cyclic factor 8.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 8.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 8.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v782.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v783.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v784.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v785.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v786.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v787.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.4.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.5.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.6.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.7.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:53) to (kernel.cpp:142:46) in function 'linear_forward_no_mul'... converting 65 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:216:34) to (kernel.cpp:138:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:516:31) to (kernel.cpp:590:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:710:3) to (kernel.cpp:753:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...32 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:50 ; elapsed = 00:00:55 . Memory (MB): peak = 1523.949 ; gain = 885.922 ; free physical = 578881 ; free virtual = 756782
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:138:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:338:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:137:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:342:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:387:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:421:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:411:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:236:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:327:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:480:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:513:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:601:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:618:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:650:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:675:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:692:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:699:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:706:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:280:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:304:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:441:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:362:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:01:00 ; elapsed = 00:01:06 . Memory (MB): peak = 1597.188 ; gain = 959.160 ; free physical = 578705 ; free virtual = 756612
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 65.86 seconds; current allocated memory: 608.078 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 609.440 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 609.832 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 610.313 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 610.894 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 611.460 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 112.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.52 seconds; current allocated memory: 613.470 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.86 seconds; current allocated memory: 616.255 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 1.03 seconds; current allocated memory: 616.765 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 616.918 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 617.041 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.08 seconds; current allocated memory: 617.205 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 617.565 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 618.003 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 618.293 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 618.620 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 618.831 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 619.051 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 619.234 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 619.489 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 619.866 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.28 seconds; current allocated memory: 620.465 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 620.919 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 621.172 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 622.920 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 2.57 seconds; current allocated memory: 627.276 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 2.31 seconds; current allocated memory: 631.636 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.3 seconds; current allocated memory: 638.113 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.57 seconds; current allocated memory: 640.138 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.68 seconds; current allocated memory: 647.302 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 1.84 seconds; current allocated memory: 657.614 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 658.484 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.46 seconds; current allocated memory: 659.908 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.61 seconds; current allocated memory: 662.157 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 663.852 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.76 seconds; current allocated memory: 665.205 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.58 seconds; current allocated memory: 667.251 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.89 seconds; current allocated memory: 669.618 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_4' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_5' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_6' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_7' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_32' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_31' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_30' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_29' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_28' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_27' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_26' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_25' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_24' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_23' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_22' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_21' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_20' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_19' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_18' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_17' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_32' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_31' to 'attention_quantiz7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_30' to 'attention_quantiz8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_29' to 'attention_quantiz9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_28' to 'attention_quantizbak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_27' to 'attention_quantizbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_26' to 'attention_quantizbck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_25' to 'attention_quantizbdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_24' to 'attention_quantizbek' due to the length limit 20
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580126 ; free virtual = 757965
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580126 ; free virtual = 757965
INFO: [HLS 200-10] Starting code transformations ...
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:140) in function 'linear_forward_no_mul(signed char (*) [384][4], ap_fixed<32, 12, (ap_q_mode)5, (ap_o_mode)3, 0>*, unsigned char (*) [1536], ap_fixed<32, 12, (ap_q_mode)5, (ap_o_mode)3, 0>, float (*) [1536])' completely with a factor of 1.
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579916 ; free virtual = 757787
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:405) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:645) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.477 ; gain = 743.449 ; free physical = 579839 ; free virtual = 757721
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:465) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:481) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:486) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:492) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:498) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:517) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:528) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:536) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:576) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:584) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:620) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:630) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:640) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:641) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:647) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:648) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:658) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:667) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:675) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:680) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:689) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:705) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:711) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:714) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:727) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:735) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:428) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:379) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:387) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:367) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:368) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:349) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:265) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:273) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:282) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:242) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:227) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:133) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:138) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:217) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:465) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:481) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:486) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:492) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:498) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:517) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:528) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:536) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:576) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:584) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:620) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:630) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:640) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:641) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:647) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:648) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:658) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:667) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:675) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:680) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:689) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:705) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:711) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:714) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:727) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:735) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:428) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:379) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:387) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:367) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:368) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:349) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:265) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:273) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:282) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:242) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:227) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:133) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:156) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:217) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:263) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:271) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v220.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:464) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:480) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:516) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:574) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:582) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:618) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:639) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:656) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:665) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:688) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:704) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:710) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:639) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:405) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:138:54) to (kernel.cpp:138:47) in function 'linear_forward_no_mul'... converting 9 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:211:34) to (kernel.cpp:134:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:503:31) to (kernel.cpp:575:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:695:3) to (kernel.cpp:736:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...4 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:49 ; elapsed = 00:00:54 . Memory (MB): peak = 1440.156 ; gain = 802.129 ; free physical = 579714 ; free virtual = 757615
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:134:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:333:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:133:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v203' (kernel.cpp:337:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v224[0]' (kernel.cpp:382:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v224[0]' (kernel.cpp:416:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v224[0]' (kernel.cpp:406:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v152[0]' (kernel.cpp:246:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v152[0]' (kernel.cpp:248:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v146[0]' (kernel.cpp:231:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v193' (kernel.cpp:317:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v193' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:467:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:488:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:494:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:500:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:578:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:586:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:595:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:603:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:622:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:635:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:652:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:660:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:669:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:677:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:691:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:267:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:275:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v163[0]' (kernel.cpp:291:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:299:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v252[0]' (kernel.cpp:436:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v210[0]' (kernel.cpp:357:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:56 ; elapsed = 00:01:01 . Memory (MB): peak = 1632.156 ; gain = 994.129 ; free physical = 579556 ; free virtual = 757462
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 61.43 seconds; current allocated memory: 604.626 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.34 seconds; current allocated memory: 605.997 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.46 seconds; current allocated memory: 606.394 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 606.875 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 607.459 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 608.026 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 111.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 608.843 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 609.938 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.34 seconds; current allocated memory: 610.162 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 610.315 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 610.420 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.1 seconds; current allocated memory: 610.584 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 610.929 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 611.371 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 611.678 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 612.001 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 612.229 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 612.448 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 612.631 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 612.887 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 613.281 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 613.877 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 614.313 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 614.566 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 616.247 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 1.88 seconds; current allocated memory: 619.902 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 1.72 seconds; current allocated memory: 623.820 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.01 seconds; current allocated memory: 630.295 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 632.321 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 636.972 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 0.79 seconds; current allocated memory: 640.437 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.31 seconds; current allocated memory: 641.336 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 642.777 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.51 seconds; current allocated memory: 645.007 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 646.734 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 648.083 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 650.129 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.83 seconds; current allocated memory: 652.511 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v262' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_DeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_hidden_states_0' to 'attention_rms_hidJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_k_cache' to 'attention_updatedKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_v_cache' to 'attention_updatedLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_weights_0' to 'attention_attn_weMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_softmax_attn_weights' to 'attention_softmaxNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_0' to 'attention_attn_ouOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_2D' to 'attention_attn_ouPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_attn_output_0' to 'attention_rms_attQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fpext_32ns_64_2_1' to 'attention_fpext_3Rg6' due to the length limit 20
WARNING: [RTGEN 206-101] Port 'attention/v277' has no fanin or fanout and is left dangling.
               Please use C simulation to confirm this function argument can be read from or written to.
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fpext_3Rg6': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'attention'.
INFO: [HLS 200-111]  Elapsed time: 1.08 seconds; current allocated memory: 658.660 MB.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 106.54 MHz
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_41nibs_MulnS_0'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_44njbC_MulnS_1'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_45nkbM_MulnS_2'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_43slbW_MulnS_3'
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatbkb_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatcud_rom' using auto ROMs.
INFO: [RTMG 210-279]==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580130 ; free virtual = 757970
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580130 ; free virtual = 757970
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:49 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579918 ; free virtual = 757789
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:660) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579842 ; free virtual = 757724
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:494) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:511) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:530) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:690) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:704) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:720) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:726) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:752) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:494) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:511) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:530) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:690) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:704) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:720) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:726) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:752) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:161) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:276) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:477) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:493) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:529) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:597) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:633) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:654) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:671) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:680) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:703) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:719) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:725) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:654) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:450) in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:452) in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:454) in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:456) in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 2.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:54) to (kernel.cpp:142:47) in function 'linear_forward_no_mul'... converting 17 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:216:34) to (kernel.cpp:138:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:516:31) to (kernel.cpp:590:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:710:3) to (kernel.cpp:753:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...8 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:50 ; elapsed = 00:00:55 . Memory (MB): peak = 1459.949 ; gain = 821.922 ; free physical = 579702 ; free virtual = 757602
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:138:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:338:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:137:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:342:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:387:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:421:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:411:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:236:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:327:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:480:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:513:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:601:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:618:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:650:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:675:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:692:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:699:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:706:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:280:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:304:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:441:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:362:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:57 ; elapsed = 00:01:02 . Memory (MB): peak = 1587.949 ; gain = 949.922 ; free physical = 579559 ; free virtual = 757465
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 62.49 seconds; current allocated memory: 605.130 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 606.504 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.51 seconds; current allocated memory: 606.898 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 607.379 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 607.961 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 608.521 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 111.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 609.499 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.43 seconds; current allocated memory: 610.842 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 611.135 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 611.291 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 611.394 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 611.557 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 611.903 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.2 seconds; current allocated memory: 612.343 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 612.634 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 612.964 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.21 seconds; current allocated memory: 613.189 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 613.409 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 613.592 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 613.886 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 614.241 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.28 seconds; current allocated memory: 614.839 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 615.278 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 615.531 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 617.271 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 2.03 seconds; current allocated memory: 620.978 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 1.72 seconds; current allocated memory: 624.945 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.1 seconds; current allocated memory: 631.443 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.57 seconds; current allocated memory: 633.446 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.65 seconds; current allocated memory: 638.419 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 0.94 seconds; current allocated memory: 642.894 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 643.764 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.47 seconds; current allocated memory: 645.220 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.58 seconds; current allocated memory: 647.465 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.45 seconds; current allocated memory: 649.206 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.45 seconds; current allocated memory: 650.511 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 652.586 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.7 seconds; current allocated memory: 654.927 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_Hfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_hidden_states_0' to 'attention_rms_hidRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_k_cache' to 'attention_updatedShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_v_cache' to 'attention_updatedThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_weights_0' to 'attention_attn_weUhA' due to the length limit 20
INFO: [SYN 201-210]==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580116 ; free virtual = 757955
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580116 ; free virtual = 757955
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:45 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579906 ; free virtual = 757777
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:660) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579830 ; free virtual = 757711
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:494) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:511) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:530) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:690) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:704) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:720) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:726) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:752) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:494) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:511) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:530) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:690) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:704) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:720) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:726) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:752) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:161) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:276) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:477) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:493) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:529) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:597) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:633) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:654) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:671) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:680) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:703) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:719) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:725) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:654) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:450) in dimension 1 with a cyclic factor 4.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:452) in dimension 1 with a cyclic factor 4.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:454) in dimension 1 with a cyclic factor 4.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:456) in dimension 1 with a cyclic factor 4.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 4.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 4.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v782.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v783.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:53) to (kernel.cpp:142:46) in function 'linear_forward_no_mul'... converting 33 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:216:34) to (kernel.cpp:138:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:516:31) to (kernel.cpp:590:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:710:3) to (kernel.cpp:753:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...16 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:50 ; elapsed = 00:00:55 . Memory (MB): peak = 1459.949 ; gain = 821.922 ; free physical = 579701 ; free virtual = 757602
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:138:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:338:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:137:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:342:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:387:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:421:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:411:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:236:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:327:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:480:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:513:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:601:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:618:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:650:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:675:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:692:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:699:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:706:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:280:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:304:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:441:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:362:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:58 ; elapsed = 00:01:03 . Memory (MB): peak = 1651.949 ; gain = 1013.922 ; free physical = 579545 ; free virtual = 757452
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 63.57 seconds; current allocated memory: 606.543 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 607.914 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 608.308 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 608.788 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 609.371 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 609.934 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 111.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 611.221 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.55 seconds; current allocated memory: 613.094 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.58 seconds; current allocated memory: 613.448 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 613.606 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 613.724 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 613.889 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 614.230 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 614.706 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 615.012 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 615.339 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 615.516 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 615.734 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 615.955 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 616.212 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 616.568 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 617.202 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 617.587 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 617.840 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 619.597 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 2.15 seconds; current allocated memory: 623.530 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 1.87 seconds; current allocated memory: 627.650 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.06 seconds; current allocated memory: 634.109 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 636.134 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.68 seconds; current allocated memory: 641.884 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 1.2 seconds; current allocated memory: 648.269 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 649.109 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.47 seconds; current allocated memory: 650.583 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.61 seconds; current allocated memory: 652.809 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 654.517 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.46 seconds; current allocated memory: 655.874 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 657.915 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.76 seconds; current allocated memory: 660.335 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_2' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_3' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_PgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_16' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_15' to 'attention_quantizRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_14' to 'attention_quantizShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_13' to 'attention_quantizThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_12' to 'attention_quantizUhA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_11' to 'attention_quantizVhK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_10' to 'attention_quantizWhU' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_9' to 'attention_quantizXh4' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizYie' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizZio' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantiz0iy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantiz1iI' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantiz2iS' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantiz3i2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantiz4jc' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantiz5jm' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantiz6jw' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_hidden_states_0' to 'attention_rms_hid7jG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_k_cache' to 'attention_updated8jQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_v_cache' to 'attention_updated9j0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_weights_0' to 'attention_attn_webak' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_softmax_attn_weights' to 'attention_softmaxbbk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_0' to 'attention_attn_oubck' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_output_2D' to 'attention_attn_oubdk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_attn_output_0' to 'attention_rms_attbek' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fpext_32ns_64_2_1' to 'attention_fpext_3bfk' due to the length limit 20
WARNING: [RTGEN 206-101] Port 'attention/v278' has no fanin or fanout and is left dangling.
               Please use C simulation to confirm this function argument can be read from or written to.
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fpext_3bfk': 2 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'attention'.
INFO: [HLS 200-111]  Elapsed time: 1.79 seconds; current allocated memory: 667.168 MB.
INFO: [HLS 200-790] **** Loop Constraint Status: All loop constraints were satisfied.
INFO: [HLS 200-789] **** Estimated Fmax: 106.54 MHz
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_41nibs_MulnS_0'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_44njbC_MulnS_1'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_45nkbM_MulnS_2'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_43slbW_MulnS_3'
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatbkb_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatcud_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatdEe_rom' using distributed ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floateOg_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatfYi_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floatg8j_rom' using auto ROMs.
INFO: [RTMG 210-279] Implementing memory 'pow_generic_floathbi_rom' using distributed ROMs.
INFO: [RTMG 210-282] Generating pipelined core: 'attention_mul_52stde_MulnS_4'
INFO: [RTMG 210-282] Generating pipelined core: 'attention_sdiv_97udo_div'
INFO: [RTMG 210-278] Implementing memory 'apply_rotary_pos_vdy_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_quantizyd2_ram (RAM)' using block RAMs with power-on initialization.
WARNING: [RTMG 210-274] Memory 'attention_quantizzec' is read-only, switch it to a ROM.
INFO: [RTMG 210-279] Implementing memory 'attention_quantizzec_rom' using distributed ROMs.
INFO: [RTMG 210-278] Implementing memory 'attention_q_proj_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_v_proj_0_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_k_proj_PgM_ram (RAM)' using block RAMs with power-on initialization.
INFO: [RTMG 210-278] Implementing memory 'attention_rms_hid7jG_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_updated8jQ_ram (RAM)' using block RAMs.
INFO: [RTMG 210-278] Implementing memory 'attention_attn_webak_ram (RAM)' using block RAMs.
INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:01:17 ; elapsed = 00:01:37 . Memory (MB): peak = 1651.949 ; gain = 1013.922 ; free physical = 579424 ; free virtual = 757368
INFO: [VHDL 208-304] Generating VHDL RTL for attention.
INFO: [VLOG 209-307] Generating Verilog RTL for attention.
INFO: [HLS 200-112] Total elapsed time: 97.03 seconds; peak allocated memory: 667.168 MB.
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580126 ; free virtual = 757965
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580126 ; free virtual = 757965
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579920 ; free virtual = 757790
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:408) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:650) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579841 ; free virtual = 757723
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:468) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:484) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:489) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:495) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:501) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:520) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:533) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:541) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:581) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:589) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:625) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:646) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:652) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:653) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:672) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:680) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:685) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:694) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:710) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:716) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:719) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:734) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:742) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:431) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:382) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:390) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:370) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:371) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:352) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:268) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:276) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:285) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:245) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:230) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:135) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:140) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:220) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:468) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:484) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:489) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:495) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:501) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:520) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:533) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:541) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:581) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:589) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:625) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:646) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:652) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:653) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:672) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:680) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:685) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:694) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:710) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:716) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:719) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:734) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:742) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:431) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:382) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:390) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:370) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:371) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:352) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:268) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:276) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:285) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:245) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:230) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:135) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:142) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:159) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:220) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:266) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:274) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:467) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:483) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:519) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:579) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:587) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:623) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:644) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:661) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:670) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:693) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:709) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:715) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:644) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 4.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 4.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v782.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v783.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.2.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.3.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:408) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:140:53) to (kernel.cpp:140:46) in function 'linear_forward_no_mul'... converting 33 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:214:34) to (kernel.cpp:136:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:506:31) to (kernel.cpp:580:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:700:3) to (kernel.cpp:743:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...16 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:49 ; elapsed = 00:00:55 . Memory (MB): peak = 1459.949 ; gain = 821.922 ; free physical = 579698 ; free virtual = 757599
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:136:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:336:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:135:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:340:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:385:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:419:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:409:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:249:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:234:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:320:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:325:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:470:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:491:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:497:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:503:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:583:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:591:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:600:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:608:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:627:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:640:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:657:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:665:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:674:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:682:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:689:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:696:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:270:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:278:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:294:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:302:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:439:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:360:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:59 ; elapsed = 00:01:05 . Memory (MB): peak = 1587.949 ; gain = 949.922 ; free physical = 579557 ; free virtual = 757464
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 65.11 seconds; current allocated memory: 607.446 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 608.802 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 609.198 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.26 seconds; current allocated memory: 609.677 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.4 seconds; current allocated memory: 610.260 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 610.826 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
WARNING: [SCHED 204-69] Unable to schedule 'load' operation ('v80_load_2', kernel.cpp:153) on array 'v80' due to limited memory ports. Please consider using a memory core with more ports or partitioning the array 'v80'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 2, Depth = 112.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.43 seconds; current allocated memory: 612.217 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.53 seconds; current allocated memory: 614.099 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.63 seconds; current allocated memory: 614.453 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.09 seconds; current allocated memory: 614.607 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 614.729 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 614.893 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 615.235 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 615.677 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.25 seconds; current allocated memory: 615.968 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 616.332 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.19 seconds; current allocated memory: 616.502 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 616.721 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.17 seconds; current allocated memory: 616.905 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 617.200 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 617.556 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.29 seconds; current allocated memory: 618.153 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 618.590 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 618.842 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 620.577 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 2.05 seconds; current allocated memory: 624.442 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 1.86 seconds; current allocated memory: 628.559 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.09 seconds; current allocated memory: 635.037 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 637.062 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.59 seconds; current allocated memory: 642.229 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 1.18 seconds; current allocated memory: 648.754 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 649.621 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 651.187 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 653.304 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 654.999 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.5 seconds; current allocated memory: 656.384 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.54 seconds; current allocated memory: 658.422 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.72 seconds; current allocated memory: 660.792 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_16' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_15' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_14' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_13' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_12' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_11' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_10' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_9' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantizHfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizNgs' due to the length limit 20
==============================================================
Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.2 (64-bit)
Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.
==============================================================
INFO: [HLS 200-10] Setting target device to 'xc7z020-clg484-1'
INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.
INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.
INFO: [HLS 200-10] Analyzing design file 'kernel.cpp' ... 
INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580119 ; free virtual = 757958
INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:37 ; elapsed = 00:00:40 . Memory (MB): peak = 1168.152 ; gain = 530.125 ; free physical = 580119 ; free virtual = 757958
INFO: [HLS 200-10] Starting code transformations ...
INFO: [XFORM 203-603] Inlining function 'std::max<float>' into 'quantize_activation' (kernel.cpp:86).
INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:44 ; elapsed = 00:00:48 . Memory (MB): peak = 1242.492 ; gain = 604.465 ; free physical = 579911 ; free virtual = 757781
INFO: [HLS 200-10] Checking synthesizability ...
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-602] Inlining function 'causal_mask' into 'attention' (kernel.cpp:660) automatically.
WARNING: [SYNCHK 200-23] /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:402: variable-indexed range selection may cause suboptimal QoR.
INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).
INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:46 ; elapsed = 00:00:50 . Memory (MB): peak = 1381.480 ; gain = 743.453 ; free physical = 579834 ; free virtual = 757716
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1' (kernel.cpp:478) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2' (kernel.cpp:494) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-3' (kernel.cpp:499) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-4' (kernel.cpp:505) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-5' (kernel.cpp:511) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-6' (kernel.cpp:530) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15' (kernel.cpp:655) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-19' (kernel.cpp:690) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-21' (kernel.cpp:704) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-22' (kernel.cpp:720) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-23' (kernel.cpp:726) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-26' (kernel.cpp:752) in function 'attention' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'l_S_k0_0_k0' (kernel.cpp:142) in function 'linear_forward_no_mul' for pipelining.
INFO: [XFORM 203-502] Unrolling small iteration loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' automatically.
INFO: [XFORM 203-502] Unrolling small iteration loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' automatically.
INFO: [HLS 200-489] Unrolling loop 'Loop-1' (kernel.cpp:478) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2' (kernel.cpp:494) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-3' (kernel.cpp:499) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-4' (kernel.cpp:505) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-5' (kernel.cpp:511) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-6' (kernel.cpp:530) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_0_i10' (kernel.cpp:543) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_1_i11' (kernel.cpp:551) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-9.1' (kernel.cpp:591) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-10.1' (kernel.cpp:599) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-13.1' (kernel.cpp:635) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_2_j10' (kernel.cpp:645) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15' (kernel.cpp:655) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-15.1' (kernel.cpp:656) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_5_i13' (kernel.cpp:662) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_5_j11' (kernel.cpp:663) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-17.1' (kernel.cpp:673) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-18.1' (kernel.cpp:682) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-19' (kernel.cpp:690) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_8_s4' (kernel.cpp:695) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-21' (kernel.cpp:704) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-22' (kernel.cpp:720) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-23' (kernel.cpp:726) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_11_i14' (kernel.cpp:729) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_j_k_12_i15' (kernel.cpp:744) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-26' (kernel.cpp:752) in function 'attention' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i9' (kernel.cpp:433) in function 'GEMM_3D_float2' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j6' (kernel.cpp:384) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_3_j7' (kernel.cpp:392) in function 'softmax' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i6' (kernel.cpp:372) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_j_0_j5' (kernel.cpp:373) in function 'causal_mask' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i5' (kernel.cpp:354) in function 'GEMM_3D_float' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1' (kernel.cpp:270) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'Loop-2.1' (kernel.cpp:278) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s2' (kernel.cpp:287) in function 'apply_rotary_pos_emb' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s1' (kernel.cpp:247) in function 'rotate_half' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_s_0_s' (kernel.cpp:232) in function 'reshape_2D_to_3D' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i3' (kernel.cpp:137) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_k1_0_k1' (kernel.cpp:144) in function 'linear_forward_no_mul' completely with a factor of 2.
INFO: [HLS 200-489] Unrolling loop 'l_S_l_0_l1' (kernel.cpp:161) in function 'linear_forward_no_mul' completely with a factor of 4.
INFO: [HLS 200-489] Unrolling loop 'Loop-1.1.2' (kernel.cpp:222) in function 'linear_forward_no_mul' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_i_0_i2' (kernel.cpp:67) in function 'quantize_activation' completely with a factor of 1.
INFO: [HLS 200-489] Unrolling loop 'l_S_index_0_index' (kernel.cpp:22) in function 'rms_norm' completely with a factor of 1.
INFO: [XFORM 203-102] Partitioning array 'rotated_q' (kernel.cpp:268) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rotated_k' (kernel.cpp:276) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v221.0' automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_hidden_states' (kernel.cpp:477) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'scales' (kernel.cpp:493) automatically.
INFO: [XFORM 203-102] Partitioning array 'scales_fixed.V' (kernel.cpp:529) automatically.
INFO: [XFORM 203-102] Partitioning array 'q_embed' (kernel.cpp:589) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_embed' (kernel.cpp:597) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_weights' (kernel.cpp:633) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix' (kernel.cpp:654) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'softmax_attn_weights' (kernel.cpp:671) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'attn_output' (kernel.cpp:680) in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'rms_attn_output' (kernel.cpp:703) in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales' (kernel.cpp:719) automatically.
INFO: [XFORM 203-102] Partitioning array 'final_scales_fixed.V' (kernel.cpp:725) automatically.
INFO: [XFORM 203-102] Partitioning array 'causal_mask_matrix.0' (kernel.cpp:654) automatically.
INFO: [XFORM 203-102] Partitioning array 'v_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'q_proj' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'k_proj' in dimension 2 automatically.
INFO: [XFORM 203-101] Partitioning array 'v264' (kernel.cpp:450) in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'v266' (kernel.cpp:452) in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'v268' (kernel.cpp:454) in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'v270' (kernel.cpp:456) in dimension 1 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'quantized_hidden_states_copy'  in dimension 2 with a cyclic factor 2.
INFO: [XFORM 203-101] Partitioning array 'quantized_final_output_copy'  in dimension 2 with a cyclic factor 2.
INFO: [XFORM 203-102] Partitioning array 'v78.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'v781.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_hidden_states_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.0.0' in dimension 2 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1' in dimension 1 automatically.
INFO: [XFORM 203-102] Partitioning array 'quantized_final_output_copy.1.0' in dimension 2 automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC2Ef8' into '_ZN9fp_structIfEC1Ef4' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:319) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isinf<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isinf.h:17) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'generic_isnan<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_isnan.h:17) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::data' into 'fp_struct<float>::to_float' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:348) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_float' into 'fp_struct<float>::to_ieee' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/src/hls/utils/x_hls_utils.h:369) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 4, 4, 39, 41>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:164) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 7, 6, 41, 44>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:167) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::log_range_reduce<ap_fixed<65, 9, (ap_q_mode)5, (ap_o_mode)3, 0>, 12, 6, 44, 39>' into 'pow_reduce::pow_traits<float>::log_range_reduction<39>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:170) automatically.
INFO: [XFORM 203-602] Inlining function '_ZN9fp_structIfEC1Ef4' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:324) automatically.
INFO: [XFORM 203-602] Inlining function '_ZNK9fp_structIfE4expvEv6' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:334) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isinf<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:373) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_isnan<float>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:375) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::to_ieee' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:412) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::log_range_reduction<39>' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:548) automatically.
INFO: [XFORM 203-602] Inlining function 'pow_reduce::pow_traits<float>::exp_Z1P_m_1' into 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:641) automatically.
INFO: [XFORM 203-602] Inlining function 'powf' into 'std::pow' (/opt/xilinx/Vivado/2019.2/lnx64/tools/gcc/lib/gcc/x86_64-unknown-linux-gnu/4.6.3/../../../../include/c++/4.6.3/cmath:349) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'rms_norm' (kernel.cpp:35) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::mantissa' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:15) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::expv' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:18) automatically.
INFO: [XFORM 203-602] Inlining function 'fp_struct<float>::__signbit' into 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:59) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, (ap_q_mode)6, float>' into 'generic_cast_IEEE754<int, float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_case_IEEE754.h:117) automatically.
INFO: [XFORM 203-602] Inlining function 'generic_cast_IEEE754<int, float>' into '__hls_fptosi_float_i32' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/src/lib_floatconversion.cpp:51) automatically.
INFO: [XFORM 203-602] Inlining function '__hls_fptosi_float_i32' into 'quantize_activation' (kernel.cpp:106) automatically.
INFO: [XFORM 203-602] Inlining function 'std::pow' into 'softmax' (kernel.cpp:410) automatically.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320:19) to (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:690:3) in function 'pow_reduce::pow_generic<float>'... converting 34 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:142:54) to (kernel.cpp:142:47) in function 'linear_forward_no_mul'... converting 17 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:216:34) to (kernel.cpp:138:45) in function 'linear_forward_no_mul'... converting 12 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:516:31) to (kernel.cpp:590:20) in function 'attention'... converting 47 basic blocks.
INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (kernel.cpp:710:3) to (kernel.cpp:753:22) in function 'attention'... converting 11 basic blocks.
INFO: [XFORM 203-11] Balancing expressions in function 'pow_reduce::pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)...6 expression(s) balanced.
INFO: [XFORM 203-11] Balancing expressions in function 'linear_forward_no_mul' (kernel.cpp:127)...8 expression(s) balanced.
INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:00:49 ; elapsed = 00:00:54 . Memory (MB): peak = 1459.949 ; gain = 821.922 ; free physical = 579706 ; free virtual = 757607
INFO: [XFORM 203-541] Flattening a loop nest 'l_S_j_0_j2' (kernel.cpp:138:52) in function 'linear_forward_no_mul'.
WARNING: [XFORM 203-631] Renaming function 'transpose_last_two_dims' to 'transpose_last_two_d' (kernel.cpp:338:45)
WARNING: [XFORM 203-631] Renaming function 'pow_reduce::pow_generic<float>' to 'pow_generic<float>' (/wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:320)
WARNING: [XFORM 203-631] Renaming function 'linear_forward_no_mul' to 'linear_forward_no_mu' (kernel.cpp:137:32)
INFO: [HLS 200-472] Inferring partial write operation for 'v204' (kernel.cpp:342:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:387:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:421:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v225[0]' (kernel.cpp:411:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:251:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v153[0]' (kernel.cpp:253:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v3[0]' (kernel.cpp:44:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v147[0]' (kernel.cpp:236:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v24[0]' (kernel.cpp:120:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:322:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v194' (kernel.cpp:327:11)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_hidden_states[0]' (kernel.cpp:480:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_proj_re' (kernel.cpp:501:7)
INFO: [HLS 200-472] Inferring partial write operation for 'k_proj_re' (kernel.cpp:507:7)
INFO: [HLS 200-472] Inferring partial write operation for 'v_proj_re' (kernel.cpp:513:7)
INFO: [HLS 200-472] Inferring partial write operation for 'q_embed[0]' (kernel.cpp:593:9)
INFO: [HLS 200-472] Inferring partial write operation for 'k_embed[0]' (kernel.cpp:601:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_k_cache' (kernel.cpp:610:9)
INFO: [HLS 200-472] Inferring partial write operation for 'updated_v_cache' (kernel.cpp:618:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:637:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:650:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_weights[0]' (kernel.cpp:667:9)
INFO: [HLS 200-472] Inferring partial write operation for 'softmax_attn_weights' (kernel.cpp:675:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output[0]' (kernel.cpp:684:9)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:692:7)
INFO: [HLS 200-472] Inferring partial write operation for 'attn_output_2D' (kernel.cpp:699:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rms_attn_output[0]' (kernel.cpp:706:7)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_q[0]' (kernel.cpp:272:9)
INFO: [HLS 200-472] Inferring partial write operation for 'rotated_k[0]' (kernel.cpp:280:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v164[0]' (kernel.cpp:296:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v165[0]' (kernel.cpp:304:9)
INFO: [HLS 200-472] Inferring partial write operation for 'v253[0]' (kernel.cpp:441:11)
INFO: [HLS 200-472] Inferring partial write operation for 'v211[0]' (kernel.cpp:362:11)
INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:00:57 ; elapsed = 00:01:02 . Memory (MB): peak = 1651.949 ; gain = 1013.922 ; free physical = 579549 ; free virtual = 757456
INFO: [HLS 200-10] Starting hardware synthesis ...
INFO: [HLS 200-10] Synthesizing 'attention' ...
WARNING: [SYN 201-103] Legalizing function name 'pow_generic<float>' to 'pow_generic_float_s'.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining function 'pow_generic<float>'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 25.
WARNING: [SCHED 204-21] Estimated clock period (9.38625ns) exceeds the target (target clock period: 10ns, clock uncertainty: 1.25ns, effective delay budget: 8.75ns).
WARNING: [SCHED 204-21] The critical path in module 'pow_generic_float_s' consists of the following:
	'mul' operation of DSP[246] ('r.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [243]  (3.36 ns)
	'add' operation of DSP[246] ('ret.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [246]  (3.02 ns)
	'icmp' operation ('icmp_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [250]  (2.32 ns)
	'select' operation ('select_ln805', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [252]  (0 ns)
	'select' operation ('r_exp.V', /wrk/2019.2/continuous/2019_11_06_2708876/src/products/hls/hls_lib/hlsmath/include/FloatingPoint/hls_pow.h:592) [253]  (0.687 ns)
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 62.35 seconds; current allocated memory: 605.123 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.38 seconds; current allocated memory: 606.495 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.49 seconds; current allocated memory: 606.891 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 607.368 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.36 seconds; current allocated memory: 607.954 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 608.515 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-61] Pipelining loop 'l_S_j_0_j2_l_S_k0_0_k0'.
INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 111.
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 609.492 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.42 seconds; current allocated memory: 610.833 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 611.127 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.08 seconds; current allocated memory: 611.282 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 611.388 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.11 seconds; current allocated memory: 611.550 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 611.896 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 612.335 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.23 seconds; current allocated memory: 612.624 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 612.954 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 613.180 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 613.398 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 613.585 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.13 seconds; current allocated memory: 613.877 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.16 seconds; current allocated memory: 614.231 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 614.828 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.39 seconds; current allocated memory: 615.266 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 615.519 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-42] -- Implementing module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SCHED 204-11] Starting scheduling ...
INFO: [SCHED 204-11] Finished scheduling.
INFO: [HLS 200-111]  Elapsed time: 0.37 seconds; current allocated memory: 617.259 MB.
INFO: [BIND 205-100] Starting micro-architecture generation ...
INFO: [BIND 205-101] Performing variable lifetime analysis.
INFO: [BIND 205-101] Exploring resource sharing.
INFO: [BIND 205-101] Binding ...
INFO: [BIND 205-100] Finished micro-architecture generation.
INFO: [HLS 200-111]  Elapsed time: 2.03 seconds; current allocated memory: 620.966 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'pow_generic_float_s' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_7' to 'pow_generic_floatbkb' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_6' to 'pow_generic_floatcud' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_9' to 'pow_generic_floatdEe' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_10' to 'pow_generic_floateOg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_8' to 'pow_generic_floatfYi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo_11' to 'pow_generic_floatg8j' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'pow_generic_float_s_pow_reduce_anonymo' to 'pow_generic_floathbi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_41ns_6ns_47_2_1' to 'attention_mul_41nibs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_44ns_6ns_50_3_1' to 'attention_mul_44njbC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_45ns_9s_52_2_1' to 'attention_mul_45nkbM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_43s_25s_67_2_1' to 'attention_mul_43slbW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_25s_6ns_25_1_1' to 'attention_mul_mulmb6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mac_muladd_13ns_13s_16s_25_1_1' to 'attention_mac_mulncg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_mul_mul_18ns_18ns_36_1_1' to 'attention_mul_mulocq' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mac_mulncg': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_41nibs': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_43slbW': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_44njbC': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_45nkbM': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulmb6': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_mul_mulocq': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'pow_generic_float_s'.
INFO: [HLS 200-111]  Elapsed time: 1.75 seconds; current allocated memory: 624.932 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rms_norm' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fadd_32ns_32ns_32_5_full_dsp_1' to 'attention_fadd_32pcA' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fmul_32ns_32ns_32_4_max_dsp_1' to 'attention_fmul_32qcK' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_fdiv_32ns_32ns_32_16_1' to 'attention_fdiv_32rcU' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'rms_norm'.
INFO: [HLS 200-111]  Elapsed time: 1.08 seconds; current allocated memory: 631.428 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'quantize_activation' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_fcmp_32ns_32ns_1_2_1' to 'attention_fcmp_32sc4' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'quantize_activation'.
INFO: [HLS 200-111]  Elapsed time: 0.57 seconds; current allocated memory: 633.432 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'linear_forward_no_mu' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_mul_52s_52s_104_2_1' to 'attention_mul_52stde' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_sdiv_97ns_63s_97_101_1' to 'attention_sdiv_97udo' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_mul_52stde': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_sdiv_97udo': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_forward_no_mu'.
INFO: [HLS 200-111]  Elapsed time: 0.67 seconds; current allocated memory: 638.411 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'reshape_2D_to_3D' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'reshape_2D_to_3D'.
INFO: [HLS 200-111]  Elapsed time: 0.9 seconds; current allocated memory: 642.885 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'rotate_half' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'rotate_half'.
INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 643.754 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'apply_rotary_pos_emb' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_q_0' to 'apply_rotary_pos_vdy' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'apply_rotary_pos_emb_rotated_k_0' to 'apply_rotary_pos_wdI' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 2 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 4 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'apply_rotary_pos_emb'.
INFO: [HLS 200-111]  Elapsed time: 0.41 seconds; current allocated memory: 645.211 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'cache_update' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'cache_update'.
INFO: [HLS 200-111]  Elapsed time: 0.56 seconds; current allocated memory: 647.454 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'transpose_last_two_d' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Finished creating RTL model for 'transpose_last_two_d'.
INFO: [HLS 200-111]  Elapsed time: 0.51 seconds; current allocated memory: 649.197 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float'.
INFO: [HLS 200-111]  Elapsed time: 0.44 seconds; current allocated memory: 650.500 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'softmax' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [SYN 201-210] Renamed object name 'attention_faddfsub_32ns_32ns_32_5_full_dsp_1' to 'attention_faddfsuxdS' due to the length limit 20
INFO: [RTGEN 206-100] Generating core module 'attention_faddfsuxdS': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fcmp_32sc4': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fdiv_32rcU': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax'.
INFO: [HLS 200-111]  Elapsed time: 0.48 seconds; current allocated memory: 652.575 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'GEMM_3D_float2' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-100] Generating core module 'attention_fadd_32pcA': 1 instance(s).
INFO: [RTGEN 206-100] Generating core module 'attention_fmul_32qcK': 1 instance(s).
INFO: [RTGEN 206-100] Finished creating RTL model for 'GEMM_3D_float2'.
INFO: [HLS 200-111]  Elapsed time: 0.69 seconds; current allocated memory: 654.916 MB.
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [HLS 200-10] -- Generating RTL for module 'attention' 
INFO: [HLS 200-10] ----------------------------------------------------------------
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v263' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v264_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v265' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v266_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v267' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v268_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v269' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_0' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v270_1' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v271' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v272' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v273' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v274' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v275' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v276' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v277' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v278' to 'ap_none'.
INFO: [RTGEN 206-500] Setting interface mode on port 'attention/v279' to 'ap_memory'.
INFO: [RTGEN 206-500] Setting interface mode on function 'attention' to 'ap_ctrl_hs'.
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_8' to 'attention_quantizyd2' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_7' to 'attention_quantizzec' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_6' to 'attention_quantizAem' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_5' to 'attention_quantizBew' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_4' to 'attention_quantizCeG' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_3' to 'attention_quantizDeQ' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_2' to 'attention_quantizEe0' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta_1' to 'attention_quantizFfa' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_hidden_sta' to 'attention_quantizGfk' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_k_proj_transposed' to 'attention_k_proj_Hfu' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_8' to 'attention_quantizIfE' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_7' to 'attention_quantizJfO' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_6' to 'attention_quantizKfY' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_5' to 'attention_quantizLf8' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_4' to 'attention_quantizMgi' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_3' to 'attention_quantizNgs' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_2' to 'attention_quantizOgC' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp_1' to 'attention_quantizPgM' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_quantized_final_outp' to 'attention_quantizQgW' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_rms_hidden_states_0' to 'attention_rms_hidRg6' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_k_cache' to 'attention_updatedShg' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_updated_v_cache' to 'attention_updatedThq' due to the length limit 20
INFO: [SYN 201-210] Renamed object name 'attention_attn_weights_0' to 'attention_attn_weUhA' due to the length limit 20
INFO: [SYN 201-210]